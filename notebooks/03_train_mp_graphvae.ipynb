{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Message-Passing Graph Variational Autoencoder\n",
    "\n",
    "Here I will use principles from message-passing graph neural networks to try to generate\n",
    "molecules in a graph variational autoencoder. This is based on my solutions to \n",
    "`geometric-gnn-dojo/geometric_gnn_101.ipynb`\n",
    "Some of the code has also been taken from there\n",
    "\n",
    "might also want to consider autoregressive model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version 2.5.0+cu124\n",
      "PyG version 2.6.1\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import logging\n",
    "import time\n",
    "from mygenai.models.graphvae import PropertyConditionedVAE\n",
    "# importlib.reload(PropertyConditionedVAE)\n",
    "\n",
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "import torch_geometric\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "print(\"PyTorch version {}\".format(torch.__version__))\n",
    "print(\"PyG version {}\".format(torch_geometric.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Debug mode is OFF\n"
     ]
    }
   ],
   "source": [
    "\n",
    "debug_print = False\n",
    "if debug_print:\n",
    "    print(\"Debug mode is ON\")\n",
    "    logging.basicConfig(\n",
    "        level=logging.DEBUG,\n",
    "        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "        force=True  # Ensure configuration is applied\n",
    "    )\n",
    "    for logger_name in ['train_epoch', 'PropertyConditionedVAE', 'ConditionalDecoder', 'Encoder']:\n",
    "        logging.getLogger(logger_name).setLevel(logging.DEBUG)\n",
    "else:\n",
    "    print(\"Debug mode is OFF\")\n",
    "    logging.basicConfig(\n",
    "        level=logging.INFO,\n",
    "        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "        force=True  # Ensure configuration is applied\n",
    "    )\n",
    "    for logger_name in ['train_epoch', 'PropertyConditionedVAE', 'ConditionalDecoder', 'Encoder']:\n",
    "        logging.getLogger(logger_name).setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-18 16:05:52,169 - rdkit - INFO - Enabling RDKit 2024.09.6 jupyter extensions\n",
      "/home/jph/dev/generative-molecular-design/.conda/lib/python3.12/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.datasets import QM9\n",
    "from torch_geometric.loader import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from mygenai.utils.transforms import CompleteGraph\n",
    "\n",
    "dataset = QM9(root=\"../data/QM9\", transform=CompleteGraph())\n",
    "# Normalize targets per data sample to mean = 0 and std = 1.\n",
    "mean = dataset.data.y.mean(dim=0, keepdim=True)\n",
    "std = dataset.data.y.std(dim=0, keepdim=True)\n",
    "dataset.data.y = (dataset.data.y - mean) / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data splitting (60/20/20)\n",
    "train_val_idx, test_idx = train_test_split(\n",
    "    np.arange(len(dataset)),\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "train_idx, val_idx = train_test_split(\n",
    "    train_val_idx,\n",
    "    test_size=0.25,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(dataset[train_idx], batch_size=128, shuffle=True)\n",
    "val_loader = DataLoader(dataset[val_idx], batch_size=128, shuffle=False)\n",
    "test_loader = DataLoader(dataset[test_idx], batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<unknown>:9: SyntaxWarning: invalid escape sequence '\\o'\n"
     ]
    }
   ],
   "source": [
    "# Training setup\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = PropertyConditionedVAE().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode='min', factor=0.5, patience=5, min_lr=1e-6\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward pass successful!\n"
     ]
    }
   ],
   "source": [
    "# test forward passs\n",
    "batch = next(iter(train_loader))\n",
    "batch = batch.to(device)\n",
    "with torch.no_grad():\n",
    "    outputs = model(batch)\n",
    "print(\"Forward pass successful!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # check if training sets are reasonably balanced\n",
    "\n",
    "# def basic_homo_lumo_stats(loader, name):\n",
    "#     total_nodes = 0\n",
    "#     total_graphs = 0\n",
    "#     prop_values = []\n",
    "\n",
    "#     for batch in loader:\n",
    "#         total_graphs += batch.batch.max().item() + 1\n",
    "#         total_nodes += batch.x.shape[0]\n",
    "#         prop_values.append(batch.y[:, 4].cpu().numpy())\n",
    "\n",
    "#     prop_values = np.concatenate(prop_values)\n",
    "#     print(f\"{name} stats - graphs: {total_graphs}, avg. nodes: {total_nodes/total_graphs}\")\n",
    "#     print(f\"{name} property stats - mean: {prop_values.mean():.4f}, std: {prop_values.std():.4f}\")\n",
    "\n",
    "# basic_homo_lumo_stats(train_loader, \"Train\")\n",
    "# basic_homo_lumo_stats(test_loader, \"Test\")\n",
    "# basic_homo_lumo_stats(val_loader, \"Validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-18 16:05:53,162 - root - INFO - Target property shape: torch.Size([128, 19])\n",
      "2025-04-18 16:05:53,163 - root - INFO - Target property sample: tensor([-0.2801,  0.0696,  0.7379,  1.1327,  0.7810,  0.0062,  0.6108, -0.7373,\n",
      "        -0.7373, -0.7373, -0.7374,  1.1148, -0.3726, -0.3733, -0.3755, -0.3464,\n",
      "        -0.0043,  0.0844, -0.0351])\n",
      "2025-04-18 16:05:53,164 - root - INFO - Input node features shape: torch.Size([2331, 11])\n",
      "2025-04-18 16:05:53,164 - root - INFO - Input positions shape: torch.Size([2331, 3])\n",
      "2025-04-18 16:05:53,164 - root - INFO - Number of nodes: 2331\n",
      "2025-04-18 16:05:53,164 - root - INFO - Batch size: 128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated node features: min=4.0144, max=5.0291\n",
      "Original node features: min=0.0000, max=9.0000\n",
      "Generated positions: min=-0.7958, max=-0.7534\n",
      "Original positions: min=-7.2859, max=6.3207\n",
      "Epoch 000 | Train Loss: 5.8704 | Val Loss: 65.1172\n",
      "Generated node features: min=-0.1438, max=9.0182\n",
      "Original node features: min=0.0000, max=9.0000\n",
      "Generated positions: min=-6.9755, max=6.9755\n",
      "Original positions: min=-6.8449, max=6.9834\n",
      "Epoch 001 | Train Loss: 22.6095 | Val Loss: 79.5893\n",
      "Generated node features: min=-0.1438, max=9.0182\n",
      "Original node features: min=0.0000, max=9.0000\n",
      "Generated positions: min=-6.9755, max=6.9755\n",
      "Original positions: min=-6.6080, max=6.3674\n",
      "Epoch 002 | Train Loss: 35.3322 | Val Loss: 78.8041\n",
      "Generated node features: min=-0.1438, max=9.0182\n",
      "Original node features: min=0.0000, max=9.0000\n",
      "Generated positions: min=-6.9755, max=6.9755\n",
      "Original positions: min=-6.5136, max=6.9398\n",
      "Epoch 003 | Train Loss: 35.6613 | Val Loss: 78.7592\n",
      "Generated node features: min=-0.1438, max=9.0182\n",
      "Original node features: min=0.0000, max=9.0000\n",
      "Generated positions: min=-6.9755, max=6.9755\n",
      "Original positions: min=-8.7131, max=6.4304\n",
      "Epoch 004 | Train Loss: 37.6424 | Val Loss: 78.9508\n",
      "Generated node features: min=-0.1438, max=9.0182\n",
      "Original node features: min=0.0000, max=9.0000\n",
      "Generated positions: min=-6.9755, max=6.9755\n",
      "Original positions: min=-6.0499, max=7.8820\n",
      "Epoch 005 | Train Loss: 35.8506 | Val Loss: 78.9447\n",
      "Generated node features: min=-0.1438, max=9.0182\n",
      "Original node features: min=0.0000, max=9.0000\n",
      "Generated positions: min=-6.9755, max=6.9755\n",
      "Original positions: min=-7.3237, max=6.7507\n",
      "Epoch 006 | Train Loss: 39.7318 | Val Loss: 79.9791\n",
      "Generated node features: min=-0.1438, max=9.0182\n",
      "Original node features: min=0.0000, max=9.0000\n",
      "Generated positions: min=-6.9755, max=6.9755\n",
      "Original positions: min=-6.2269, max=6.3428\n",
      "Epoch 007 | Train Loss: 40.5815 | Val Loss: 79.9791\n",
      "Generated node features: min=-0.1438, max=9.0182\n",
      "Original node features: min=0.0000, max=9.0000\n",
      "Generated positions: min=-6.9755, max=6.9755\n",
      "Original positions: min=-7.2061, max=7.0049\n",
      "Epoch 008 | Train Loss: 36.9261 | Val Loss: 79.9791\n",
      "Generated node features: min=-0.1438, max=9.0182\n",
      "Original node features: min=0.0000, max=8.0000\n",
      "Generated positions: min=-6.9755, max=6.9755\n",
      "Original positions: min=-7.0567, max=6.5750\n",
      "Epoch 009 | Train Loss: 37.3802 | Val Loss: 79.9814\n",
      "Generated node features: min=-0.1438, max=9.0182\n",
      "Original node features: min=0.0000, max=9.0000\n",
      "Generated positions: min=-6.9755, max=6.9755\n",
      "Original positions: min=-7.0463, max=5.7021\n",
      "Early stopping at epoch 10\n",
      "Saved best model to: best_vae_model_20250418_162135.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_55219/1786063530.py:168: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('best_vae_model.pt'))\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for PropertyConditionedVAE:\n\tMissing key(s) in state_dict: \"decoder.node_scale\", \"decoder.node_shift\", \"decoder.pos_scale\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 168\u001b[39m\n\u001b[32m    165\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m03d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m | Train Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m | Val Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n\u001b[32m    167\u001b[39m \u001b[38;5;66;03m# Load best model for testing\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m168\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mbest_vae_model.pt\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    170\u001b[39m \u001b[38;5;66;03m# Test final model\u001b[39;00m\n\u001b[32m    171\u001b[39m test_loss = validate(model, test_loader, device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/generative-molecular-design/.conda/lib/python3.12/site-packages/torch/nn/modules/module.py:2584\u001b[39m, in \u001b[36mModule.load_state_dict\u001b[39m\u001b[34m(self, state_dict, strict, assign)\u001b[39m\n\u001b[32m   2576\u001b[39m         error_msgs.insert(\n\u001b[32m   2577\u001b[39m             \u001b[32m0\u001b[39m,\n\u001b[32m   2578\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m. \u001b[39m\u001b[33m\"\u001b[39m.format(\n\u001b[32m   2579\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m.join(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)\n\u001b[32m   2580\u001b[39m             ),\n\u001b[32m   2581\u001b[39m         )\n\u001b[32m   2583\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) > \u001b[32m0\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m2584\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   2585\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m\"\u001b[39m.format(\n\u001b[32m   2586\u001b[39m             \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m, \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[33m\"\u001b[39m.join(error_msgs)\n\u001b[32m   2587\u001b[39m         )\n\u001b[32m   2588\u001b[39m     )\n\u001b[32m   2589\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[31mRuntimeError\u001b[39m: Error(s) in loading state_dict for PropertyConditionedVAE:\n\tMissing key(s) in state_dict: \"decoder.node_scale\", \"decoder.node_shift\", \"decoder.pos_scale\". "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# TODO : move training etc. to mygenai\n",
    "# logging.basicConfig(level=logging.DEBUG)\n",
    "\n",
    "# for now, check to see if can at least reconstruct molecules\n",
    "recon_weight = 1.0\n",
    "kl_weight = 0.\n",
    "property_weight = 0.\n",
    "\n",
    "def train_epoch(model, optimizer, train_loader, device):\n",
    "    logger = logging.getLogger('train_epoch')\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch_idx, batch in enumerate(train_loader):\n",
    "        batch = batch.to(device)\n",
    "        logger.debug(f\"\\nBatch {batch_idx}:\")\n",
    "        logger.debug(f\"Batch properties: x={batch.x.shape}, pos={batch.pos.shape}, batch={batch.batch.shape}\")\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        node_features, positions, mu, log_var, property_pred, num_nodes = model(batch)\n",
    "        if batch_idx == 0:  # Check first batch only\n",
    "            # Print statistics about generated values\n",
    "            print(f\"Generated node features: min={node_features.min().item():.4f}, max={node_features.max().item():.4f}\")\n",
    "            print(f\"Original node features: min={batch.x.min().item():.4f}, max={batch.x.max().item():.4f}\")\n",
    "            print(f\"Generated positions: min={positions.min().item():.4f}, max={positions.max().item():.4f}\")\n",
    "            print(f\"Original positions: min={batch.pos.min().item():.4f}, max={batch.pos.max().item():.4f}\")\n",
    "\n",
    "        # Calculate loss\n",
    "        loss = model.loss_function(\n",
    "            node_features, positions, num_nodes,\n",
    "            batch, mu, log_var, property_pred,\n",
    "            recon_weight=recon_weight, kl_weight=kl_weight, property_weight=property_weight\n",
    "        )\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=.5)\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(train_loader)\n",
    "\n",
    "def validate(model, val_loader, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    batch_losses = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch in enumerate(val_loader):\n",
    "            batch = batch.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            node_features, positions, mu, log_var, property_pred, num_nodes = model(batch)\n",
    "\n",
    "            # Calculate reconstruction loss manually for debugging\n",
    "            recon_loss = 0\n",
    "            start_idx = 0\n",
    "            total_nodes = 0\n",
    "\n",
    "            # Process each graph in the batch\n",
    "            for i, n in enumerate(num_nodes):\n",
    "                n_orig = (batch.batch == i).sum().item()\n",
    "                n_gen = n.item()\n",
    "                nodes_to_compare = min(n_gen, n_orig)\n",
    "                total_nodes += nodes_to_compare\n",
    "\n",
    "                # # Debug node counts\n",
    "                # if nodes_to_compare == 0:\n",
    "                #     print(f\"Warning: Zero nodes to compare in graph {i}, batch {batch_idx}\")\n",
    "                #     print(f\"  Original: {n_orig}, Generated: {n_gen}\")\n",
    "\n",
    "                # if nodes_to_compare > 0:\n",
    "                #     try:\n",
    "                #         # Check for NaN or inf values\n",
    "                #         if torch.isnan(node_features[start_idx:start_idx + nodes_to_compare]).any():\n",
    "                #             print(f\"NaN in node features, batch {batch_idx}, graph {i}\")\n",
    "                #         if torch.isnan(positions[start_idx:start_idx + nodes_to_compare]).any():\n",
    "                #             print(f\"NaN in positions, batch {batch_idx}, graph {i}\")\n",
    "\n",
    "                #         # Debug ranges\n",
    "                #         print(f\"Batch {batch_idx}, Graph {i}: Node features range: \"\n",
    "                #               f\"{node_features[start_idx:start_idx + nodes_to_compare].min().item():.2f} - \"\n",
    "                #               f\"{node_features[start_idx:start_idx + nodes_to_compare].max().item():.2f}\")\n",
    "                #         print(f\"Batch {batch_idx}, Graph {i}: Positions range: \"\n",
    "                #               f\"{positions[start_idx:start_idx + nodes_to_compare].min().item():.2f} - \"\n",
    "                #               f\"{positions[start_idx:start_idx + nodes_to_compare].max().item():.2f}\")\n",
    "                #     except Exception as e:\n",
    "                #         print(f\"Error checking batch {batch_idx}, graph {i}: {e}\")\n",
    "\n",
    "                start_idx += n_gen\n",
    "\n",
    "            # Regular loss calculation\n",
    "            loss = model.loss_function(\n",
    "                node_features, positions, num_nodes,\n",
    "                batch, mu, log_var, property_pred,\n",
    "                recon_weight=recon_weight, kl_weight=kl_weight, property_weight=property_weight\n",
    "            )\n",
    "\n",
    "            # Check for reasonable loss values\n",
    "            if loss.item() > 1e6:\n",
    "                print(f\"âŒ Extremely high loss in validation batch {batch_idx}: {loss.item():.4f}\")\n",
    "                # Try to identify which graphs in the batch are problematic\n",
    "                for i, n in enumerate(num_nodes):\n",
    "                    # Check node feature norms\n",
    "                    start_idx = sum(n_prev.item() for n_prev in num_nodes[:i])\n",
    "                    end_idx = start_idx + n.item()\n",
    "                    if end_idx > start_idx:\n",
    "                        feat_norm = torch.norm(node_features[start_idx:end_idx]).item()\n",
    "                        pos_norm = torch.norm(positions[start_idx:end_idx]).item()\n",
    "                        print(f\"  Graph {i}: Features norm={feat_norm:.2f}, Positions norm={pos_norm:.2f}\")\n",
    "\n",
    "            batch_losses.append(loss.item())\n",
    "            total_loss += loss.item()\n",
    "\n",
    "    # Print statistics of losses\n",
    "    batch_losses = np.array(batch_losses)\n",
    "    # print(f\"Validation loss stats: mean={batch_losses.mean():.2f}, median={np.median(batch_losses):.2f}, \"\n",
    "        #   f\"min={batch_losses.min():.2f}, max={batch_losses.max():.2f}\")\n",
    "\n",
    "    return total_loss / len(val_loader)\n",
    "\n",
    "\n",
    "# Training loop\n",
    "n_epochs = 100\n",
    "best_val_loss = float('inf')\n",
    "patience = 10\n",
    "patience_counter = 0\n",
    "\n",
    "batch = next(iter(train_loader))\n",
    "logging.info(f\"Target property shape: {batch.y.shape}\")\n",
    "logging.info(f\"Target property sample: {batch.y[0]}\")\n",
    "logging.info(f\"Input node features shape: {batch.x.shape}\")  # Should be (N, 11)\n",
    "logging.info(f\"Input positions shape: {batch.pos.shape}\")    # Should be (N, 3)\n",
    "logging.info(f\"Number of nodes: {batch.num_nodes}\")\n",
    "logging.info(f\"Batch size: {batch.batch.max().item() + 1}\")\n",
    "for epoch in range(n_epochs):\n",
    "    # Train\n",
    "    train_loss = train_epoch(model, optimizer, train_loader, device)\n",
    "\n",
    "    # Validate\n",
    "    val_loss = validate(model, val_loader, device)\n",
    "\n",
    "    # Learning rate scheduling\n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "    # Early stopping\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        patience_counter = 0\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= patience:\n",
    "            print(f'Early stopping at epoch {epoch}')\n",
    "            # Save best model\n",
    "            # Save model with timestamp in a more readable format\n",
    "            timestamp = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "            save_path = f'best_vae_model_{timestamp}.pt'\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            print(f'Saved best model to: {save_path}')\n",
    "            break\n",
    "\n",
    "    # Print progress\n",
    "    print(f'Epoch {epoch:03d} | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}')\n",
    "\n",
    "# Load best model for testing\n",
    "# model.load_state_dict(torch.load('best_vae_model.pt'))\n",
    "\n",
    "# Test final model\n",
    "test_loss = validate(model, test_loader, device)\n",
    "print(f'Final Test Loss: {test_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
