{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Message-Passing Graph Variational Autoencoder\n",
    "\n",
    "Here I will use principles from message-passing graph neural networks to try to generate\n",
    "molecules in a graph variational autoencoder. This is based on my solutions to \n",
    "`geometric-gnn-dojo/geometric_gnn_101.ipynb`\n",
    "Some of the code has also been taken from there\n",
    "\n",
    "might also want to consider autoregressive model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version 2.5.0+cu124\n",
      "PyG version 2.6.1\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import logging\n",
    "import time\n",
    "from mygenai.models.graphvae import PropertyConditionedVAE\n",
    "# importlib.reload(PropertyConditionedVAE)\n",
    "\n",
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "import torch_geometric\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "print(\"PyTorch version {}\".format(torch.__version__))\n",
    "print(\"PyG version {}\".format(torch_geometric.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Debug mode is OFF\n"
     ]
    }
   ],
   "source": [
    "\n",
    "debug_print = False\n",
    "if debug_print:\n",
    "    print(\"Debug mode is ON\")\n",
    "    logging.basicConfig(\n",
    "        level=logging.DEBUG,\n",
    "        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "        force=True  # Ensure configuration is applied\n",
    "    )\n",
    "    for logger_name in ['train_epoch', 'PropertyConditionedVAE', 'ConditionalDecoder', 'Encoder']:\n",
    "        logging.getLogger(logger_name).setLevel(logging.DEBUG)\n",
    "else:\n",
    "    print(\"Debug mode is OFF\")\n",
    "    logging.basicConfig(\n",
    "        level=logging.INFO,\n",
    "        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "        force=True  # Ensure configuration is applied\n",
    "    )\n",
    "    for logger_name in ['train_epoch', 'PropertyConditionedVAE', 'ConditionalDecoder', 'Encoder']:\n",
    "        logging.getLogger(logger_name).setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jph/dev/generative-molecular-design/.conda/lib/python3.12/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.datasets import QM9\n",
    "from torch_geometric.loader import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from mygenai.utils.transforms import CompleteGraph\n",
    "from mygenai.utils.transforms import AddEdgeExistence\n",
    "\n",
    "dataset = QM9(root=\"../data/QM9\", transform=AddEdgeExistence()) #, transform=CompleteGraph())\n",
    "# Normalize targets per data sample to mean = 0 and std = 1.\n",
    "mean = dataset.data.y.mean(dim=0, keepdim=True)\n",
    "std = dataset.data.y.std(dim=0, keepdim=True)\n",
    "dataset.data.y = (dataset.data.y - mean) / std\n",
    "# focus on just using the one-hot encoding of the atomic number, for simplicity for now\n",
    "dataset.data.x = dataset.data.x[:, :5]\n",
    "\n",
    "# Normalize distances in the dataset\n",
    "fixed_max_distance = 2.0\n",
    "\n",
    "# TODO in the future maybe use a Z matrix representation for positions\n",
    "# def normalize_distances(dataset, max_distance):\n",
    "#     for data in dataset:\n",
    "#         pos = data.pos  # (n, 3) - absolute coordinates\n",
    "#         src, dst = data.edge_index  # (2, num_edges) - edge indices\n",
    "#         relative_positions = pos[dst] - pos[src]  # (num_edges, 3)\n",
    "#         distances = torch.norm(relative_positions, dim=1)  # (num_edges,)\n",
    "#         data.normalized_distances = distances / max_distance  # Normalize distances\n",
    "#     return dataset\n",
    "\n",
    "# dataset = normalize_distances(dataset, fixed_max_distance)\n",
    "# min_atomic_number = 1\n",
    "# max_atomic_number = 9\n",
    "# dataset.data.z = (dataset.data.z - min_atomic_number) / (max_atomic_number - min_atomic_number) # doesn't actually matter because it's not used (this information is determined by data.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data splitting (60/20/20)\n",
    "train_val_idx, test_idx = train_test_split(\n",
    "    np.arange(len(dataset)),\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "train_idx, val_idx = train_test_split(\n",
    "    train_val_idx,\n",
    "    test_size=0.25,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(dataset[train_idx], batch_size=128, shuffle=True)\n",
    "val_loader = DataLoader(dataset[val_idx], batch_size=128, shuffle=False)\n",
    "test_loader = DataLoader(dataset[test_idx], batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training setup\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = PropertyConditionedVAE().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode='min', factor=0.5, patience=5, min_lr=1e-6\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward pass successful!\n"
     ]
    }
   ],
   "source": [
    "# test forward passs\n",
    "batch = next(iter(train_loader))\n",
    "batch = batch.to(device)\n",
    "with torch.no_grad():\n",
    "    outputs = model(batch)\n",
    "print(\"Forward pass successful!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # check if training sets are reasonably balanced\n",
    "\n",
    "# def basic_homo_lumo_stats(loader, name):\n",
    "#     total_nodes = 0\n",
    "#     total_graphs = 0\n",
    "#     prop_values = []\n",
    "\n",
    "#     for batch in loader:\n",
    "#         total_graphs += batch.batch.max().item() + 1\n",
    "#         total_nodes += batch.x.shape[0]\n",
    "#         prop_values.append(batch.y[:, 4].cpu().numpy())\n",
    "\n",
    "#     prop_values = np.concatenate(prop_values)\n",
    "#     print(f\"{name} stats - graphs: {total_graphs}, avg. nodes: {total_nodes/total_graphs}\")\n",
    "#     print(f\"{name} property stats - mean: {prop_values.mean():.4f}, std: {prop_values.std():.4f}\")\n",
    "\n",
    "# basic_homo_lumo_stats(train_loader, \"Train\")\n",
    "# basic_homo_lumo_stats(test_loader, \"Test\")\n",
    "# basic_homo_lumo_stats(val_loader, \"Validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-21 13:29:35,288 - root - INFO - Target property shape: torch.Size([128, 19])\n",
      "2025-04-21 13:29:35,289 - root - INFO - Target property sample: tensor([ 1.1939e+00,  1.2649e+00, -2.1483e+00, -2.4554e+00, -1.4376e+00,\n",
      "         1.9015e+00, -1.4796e+00,  2.8287e-01,  2.8287e-01,  2.8287e-01,\n",
      "         2.8283e-01, -4.2958e-01,  8.9549e-01,  9.0289e-01,  9.0640e-01,\n",
      "         8.4868e-01, -2.3879e-03, -4.6962e-01, -4.6332e-01])\n",
      "2025-04-21 13:29:35,289 - root - INFO - Input node features shape: torch.Size([2279, 5])\n",
      "2025-04-21 13:29:35,289 - root - INFO - Input positions shape: torch.Size([2279, 3])\n",
      "2025-04-21 13:29:35,290 - root - INFO - Number of nodes: 2279\n",
      "2025-04-21 13:29:35,290 - root - INFO - Batch size: 128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated node features: min=0.0174, max=0.6122\n",
      "Generated distances: min=1.0282, max=1.7611\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'GlobalStorage' object has no attribute 'edge_existence'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 91\u001b[39m\n\u001b[32m     88\u001b[39m logging.info(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mBatch size: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbatch.batch.max().item()\u001b[38;5;250m \u001b[39m+\u001b[38;5;250m \u001b[39m\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     89\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_epochs):\n\u001b[32m     90\u001b[39m     \u001b[38;5;66;03m# Train\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m91\u001b[39m     train_loss = \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     93\u001b[39m     \u001b[38;5;66;03m# Validate\u001b[39;00m\n\u001b[32m     94\u001b[39m     val_loss = validate(model, val_loader, device)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 31\u001b[39m, in \u001b[36mtrain_epoch\u001b[39m\u001b[34m(model, optimizer, train_loader, device)\u001b[39m\n\u001b[32m     27\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mGenerated distances: min=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdistances.min().item()\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, max=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdistances.max().item()\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     28\u001b[39m     \u001b[38;5;66;03m# print(f\"Generated directions: min={directions.min().item():.4f}, max={directions.max().item():.4f}\")\u001b[39;00m\n\u001b[32m     29\u001b[39m \n\u001b[32m     30\u001b[39m \u001b[38;5;66;03m# Calculate loss\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m loss = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mloss_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     32\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnode_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdistances\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdirections\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_nodes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[43m    \u001b[49m\u001b[43medge_existence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_var\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproperty_pred\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     34\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrecon_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrecon_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkl_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkl_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproperty_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproperty_weight\u001b[49m\n\u001b[32m     35\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     37\u001b[39m \u001b[38;5;66;03m# Backward pass\u001b[39;00m\n\u001b[32m     38\u001b[39m loss.backward()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/generative-molecular-design/mygenai/models/graphvae.py:195\u001b[39m, in \u001b[36mPropertyConditionedVAE.loss_function\u001b[39m\u001b[34m(self, node_features, distances, directions, edge_features, num_nodes, edge_existence, data, mu, log_var, property_pred, property_weight, recon_weight, kl_weight)\u001b[39m\n\u001b[32m    192\u001b[39m logger.debug(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNode feature loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnode_loss.item()\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.6f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    194\u001b[39m \u001b[38;5;66;03m# Edge existence loss\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m195\u001b[39m edge_existence_loss = F.binary_cross_entropy(edge_existence, \u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43medge_existence\u001b[49m.float())\n\u001b[32m    196\u001b[39m logger.debug(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mEdge existence loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00medge_existence_loss.item()\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.6f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    198\u001b[39m \u001b[38;5;66;03m# Filter edges that exist in the ground truth\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/generative-molecular-design/.conda/lib/python3.12/site-packages/torch_geometric/data/data.py:561\u001b[39m, in \u001b[36mData.__getattr__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m    555\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33m_store\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.\u001b[34m__dict__\u001b[39m:\n\u001b[32m    556\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    557\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mThe \u001b[39m\u001b[33m'\u001b[39m\u001b[33mdata\u001b[39m\u001b[33m'\u001b[39m\u001b[33m object was created by an older version of PyG. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    558\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mIf this error occurred while loading an already existing \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    559\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mdataset, remove the \u001b[39m\u001b[33m'\u001b[39m\u001b[33mprocessed/\u001b[39m\u001b[33m'\u001b[39m\u001b[33m directory in the dataset\u001b[39m\u001b[33m'\u001b[39m\u001b[33ms \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    560\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mroot folder and try again.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m561\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_store\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/generative-molecular-design/.conda/lib/python3.12/site-packages/torch_geometric/data/storage.py:96\u001b[39m, in \u001b[36mBaseStorage.__getattr__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m     94\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[key]\n\u001b[32m     95\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m96\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[32m     97\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m object has no attribute \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     98\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[31mAttributeError\u001b[39m: 'GlobalStorage' object has no attribute 'edge_existence'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# TODO : move training etc. to mygenai\n",
    "# logging.basicConfig(level=logging.DEBUG)\n",
    "\n",
    "# for now, check to see if can at least reconstruct molecules\n",
    "recon_weight = 1.0\n",
    "kl_weight = 0. #0.001\n",
    "property_weight = 0.\n",
    "\n",
    "def train_epoch(model, optimizer, train_loader, device):\n",
    "    logger = logging.getLogger('train_epoch')\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch_idx, batch in enumerate(train_loader):\n",
    "        batch = batch.to(device)\n",
    "        logger.debug(f\"\\nBatch {batch_idx}:\")\n",
    "        logger.debug(f\"Batch properties: x={batch.x.shape}, pos={batch.pos.shape}, batch={batch.batch.shape}\")\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        node_features, distances, directions, edge_features, num_nodes, edge_existence, mu, log_var, property_pred = model(batch)\n",
    "\n",
    "        if batch_idx == 0:  # Check first batch only\n",
    "            # Print statistics about generated values\n",
    "            print(f\"Generated node features: min={node_features.min().item():.4f}, max={node_features.max().item():.4f}\")\n",
    "            # print(f\"Original node features: min={batch.x.min().item():.4f}, max={batch.x.max().item():.4f}\") # always in [0,1] because one-hot encoding\n",
    "            print(f\"Generated distances: min={distances.min().item():.4f}, max={distances.max().item():.4f}\")\n",
    "            # print(f\"Generated directions: min={directions.min().item():.4f}, max={directions.max().item():.4f}\")\n",
    "\n",
    "        # Calculate loss\n",
    "        loss = model.loss_function(\n",
    "            node_features, distances, directions, edge_features, num_nodes,\n",
    "            edge_existence, batch, mu, log_var, property_pred,\n",
    "            recon_weight=recon_weight, kl_weight=kl_weight, property_weight=property_weight\n",
    "        )\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.)\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(train_loader)\n",
    "\n",
    "\n",
    "def validate(model, val_loader, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    batch_losses = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch in enumerate(val_loader):\n",
    "            batch = batch.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            node_features, distances, directions, edge_features, num_nodes, mu, log_var, property_pred = model(batch)\n",
    "\n",
    "            # Calculate loss\n",
    "            loss = model.loss_function(\n",
    "                node_features, distances, directions, edge_features, num_nodes,\n",
    "                batch, mu, log_var, property_pred,\n",
    "                recon_weight=recon_weight, kl_weight=kl_weight, property_weight=property_weight\n",
    "            )\n",
    "\n",
    "            batch_losses.append(loss.item())\n",
    "            total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(val_loader)\n",
    "\n",
    "\n",
    "# Training loop\n",
    "n_epochs = 100\n",
    "best_val_loss = float('inf')\n",
    "patience = 10\n",
    "patience_counter = 0\n",
    "\n",
    "# TODO normalise for a minimum distance!!\n",
    "# TODO !!!!! The minimal and maximal distances are from preprocessing WITHOUT CompleteGraph >____<<< !!!!!!\n",
    "#   No wonder you get fucked up distances...\n",
    "# TODO don't use a complete graph, check edge detection and use softmax (since it is one-hot) for bond type!\n",
    "batch = next(iter(train_loader))\n",
    "logging.info(f\"Target property shape: {batch.y.shape}\")\n",
    "logging.info(f\"Target property sample: {batch.y[0]}\")\n",
    "logging.info(f\"Input node features shape: {batch.x.shape}\")  # Should be (N, 11)\n",
    "logging.info(f\"Input positions shape: {batch.pos.shape}\")    # Should be (N, 3)\n",
    "logging.info(f\"Number of nodes: {batch.num_nodes}\")\n",
    "logging.info(f\"Batch size: {batch.batch.max().item() + 1}\")\n",
    "for epoch in range(n_epochs):\n",
    "    # Train\n",
    "    train_loss = train_epoch(model, optimizer, train_loader, device)\n",
    "\n",
    "    # Validate\n",
    "    val_loss = validate(model, val_loader, device)\n",
    "\n",
    "    # Learning rate scheduling\n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "    # Early stopping\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        patience_counter = 0\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= patience:\n",
    "            print(f'Early stopping at epoch {epoch}')\n",
    "            # Save best model\n",
    "            # Save model with timestamp in a more readable format\n",
    "            timestamp = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "            save_path = f'best_vae_model_{timestamp}.pt'\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            print(f'Saved best model to: {save_path}')\n",
    "            break\n",
    "\n",
    "    # Print progress\n",
    "    print(f'Epoch {epoch:03d} | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}')\n",
    "\n",
    "# Load best model for testing\n",
    "# model.load_state_dict(torch.load('best_vae_model.pt'))\n",
    "\n",
    "# Test final model\n",
    "test_loss = validate(model, test_loader, device)\n",
    "print(f'Final Test Loss: {test_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_molecule = dataset[0]\n",
    "test_molecule = test_molecule.to(device)\n",
    "\n",
    "from torch_geometric.data import Batch\n",
    "# Create a batch with a single molecule\n",
    "test_batch = Batch.from_data_list([test_molecule])\n",
    "outputs = model(test_batch)\n",
    "node_features, distances, directions, edge_features, num_nodes, mu, log_var, property_pred = outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated node features:\n",
      "tensor([[0.5131, 0.3238, 0.0774, 0.0667, 0.0009],\n",
      "        [0.5131, 0.3238, 0.0774, 0.0667, 0.0009],\n",
      "        [0.5131, 0.3238, 0.0774, 0.0667, 0.0009],\n",
      "        [0.5131, 0.3238, 0.0774, 0.0667, 0.0009],\n",
      "        [0.5131, 0.3238, 0.0774, 0.0667, 0.0009]], device='cuda:0',\n",
      "       grad_fn=<SigmoidBackward0>)\n",
      "Generated distances:\n",
      "tensor([[0.9756],\n",
      "        [0.9756],\n",
      "        [0.9756],\n",
      "        [0.9756],\n",
      "        [0.9756],\n",
      "        [0.9756],\n",
      "        [0.9756],\n",
      "        [0.9756],\n",
      "        [0.9756],\n",
      "        [0.9756],\n",
      "        [0.9756],\n",
      "        [0.9756],\n",
      "        [0.9756],\n",
      "        [0.9756],\n",
      "        [0.9756],\n",
      "        [0.9756],\n",
      "        [0.9756],\n",
      "        [0.9756],\n",
      "        [0.9756],\n",
      "        [0.9756]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Generated directions:\n",
      "tensor([[ 0.5079,  0.3173, -0.8008],\n",
      "        [ 0.5079,  0.3173, -0.8008],\n",
      "        [ 0.5079,  0.3173, -0.8008],\n",
      "        [ 0.5079,  0.3173, -0.8008],\n",
      "        [ 0.5079,  0.3173, -0.8008],\n",
      "        [ 0.5079,  0.3173, -0.8008],\n",
      "        [ 0.5079,  0.3173, -0.8008],\n",
      "        [ 0.5079,  0.3173, -0.8008],\n",
      "        [ 0.5079,  0.3173, -0.8008],\n",
      "        [ 0.5079,  0.3173, -0.8008],\n",
      "        [ 0.5079,  0.3173, -0.8008],\n",
      "        [ 0.5079,  0.3173, -0.8008],\n",
      "        [ 0.5079,  0.3173, -0.8008],\n",
      "        [ 0.5079,  0.3173, -0.8008],\n",
      "        [ 0.5079,  0.3173, -0.8008],\n",
      "        [ 0.5079,  0.3173, -0.8008],\n",
      "        [ 0.5079,  0.3173, -0.8008],\n",
      "        [ 0.5079,  0.3173, -0.8008],\n",
      "        [ 0.5079,  0.3173, -0.8008],\n",
      "        [ 0.5079,  0.3173, -0.8008]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Generated edge features:\n",
      "tensor([[2.5264e-01, 4.0718e-02, 2.3968e-02, 9.3076e-05],\n",
      "        [2.5264e-01, 4.0718e-02, 2.3968e-02, 9.3076e-05],\n",
      "        [2.5264e-01, 4.0718e-02, 2.3968e-02, 9.3076e-05],\n",
      "        [2.5264e-01, 4.0718e-02, 2.3968e-02, 9.3076e-05],\n",
      "        [2.5264e-01, 4.0718e-02, 2.3968e-02, 9.3076e-05],\n",
      "        [2.5264e-01, 4.0718e-02, 2.3968e-02, 9.3076e-05],\n",
      "        [2.5264e-01, 4.0718e-02, 2.3968e-02, 9.3076e-05],\n",
      "        [2.5264e-01, 4.0718e-02, 2.3968e-02, 9.3076e-05],\n",
      "        [2.5264e-01, 4.0718e-02, 2.3968e-02, 9.3076e-05],\n",
      "        [2.5264e-01, 4.0718e-02, 2.3968e-02, 9.3076e-05],\n",
      "        [2.5264e-01, 4.0718e-02, 2.3968e-02, 9.3076e-05],\n",
      "        [2.5264e-01, 4.0718e-02, 2.3968e-02, 9.3076e-05],\n",
      "        [2.5264e-01, 4.0718e-02, 2.3968e-02, 9.3076e-05],\n",
      "        [2.5264e-01, 4.0718e-02, 2.3968e-02, 9.3076e-05],\n",
      "        [2.5264e-01, 4.0718e-02, 2.3968e-02, 9.3076e-05],\n",
      "        [2.5264e-01, 4.0718e-02, 2.3968e-02, 9.3076e-05],\n",
      "        [2.5264e-01, 4.0718e-02, 2.3968e-02, 9.3076e-05],\n",
      "        [2.5264e-01, 4.0718e-02, 2.3968e-02, 9.3076e-05],\n",
      "        [2.5264e-01, 4.0718e-02, 2.3968e-02, 9.3076e-05],\n",
      "        [2.5264e-01, 4.0718e-02, 2.3968e-02, 9.3076e-05]], device='cuda:0',\n",
      "       grad_fn=<SigmoidBackward0>)\n",
      "Generated num_nodes:\n",
      "tensor([5.0497], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "Generated mu:\n",
      "tensor([[-1.4931, -1.1431, -0.6427,  3.0384,  5.1735, -2.8455,  5.3105,  4.4994,\n",
      "          5.1331, -0.5789,  5.2715,  2.6913,  4.9612,  0.0303, -3.9811,  4.3022,\n",
      "         -1.9181, -4.7709, -1.6884, -1.4698,  3.2799,  0.2863, -1.5041, -3.2124,\n",
      "          1.4911, -0.8922,  3.1198,  1.8566, -3.1737, -5.3321, -0.7464,  1.9608]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "Generated log_var:\n",
      "tensor([[ -9.7594, -12.1989, -11.7337,  -8.4646, -12.7572, -10.8528, -14.3956,\n",
      "         -13.9251, -13.2693, -12.6329, -13.7991, -12.1467, -13.0779, -11.5100,\n",
      "         -14.7007, -14.1452, -10.6760, -13.8893,  -9.8134, -12.9918, -13.1495,\n",
      "          -8.3689, -11.0950, -13.5496,  -7.2385, -10.6251, -14.5129, -13.5778,\n",
      "         -13.5402, -14.1881, -12.4261, -11.4211]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Generated property prediction:\n",
      "tensor([[0.3805]], device='cuda:0', grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Print the generated node features\n",
    "print(\"Generated node features:\")\n",
    "print(node_features)\n",
    "print(\"Generated distances:\")\n",
    "print(distances)\n",
    "print(\"Generated directions:\")\n",
    "print(directions)\n",
    "print(\"Generated edge features:\")\n",
    "print(edge_features)\n",
    "print(\"Generated num_nodes:\")\n",
    "print(num_nodes)\n",
    "print(\"Generated mu:\")\n",
    "print(mu)\n",
    "print(\"Generated log_var:\")\n",
    "print(log_var)\n",
    "print(\"Generated property prediction:\")\n",
    "print(property_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/3dmoljs_load.v0": "<div id=\"3dmolviewer_1745179532531168\"  style=\"position: relative; width: 300px; height: 300px;\">\n        <p id=\"3dmolwarning_1745179532531168\" style=\"background-color:#ffcccc;color:black\">3Dmol.js failed to load for some reason.  Please check your browser console for error messages.<br></p>\n        </div>\n<script>\n\nvar loadScriptAsync = function(uri){\n  return new Promise((resolve, reject) => {\n    //this is to ignore the existence of requirejs amd\n    var savedexports, savedmodule;\n    if (typeof exports !== 'undefined') savedexports = exports;\n    else exports = {}\n    if (typeof module !== 'undefined') savedmodule = module;\n    else module = {}\n\n    var tag = document.createElement('script');\n    tag.src = uri;\n    tag.async = true;\n    tag.onload = () => {\n        exports = savedexports;\n        module = savedmodule;\n        resolve();\n    };\n  var firstScriptTag = document.getElementsByTagName('script')[0];\n  firstScriptTag.parentNode.insertBefore(tag, firstScriptTag);\n});\n};\n\nif(typeof $3Dmolpromise === 'undefined') {\n$3Dmolpromise = null;\n  $3Dmolpromise = loadScriptAsync('https://cdnjs.cloudflare.com/ajax/libs/3Dmol/2.4.2/3Dmol-min.js');\n}\n\nvar viewer_1745179532531168 = null;\nvar warn = document.getElementById(\"3dmolwarning_1745179532531168\");\nif(warn) {\n    warn.parentNode.removeChild(warn);\n}\n$3Dmolpromise.then(function() {\nviewer_1745179532531168 = $3Dmol.createViewer(document.getElementById(\"3dmolviewer_1745179532531168\"),{backgroundColor:\"white\"});\nviewer_1745179532531168.zoomTo();\n\tviewer_1745179532531168.addModel(\"\\n     RDKit          3D\\n\\n  5  4  0  0  0  0  0  0  0  0999 V2000\\n    0.0000   -0.0000   -0.0000 C   0  0  0  0  0  0  0  0  0  0  0  0\\n   -0.5762   -0.1871    0.9088 H   0  0  0  0  0  0  0  0  0  0  0  0\\n    0.4536    0.9920    0.0543 H   0  0  0  0  0  0  0  0  0  0  0  0\\n   -0.6616   -0.0508   -0.8675 H   0  0  0  0  0  0  0  0  0  0  0  0\\n    0.7842   -0.7542   -0.0956 H   0  0  0  0  0  0  0  0  0  0  0  0\\n  1  2  1  0\\n  1  3  1  0\\n  1  4  1  0\\n  1  5  1  0\\nM  END\\n\",\"mol\");\n\tviewer_1745179532531168.setStyle({\"stick\": {}});\n\tviewer_1745179532531168.zoomTo();\nviewer_1745179532531168.render();\n});\n</script>",
      "text/html": [
       "<div id=\"3dmolviewer_1745179532531168\"  style=\"position: relative; width: 300px; height: 300px;\">\n",
       "        <p id=\"3dmolwarning_1745179532531168\" style=\"background-color:#ffcccc;color:black\">3Dmol.js failed to load for some reason.  Please check your browser console for error messages.<br></p>\n",
       "        </div>\n",
       "<script>\n",
       "\n",
       "var loadScriptAsync = function(uri){\n",
       "  return new Promise((resolve, reject) => {\n",
       "    //this is to ignore the existence of requirejs amd\n",
       "    var savedexports, savedmodule;\n",
       "    if (typeof exports !== 'undefined') savedexports = exports;\n",
       "    else exports = {}\n",
       "    if (typeof module !== 'undefined') savedmodule = module;\n",
       "    else module = {}\n",
       "\n",
       "    var tag = document.createElement('script');\n",
       "    tag.src = uri;\n",
       "    tag.async = true;\n",
       "    tag.onload = () => {\n",
       "        exports = savedexports;\n",
       "        module = savedmodule;\n",
       "        resolve();\n",
       "    };\n",
       "  var firstScriptTag = document.getElementsByTagName('script')[0];\n",
       "  firstScriptTag.parentNode.insertBefore(tag, firstScriptTag);\n",
       "});\n",
       "};\n",
       "\n",
       "if(typeof $3Dmolpromise === 'undefined') {\n",
       "$3Dmolpromise = null;\n",
       "  $3Dmolpromise = loadScriptAsync('https://cdnjs.cloudflare.com/ajax/libs/3Dmol/2.4.2/3Dmol-min.js');\n",
       "}\n",
       "\n",
       "var viewer_1745179532531168 = null;\n",
       "var warn = document.getElementById(\"3dmolwarning_1745179532531168\");\n",
       "if(warn) {\n",
       "    warn.parentNode.removeChild(warn);\n",
       "}\n",
       "$3Dmolpromise.then(function() {\n",
       "viewer_1745179532531168 = $3Dmol.createViewer(document.getElementById(\"3dmolviewer_1745179532531168\"),{backgroundColor:\"white\"});\n",
       "viewer_1745179532531168.zoomTo();\n",
       "\tviewer_1745179532531168.addModel(\"\\n     RDKit          3D\\n\\n  5  4  0  0  0  0  0  0  0  0999 V2000\\n    0.0000   -0.0000   -0.0000 C   0  0  0  0  0  0  0  0  0  0  0  0\\n   -0.5762   -0.1871    0.9088 H   0  0  0  0  0  0  0  0  0  0  0  0\\n    0.4536    0.9920    0.0543 H   0  0  0  0  0  0  0  0  0  0  0  0\\n   -0.6616   -0.0508   -0.8675 H   0  0  0  0  0  0  0  0  0  0  0  0\\n    0.7842   -0.7542   -0.0956 H   0  0  0  0  0  0  0  0  0  0  0  0\\n  1  2  1  0\\n  1  3  1  0\\n  1  4  1  0\\n  1  5  1  0\\nM  END\\n\",\"mol\");\n",
       "\tviewer_1745179532531168.setStyle({\"stick\": {}});\n",
       "\tviewer_1745179532531168.zoomTo();\n",
       "viewer_1745179532531168.render();\n",
       "});\n",
       "</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<py3Dmol.view at 0x7fd40204b620>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mygenai.utils.visualisation import visualise_molecule\n",
    "visualise_molecule(test_molecule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-20 22:15:35,154 - PropertyConditionedVAE - DEBUG - Input data - batch_size: 100, nodes: 1005\n",
      "2025-04-20 22:15:35,154 - PropertyConditionedVAE - DEBUG - Forward called without target_property (None)\n",
      "2025-04-20 22:15:35,157 - PropertyConditionedVAE - DEBUG - Encoder outputs - mu: torch.Size([100, 32]), log_var: torch.Size([100, 32]), property_pred: torch.Size([100, 1])\n",
      "2025-04-20 22:15:35,158 - PropertyConditionedVAE - DEBUG - Sampled z shape: torch.Size([100, 32])\n",
      "2025-04-20 22:15:35,158 - PropertyConditionedVAE - DEBUG - Using encoder prediction for property, shape: torch.Size([100, 1])\n",
      "2025-04-20 22:15:35,161 - PropertyConditionedVAE - DEBUG - Decoder outputs - node_features: torch.Size([1005, 5]), distances: torch.Size([10070, 1]), directions: torch.Size([10070, 3]), edge_features: torch.Size([10070, 4]), num_nodes: tensor([ 5.0497,  4.1476,  3.2143,  3.9463,  2.7335,  3.9900,  8.1959,  6.0648,\n",
      "         7.1128,  6.0964,  7.1026,  6.1230, 11.0618,  9.1959,  9.2088,  9.1748,\n",
      "         7.0867, 10.1681,  9.2303,  8.2218, 14.1310, 12.1423,  6.0138,  5.0495,\n",
      "         3.9108,  6.0440,  5.1101,  6.0573, 10.2043, 10.1809,  9.2224,  8.1946,\n",
      "         8.1760,  7.1230, 10.1608,  9.2309,  8.1667,  8.1545, 14.1338, 12.1415,\n",
      "        12.1465, 10.1613, 12.1187, 10.1624, 11.1417, 10.1526, 12.1156, 10.1552,\n",
      "        12.1653, 10.1503,  9.1841,  9.1720,  8.1120, 17.1554, 15.1755,  9.1902,\n",
      "         8.1200,  8.1405,  9.2026,  8.1552, 13.1370, 12.1617, 11.1665, 11.1458,\n",
      "        10.1755, 13.1500, 11.1680, 12.1636, 11.1707, 13.1431, 12.1702, 12.1610,\n",
      "        11.1906, 12.1634, 11.1786, 10.1961, 10.1898, 15.1739, 13.1523, 17.1544,\n",
      "        15.1722, 15.1728, 15.1740, 13.1476, 13.1484, 10.1714, 11.1346, 10.1659,\n",
      "         9.1858, 10.1652,  9.1915, 15.1721, 13.1461, 13.1484, 13.1493, 11.1659,\n",
      "        15.1720, 13.1467, 14.1443, 13.1445], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# import importlib\n",
    "# import mygenai.models.graphvae\n",
    "# from mygenai.models.graphvae import PropertyConditionedVAE\n",
    "# importlib.reload(mygenai.models.graphvae)\n",
    "logging.getLogger('PropertyConditionedVAE').setLevel(logging.DEBUG)\n",
    "batch_data = dataset[:100]\n",
    "batch = Batch.from_data_list(batch_data).to(device)\n",
    "with torch.no_grad():  # Disable gradient computation\n",
    "    outputs = model(batch)\n",
    "node_features, distances, directions, edge_features, num_nodes, mu, log_var, property_pred = outputs\n",
    "\n",
    "# Compute the loss\n",
    "loss = model.loss_function(\n",
    "    node_features=node_features,\n",
    "    distances=distances,\n",
    "    directions=directions,\n",
    "    edge_features=edge_features,\n",
    "    num_nodes=num_nodes,\n",
    "    data=batch,\n",
    "    mu=mu,\n",
    "    log_var=log_var,\n",
    "    property_pred=property_pred,\n",
    "    property_weight=property_weight,  # Use the same weights as during training\n",
    "    recon_weight=recon_weight,\n",
    "    kl_weight=kl_weight\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
