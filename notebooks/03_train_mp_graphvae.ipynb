{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Message-Passing Graph Variational Autoencoder\n",
    "\n",
    "Here I will use principles from message-passing graph neural networks to try to generate\n",
    "molecules in a graph variational autoencoder. This is based on my solutions to \n",
    "`geometric-gnn-dojo/geometric_gnn_101.ipynb`\n",
    "Some of the code has also been taken from there\n",
    "\n",
    "might also want to consider autoregressive model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version 2.5.0+cu124\n",
      "PyG version 2.6.1\n"
     ]
    }
   ],
   "source": [
    "#@title [RUN] Import python modules\n",
    "\n",
    "import logging\n",
    "\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "from scipy.stats import ortho_group\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Linear, ReLU, BatchNorm1d, Module, Sequential, Sigmoid\n",
    "\n",
    "import torch_geometric\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.data import Batch\n",
    "from torch_geometric.datasets import QM9\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.utils import remove_self_loops, to_dense_adj, dense_to_sparse\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import MessagePassing, global_mean_pool\n",
    "from torch_geometric.datasets import QM9\n",
    "from torch_scatter import scatter\n",
    "\n",
    "import rdkit.Chem as Chem\n",
    "from rdkit.Geometry.rdGeometry import Point3D\n",
    "from rdkit.Chem import QED, Crippen, rdMolDescriptors, rdmolops\n",
    "from rdkit.Chem.Draw import IPythonConsole\n",
    "\n",
    "import py3Dmol\n",
    "from rdkit.Chem import AllChem\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# from google.colab import files\n",
    "from IPython.display import HTML\n",
    "\n",
    "print(\"PyTorch version {}\".format(torch.__version__))\n",
    "print(\"PyG version {}\".format(torch_geometric.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Debug mode is OFF\n"
     ]
    }
   ],
   "source": [
    "debug_print = False\n",
    "if debug_print:\n",
    "    print(\"Debug mode is ON\")\n",
    "    logging.basicConfig(\n",
    "        level=logging.DEBUG,\n",
    "        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "        force=True  # Ensure configuration is applied\n",
    "    )\n",
    "    for logger_name in ['train_epoch', 'PropertyConditionedVAE', 'ConditionalDecoder', 'Encoder']:\n",
    "        logging.getLogger(logger_name).setLevel(logging.DEBUG)\n",
    "else:\n",
    "    print(\"Debug mode is OFF\")\n",
    "    logging.basicConfig(\n",
    "        level=logging.INFO,\n",
    "        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "        force=True  # Ensure configuration is applied\n",
    "    )\n",
    "    for logger_name in ['train_epoch', 'PropertyConditionedVAE', 'ConditionalDecoder', 'Encoder']:\n",
    "        logging.getLogger(logger_name).setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CompleteGraph(object):\n",
    "    \"\"\"\n",
    "    This transform adds all pairwise edges into the edge index per data sample,\n",
    "    then removes self loops, i.e. it builds a fully connected or complete graph\n",
    "    \"\"\"\n",
    "    def __call__(self, data):\n",
    "        device = data.edge_index.device\n",
    "\n",
    "        row = torch.arange(data.num_nodes, dtype=torch.long, device=device)\n",
    "        col = torch.arange(data.num_nodes, dtype=torch.long, device=device)\n",
    "\n",
    "        row = row.view(-1, 1).repeat(1, data.num_nodes).view(-1)\n",
    "        col = col.repeat(data.num_nodes)\n",
    "        edge_index = torch.stack([row, col], dim=0)\n",
    "\n",
    "        edge_attr = None\n",
    "        if data.edge_attr is not None:\n",
    "            idx = data.edge_index[0] * data.num_nodes + data.edge_index[1]\n",
    "            size = list(data.edge_attr.size())\n",
    "            size[0] = data.num_nodes * data.num_nodes\n",
    "            edge_attr = data.edge_attr.new_zeros(size)\n",
    "            edge_attr[idx] = data.edge_attr\n",
    "\n",
    "        edge_index, edge_attr = remove_self_loops(edge_index, edge_attr)\n",
    "        data.edge_attr = edge_attr\n",
    "        data.edge_index = edge_index\n",
    "\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch_geometric.utils import to_dense_batch\n",
    "import torch_geometric as pyg\n",
    "import torch_geometric.nn as pyg_nn\n",
    "from torch_geometric.datasets import QM9\n",
    "from torch_geometric.loader import DataLoader\n",
    "import mygenai\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "dataset = QM9(root=\"../data/QM9\", transform=CompleteGraph())\n",
    "# Normalize targets per data sample to mean = 0 and std = 1.\n",
    "mean = dataset.data.y.mean(dim=0, keepdim=True)\n",
    "std = dataset.data.y.std(dim=0, keepdim=True)\n",
    "dataset.data.y = (dataset.data.y - mean) / std\n",
    "# mean, std = mean[:, target].item(), std[:, target].item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First, some review\n",
    "This is the non-generative model that simply predicts properties based on input "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:3: SyntaxWarning: invalid escape sequence '\\o'\n",
      "<>:3: SyntaxWarning: invalid escape sequence '\\o'\n",
      "/tmp/ipykernel_71418/3876908471.py:3: SyntaxWarning: invalid escape sequence '\\o'\n",
      "  \"\"\"Message Passing Neural Network Layer\n"
     ]
    }
   ],
   "source": [
    "class EquivariantMPNNLayer(MessagePassing):\n",
    "    def __init__(self, emb_dim=64, edge_dim=4, aggr='add'):\n",
    "        \"\"\"Message Passing Neural Network Layer\n",
    "\n",
    "        This layer is equivariant to 3D rotations and translations.\n",
    "\n",
    "        Args:\n",
    "            emb_dim: (int) - hidden dimension `d`\n",
    "            edge_dim: (int) - edge feature dimension `d_e`\n",
    "            aggr: (str) - aggregation function `\\oplus` (sum/mean/max)\n",
    "        \"\"\"\n",
    "        # Set the aggregation function\n",
    "        super().__init__(aggr=aggr)\n",
    "\n",
    "        self.emb_dim = emb_dim\n",
    "        self.edge_dim = edge_dim\n",
    "\n",
    "        self.mlp_scalar = Sequential(\n",
    "            Linear(2*emb_dim + edge_dim + 1, emb_dim),  # +1 for distance\n",
    "            BatchNorm1d(emb_dim),\n",
    "            ReLU()\n",
    "        )\n",
    "        self.mlp_vector = Sequential(\n",
    "            Linear(2*emb_dim + edge_dim + 1, 1),  # Input: [h_i, h_j, edge_attr, dist]\n",
    "            BatchNorm1d(1),\n",
    "            ReLU()\n",
    "        )\n",
    "\n",
    "        # update MLPs\n",
    "        self.mlp_h = Sequential(\n",
    "            Linear(2*emb_dim, emb_dim), BatchNorm1d(emb_dim), ReLU(),\n",
    "            Linear(emb_dim, emb_dim), BatchNorm1d(emb_dim), ReLU()\n",
    "        )\n",
    "        self.mlp_pos = Sequential(\n",
    "            Linear(emb_dim, emb_dim), BatchNorm1d(emb_dim), ReLU(),\n",
    "            Linear(emb_dim, 1), BatchNorm1d(1), ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, h, pos, edge_index, edge_attr):\n",
    "        \"\"\"\n",
    "        The forward pass updates node features `h` via one round of message passing.\n",
    "\n",
    "        Args:\n",
    "            h: (n, d) - initial node features\n",
    "            pos: (n, 3) - initial node coordinates\n",
    "            edge_index: (e, 2) - pairs of edges (i, j)\n",
    "            edge_attr: (e, d_e) - edge features\n",
    "\n",
    "        Returns:\n",
    "            out: [(n, d),(n,3)] - updated node features\n",
    "        \"\"\"\n",
    "        return self.propagate(edge_index, h=h, pos=pos, edge_attr=edge_attr)\n",
    "\n",
    "    def message(self, h_i, h_j, pos_i, pos_j, edge_attr):\n",
    "        r_ij = pos_j - pos_i # equivariant\n",
    "        dist = torch.norm(r_ij, dim=-1, keepdim=True)  # invariant\n",
    "\n",
    "        # Scalar message (invariant features)\n",
    "        scalar_inputs = torch.cat([h_i, h_j, edge_attr, dist], dim=-1)\n",
    "        scalar_msg = self.mlp_scalar(scalar_inputs)\n",
    "\n",
    "        # Vector message (equivariant coordinates)\n",
    "        # vector message should only depend on rotation/translation invariant quantities\n",
    "        vector_inputs = torch.cat([h_i, h_j, edge_attr, dist], dim=-1)\n",
    "        scale = self.mlp_vector(vector_inputs) # (e, 1)\n",
    "        vector_msg = scale * r_ij # (e, 3)\n",
    "\n",
    "        return scalar_msg, vector_msg\n",
    "\n",
    "    def aggregate(self, inputs, index):\n",
    "        scalar_msgs, vector_msgs = inputs\n",
    "        scalar_aggr = scatter(scalar_msgs, index, dim=self.node_dim, reduce=self.aggr)\n",
    "        vector_aggr = scatter(vector_msgs, index, dim=self.node_dim, reduce=self.aggr)\n",
    "        return scalar_aggr, vector_aggr\n",
    "\n",
    "    def update(self, aggr_out, h, pos):\n",
    "        scalar_aggr, vector_aggr = aggr_out\n",
    "\n",
    "        # Update node features (h)\n",
    "        h_update = self.mlp_h(torch.cat([h, scalar_aggr], dim=-1))\n",
    "\n",
    "        # Update node positions (pos)\n",
    "        scale = self.mlp_pos(scalar_aggr) # (n, 1)\n",
    "        pos_update = pos + scale * vector_aggr  # (n, 3)\n",
    "\n",
    "        return h_update, pos_update\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return (f'{self.__class__.__name__}(emb_dim={self.emb_dim}, aggr={self.aggr})')\n",
    "\n",
    "\n",
    "class EquivariantGNNPredictor(Module):\n",
    "    def __init__(self, num_layers=4, emb_dim=64, in_dim=11, edge_dim=4, out_dim=1):\n",
    "        \"\"\"Message Passing Neural Network model for graph property prediction\n",
    "\n",
    "        This model uses both node features and coordinates as inputs, and\n",
    "        is invariant to 3D rotations and translations (the constituent MPNN layers\n",
    "        are equivariant to 3D rotations and translations).\n",
    "\n",
    "        Args:\n",
    "            num_layers: (int) - number of message passing layers `L`\n",
    "            emb_dim: (int) - hidden dimension `d`\n",
    "            in_dim: (int) - initial node feature dimension `d_n`\n",
    "            edge_dim: (int) - edge feature dimension `d_e`\n",
    "            out_dim: (int) - output dimension (fixed to 1)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        # Linear projection for initial node features\n",
    "        # dim: d_n -> d\n",
    "        self.lin_in = Linear(in_dim, emb_dim)\n",
    "\n",
    "        # Stack of MPNN layers\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        for layer in range(num_layers):\n",
    "            self.convs.append(EquivariantMPNNLayer(emb_dim, edge_dim, aggr='add'))\n",
    "\n",
    "        # Global pooling/readout function `R` (mean pooling)\n",
    "        # PyG handles the underlying logic via `global_mean_pool()`\n",
    "        self.pool = global_mean_pool\n",
    "\n",
    "        # Linear prediction head\n",
    "        # dim: d -> out_dim\n",
    "        self.lin_pred = Linear(emb_dim, out_dim)\n",
    "\n",
    "    def forward(self, data):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            data: (PyG.Data) - batch of PyG graphs\n",
    "\n",
    "        Returns:\n",
    "            out: (batch_size, out_dim) - prediction for each graph\n",
    "        \"\"\"\n",
    "        h = self.lin_in(data.x) # (n, d_n) -> (n, d)\n",
    "        pos = data.pos\n",
    "\n",
    "        for conv in self.convs:\n",
    "            # Message passing layer\n",
    "            h_update, pos_update = conv(h, pos, data.edge_index, data.edge_attr)\n",
    "\n",
    "            # Update node features\n",
    "            h = h + h_update # (n, d) -> (n, d)\n",
    "            # Note that we add a residual connection after each MPNN layer\n",
    "\n",
    "            # Update node coordinates\n",
    "            pos = pos_update # (n, 3) -> (n, 3)\n",
    "\n",
    "        h_graph = self.pool(h, data.batch) # (n, d) -> (batch_size, d)\n",
    "\n",
    "        out = self.lin_pred(h_graph) # (batch_size, d) -> (batch_size, 1)\n",
    "\n",
    "        return out.view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EquivariantGNNPredictor(num_layers=4, emb_dim=64, in_dim=11, edge_dim=4, out_dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unit test\n",
    "def random_orthogonal_matrix(dim=3):\n",
    "  \"\"\"Helper function to build a random orthogonal matrix of shape (dim, dim)\n",
    "  \"\"\"\n",
    "  Q = torch.tensor(ortho_group.rvs(dim=dim)).float()\n",
    "  return Q\n",
    "\n",
    "def random_orthogonal_matrix(dim=3):\n",
    "  \"\"\"Helper function to build a random orthogonal matrix of shape (dim, dim)\n",
    "  \"\"\"\n",
    "  Q = torch.tensor(ortho_group.rvs(dim=dim)).float()\n",
    "  return Q\n",
    "\n",
    "\n",
    "def rot_trans_invariance_unit_test(module, dataloader):\n",
    "    \"\"\"Unit test for checking whether a module (GNN model/layer) is\n",
    "    rotation and translation invariant.\n",
    "    \"\"\"\n",
    "    it = iter(dataloader)\n",
    "    data = next(it)\n",
    "\n",
    "    # Forward pass on original example\n",
    "    # Note: We have written a conditional forward pass so that the same unit\n",
    "    #       test can be used for both the GNN model as well as the layer.\n",
    "    #       The functionality for layers will be useful subsequently.\n",
    "    # if isinstance(module, MPNNModel):\n",
    "    out_1 = module(data)\n",
    "    # else: # if ininstance(module, MessagePassing):\n",
    "        # out_1 = module(data.x, data.pos, data.edge_index, data.edge_attr)\n",
    "\n",
    "    Q = random_orthogonal_matrix(dim=3)\n",
    "    t = torch.rand(3)\n",
    "    # ============ YOUR CODE HERE ==============\n",
    "    # Perform random rotation + translation on data.\n",
    "    #\n",
    "    data.pos = data.pos @ Q  + t\n",
    "    # ==========================================\n",
    "\n",
    "    # Forward pass on rotated + translated example\n",
    "    # if isinstance(module, MPNNModel):\n",
    "    out_2 = module(data)\n",
    "    # else: # if ininstance(module, MessagePassing):\n",
    "        # out_2 = module(data.x, data.pos, data.edge_index, data.edge_attr)\n",
    "\n",
    "    # ============ YOUR CODE HERE ==============\n",
    "    # Check whether output varies after applying transformations.\n",
    "    #\n",
    "    return torch.allclose(out_1, out_2, atol=1e-04)\n",
    "    # ==========================================\n",
    "\n",
    "def rot_trans_equivariance_unit_test(module, dataloader):\n",
    "    \"\"\"Unit test for checking whether a module (GNN layer) is\n",
    "    rotation and translation equivariant.\n",
    "    \"\"\"\n",
    "    it = iter(dataloader)\n",
    "    data = next(it)\n",
    "\n",
    "    out_1, pos_1 = module(data.x, data.pos, data.edge_index, data.edge_attr)\n",
    "\n",
    "    Q = random_orthogonal_matrix(dim=3)\n",
    "    t = torch.rand(3)\n",
    "    # ============ YOUR CODE HERE ==============\n",
    "    # Perform random rotation + translation on data.\n",
    "    #\n",
    "    data.pos = data.pos @ Q + t # row vectors => post-multiply Q\n",
    "    # ==========================================\n",
    "\n",
    "    # Forward pass on rotated + translated example\n",
    "    out_2, pos_2 = module(data.x, data.pos, data.edge_index, data.edge_attr)\n",
    "\n",
    "    # ============ YOUR CODE HERE ==============\n",
    "    # Check whether output varies after applying transformations.\n",
    "    return torch.allclose(out_1, out_2, atol=1e-04) and torch.allclose(pos_1 @ Q + t, pos_2, atol=1e-04)\n",
    "    # =========================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is EquivariantGNNPredictor rotation and translation invariant? --> True!\n",
      "Is EquivariantMPNNLayer rotation and translation equivariant? --> True!\n"
     ]
    }
   ],
   "source": [
    "# ============ YOUR CODE HERE ==============\n",
    "# Instantiate temporary model, layer, and dataloader for unit testing.\n",
    "# Remember that we are now unit testing the EquivariantGNNPredictor,\n",
    "# which is  composed of the EquivariantMPNNLayer.\n",
    "#\n",
    "layer = EquivariantMPNNLayer(emb_dim=11, edge_dim=4)\n",
    "model = EquivariantGNNPredictor(num_layers=4, emb_dim=64, in_dim=11, edge_dim=4, out_dim=1)\n",
    "# ==========================================\n",
    "dataloader = DataLoader(dataset[:1000], batch_size=1, shuffle=True)\n",
    "\n",
    "# Rotation and translation invariance unit test for MPNN model\n",
    "print(f\"Is {type(model).__name__} rotation and translation invariant? --> {rot_trans_invariance_unit_test(model, dataloader)}!\")\n",
    "\n",
    "# Rotation and translation invariance unit test for MPNN layer\n",
    "print(f\"Is {type(layer).__name__} rotation and translation equivariant? --> {rot_trans_equivariance_unit_test(layer, dataloader)}!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now trying an encoder-decoder architecture\n",
    "class Encoder(Module):\n",
    "    def __init__(self, emb_dim=64, in_dim=11, edge_dim=4, latent_dim=32):\n",
    "        \"\"\"Encoder module for graph property prediction\n",
    "\n",
    "        Args:\n",
    "            emb_dim: (int) - hidden dimension `d`\n",
    "            in_dim: (int) - initial node feature dimension `d_n`\n",
    "            edge_dim: (int) - edge feature dimension `d_e`\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        # Linear projection for initial node features\n",
    "        # dim: d_n -> d\n",
    "        self.lin_in = Linear(in_dim, emb_dim)\n",
    "\n",
    "        # Stack of MPNN layers\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        for layer in range(2):\n",
    "            self.convs.append(EquivariantMPNNLayer(emb_dim, edge_dim, aggr='add'))\n",
    "\n",
    "        # Global pooling/readout function `R` (mean pooling)\n",
    "        # PyG handles the underlying logic via `global_mean_pool()`\n",
    "        self.pool = global_mean_pool\n",
    "\n",
    "        # projections to latent space\n",
    "        self.mu = Linear(emb_dim, latent_dim)\n",
    "        self.log_var = Linear(emb_dim, latent_dim)\n",
    "\n",
    "        # Property prediction\n",
    "        self.property_predictor = Sequential(\n",
    "            Linear(latent_dim, emb_dim),\n",
    "            ReLU(),\n",
    "            BatchNorm1d(emb_dim),\n",
    "            Linear(emb_dim, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, data):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            data: (PyG.Data) - batch of PyG graphs\n",
    "\n",
    "        Returns:\n",
    "            out: [(batch_size, d),(batch_size,3)] - updated node features\n",
    "        \"\"\"\n",
    "        h = self.lin_in(data.x) # (n, d_n) -> (n, d)\n",
    "        pos = data.pos\n",
    "\n",
    "        for conv in self.convs:\n",
    "            # Message passing layer\n",
    "            h_update, pos_update = conv(h, pos, data.edge_index, data.edge_attr)\n",
    "\n",
    "            # Update node features\n",
    "            h = h + h_update # (n, d) -> (n, d)\n",
    "\n",
    "            # Update node coordinates\n",
    "            pos = pos_update # (n, 3) -> (n, 3)\n",
    "\n",
    "        # Pool to graph level\n",
    "        h_graph = self.pool(h, data.batch) # (n, d) -> (batch_size, d)\n",
    "\n",
    "        # Get latent parameters and property prediction\n",
    "        mu = self.mu(h_graph)\n",
    "        log_var = self.log_var(h_graph)\n",
    "        property_pred = self.property_predictor(mu)\n",
    "\n",
    "        return self.mu(h_graph), log_var, property_pred\n",
    "\n",
    "class ConditionalDecoder(Module):\n",
    "    def __init__(self, latent_dim=32, emb_dim=64, out_node_dim=11, out_edge_dim=4):\n",
    "        super().__init__()\n",
    "        self.logger = logging.getLogger(self.__class__.__name__)\n",
    "\n",
    "        # Initial projection from latent+property space\n",
    "        self.lin_latent = Linear(latent_dim + 1, emb_dim)\n",
    "\n",
    "        # Node feature generation\n",
    "        self.node_decoder = Sequential(\n",
    "            Linear(emb_dim, emb_dim),\n",
    "            ReLU(),\n",
    "            BatchNorm1d(emb_dim),\n",
    "            Linear(emb_dim, out_node_dim)\n",
    "        )\n",
    "\n",
    "        # Position generation\n",
    "        self.pos_decoder = Sequential(\n",
    "            Linear(emb_dim, emb_dim),\n",
    "            ReLU(),\n",
    "            BatchNorm1d(emb_dim),\n",
    "            Linear(emb_dim, 3)\n",
    "        )\n",
    "\n",
    "        # Number of nodes predictor\n",
    "        self.num_nodes_predictor = Sequential(\n",
    "            Linear(emb_dim, emb_dim),\n",
    "            ReLU(),\n",
    "            Linear(emb_dim, 1)\n",
    "        )\n",
    "\n",
    "        # Edge prediction\n",
    "        self.edge_existence = Sequential(\n",
    "            Linear(2 * emb_dim, emb_dim),\n",
    "            ReLU(),\n",
    "            BatchNorm1d(emb_dim),\n",
    "            Linear(emb_dim, 1),\n",
    "            Sigmoid()\n",
    "        )\n",
    "\n",
    "        self.edge_features = Sequential(\n",
    "            Linear(2 * emb_dim, emb_dim),\n",
    "            ReLU(),\n",
    "            BatchNorm1d(emb_dim),\n",
    "            Linear(emb_dim, out_edge_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, z, target_property, batch_size):\n",
    "        self.logger.debug(f\"Input shapes - z: {z.shape}, target_property: {target_property.shape}\")\n",
    "\n",
    "        # Make sure target_property has correct shape for concatenation\n",
    "        if target_property.dim() == 3:\n",
    "            target_property = target_property.squeeze(1)\n",
    "        if target_property.dim() == 1:\n",
    "            target_property = target_property.unsqueeze(1)\n",
    "\n",
    "        z_cond = torch.cat([z, target_property], dim=1)\n",
    "        h = self.lin_latent(z_cond)\n",
    "\n",
    "        # Predict number of nodes per graph\n",
    "        num_nodes = self.num_nodes_predictor(h).sigmoid() * 30 + 5  # 5-35 nodes\n",
    "        num_nodes = num_nodes.long()\n",
    "\n",
    "        node_features_list = []\n",
    "        positions_list = []\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            n = num_nodes[i].item()  # Convert tensor to integer\n",
    "            h_expanded = h[i:i+1].expand(n, -1)\n",
    "\n",
    "            # Generate node features and positions\n",
    "            node_feat = self.node_decoder(h_expanded)\n",
    "            pos = self.pos_decoder(h_expanded)\n",
    "\n",
    "            node_features_list.append(node_feat)\n",
    "            positions_list.append(pos)\n",
    "\n",
    "        node_features = torch.cat(node_features_list, dim=0)\n",
    "        positions = torch.cat(positions_list, dim=0)\n",
    "\n",
    "        self.logger.debug(f\"Output shapes - node_features: {node_features.shape}, positions: {positions.shape}\")\n",
    "\n",
    "        return node_features, positions, num_nodes\n",
    "\n",
    "class PropertyConditionedVAE(Module):\n",
    "    def __init__(self, num_layers=4, emb_dim=64, in_dim=11, edge_dim=4, latent_dim=32):\n",
    "        super().__init__()\n",
    "        self.logger = logging.getLogger(self.__class__.__name__)\n",
    "\n",
    "        self.encoder = Encoder(emb_dim, in_dim, edge_dim, latent_dim)\n",
    "        self.decoder = ConditionalDecoder(latent_dim, emb_dim, in_dim)\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "    def reparameterize(self, mu, log_var):\n",
    "        if self.training:\n",
    "            std = torch.exp(0.5 * log_var)\n",
    "            eps = torch.randn_like(std)\n",
    "            return mu + eps * std\n",
    "        return mu\n",
    "\n",
    "    def forward(self, data, target_property=None):\n",
    "        logger = logging.getLogger('PropertyConditionedVAE')\n",
    "\n",
    "        # Encode\n",
    "        mu, log_var, property_pred = self.encoder(data)\n",
    "        logger.debug(f\"Encoder outputs - mu: {mu.shape}, log_var: {log_var.shape}, property_pred: {property_pred.shape}\")\n",
    "\n",
    "        # Sample from latent space\n",
    "        z = self.reparameterize(mu, log_var)\n",
    "        logger.debug(f\"Sampled z shape: {z.shape}\")\n",
    "\n",
    "        # Use predicted property if target not provided\n",
    "        if target_property is None:\n",
    "            target_property = property_pred\n",
    "        logger.debug(f\"Target property shape before squeeze: {target_property.shape}\")\n",
    "\n",
    "        # Ensure target_property is 2D\n",
    "        if len(target_property.shape) == 3:\n",
    "            target_property = target_property.squeeze(1)\n",
    "        logger.debug(f\"Target property shape after squeeze: {target_property.shape}\")\n",
    "\n",
    "        # Decode\n",
    "        node_features, positions, num_nodes = self.decoder(\n",
    "            z, target_property, data.batch.max().item() + 1\n",
    "        )\n",
    "        logger.debug(f\"Decoder outputs - features: {node_features.shape}, positions: {positions.shape}\")\n",
    "\n",
    "        return node_features, positions, mu, log_var, property_pred, num_nodes\n",
    "\n",
    "    def loss_function(self, node_features, positions, num_nodes, data, mu, log_var,\n",
    "                     property_pred, property_weight=1.0):\n",
    "        logger = logging.getLogger(self.__class__.__name__)\n",
    "\n",
    "        # Log shapes for debugging\n",
    "        logger.debug(f\"Property prediction shape: {property_pred.shape}\")\n",
    "        logger.debug(f\"Target property shape: {data.y.shape}\")\n",
    "\n",
    "        # Reconstruction loss (with proper masking for variable size graphs)\n",
    "        recon_loss = 0\n",
    "        start_idx = 0\n",
    "\n",
    "        for i, n in enumerate(num_nodes):\n",
    "            n_orig = (data.batch == i).sum()\n",
    "            n_gen = n.item()\n",
    "\n",
    "            # Node feature reconstruction\n",
    "            recon_loss += F.mse_loss(\n",
    "                node_features[start_idx:start_idx + min(n_gen, n_orig)],\n",
    "                data.x[data.batch == i][:min(n_gen, n_orig)]\n",
    "            )\n",
    "\n",
    "            # Position reconstruction\n",
    "            recon_loss += F.mse_loss(\n",
    "                positions[start_idx:start_idx + min(n_gen, n_orig)],\n",
    "                data.pos[data.batch == i][:min(n_gen, n_orig)]\n",
    "            )\n",
    "\n",
    "            start_idx += n_gen\n",
    "\n",
    "        # KL divergence\n",
    "        kl_loss = -0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n",
    "        kl_loss = kl_loss / data.batch.max().item()  # Normalize by batch size\n",
    "\n",
    "        # Property prediction loss - ensure shapes match\n",
    "        if len(data.y.shape) == 1:\n",
    "            data_y = data.y.unsqueeze(1)  # Make it [batch_size, 1]\n",
    "        else:\n",
    "            data_y = data.y\n",
    "\n",
    "        prop_loss = F.mse_loss(property_pred, data_y)\n",
    "\n",
    "        # Combine losses\n",
    "        total_loss = recon_loss + 0.1 * kl_loss + property_weight * prop_loss\n",
    "\n",
    "        logger.debug(f\"Losses - recon: {recon_loss:.4f}, KL: {kl_loss:.4f}, prop: {prop_loss:.4f}\")\n",
    "\n",
    "        return total_loss\n",
    "\n",
    "    def generate_molecule(self, target_property, num_samples=1):\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            # Sample from prior\n",
    "            z = torch.randn(num_samples, self.latent_dim).to(next(self.parameters()).device)\n",
    "            target = torch.ones(num_samples).to(z.device) * target_property\n",
    "\n",
    "            # Generate\n",
    "            node_features, positions, num_nodes = self.decoder(z, target, num_samples)\n",
    "\n",
    "            return node_features, positions, num_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data splitting (60/20/20)\n",
    "train_val_idx, test_idx = train_test_split(\n",
    "    np.arange(len(dataset)),\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "train_idx, val_idx = train_test_split(\n",
    "    train_val_idx,\n",
    "    test_size=0.25,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(dataset[train_idx], batch_size=128, shuffle=True)\n",
    "val_loader = DataLoader(dataset[val_idx], batch_size=128, shuffle=False)\n",
    "test_loader = DataLoader(dataset[test_idx], batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target property shape: torch.Size([128, 19])\n",
      "Target property sample: tensor([-0.2383, -0.0479, -0.3319, -0.7414, -0.5816, -0.1202, -0.4033, -0.2759,\n",
      "        -0.2760, -0.2760, -0.2759, -0.2214,  0.0731,  0.0751,  0.0771,  0.0519,\n",
      "        -0.0033, -0.1476, -0.0967])\n",
      "Input node features shape: torch.Size([2320, 11])\n",
      "Input positions shape: torch.Size([2320, 3])\n",
      "Number of nodes: 2320\n",
      "Batch size: 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_71418/2303556595.py:238: UserWarning: Using a target size (torch.Size([128, 19])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  prop_loss = F.mse_loss(property_pred, data_y)\n",
      "/tmp/ipykernel_71418/2303556595.py:238: UserWarning: Using a target size (torch.Size([34, 19])) that is different to the input size (torch.Size([34, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  prop_loss = F.mse_loss(property_pred, data_y)\n",
      "/tmp/ipykernel_71418/2303556595.py:238: UserWarning: Using a target size (torch.Size([54, 19])) that is different to the input size (torch.Size([54, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  prop_loss = F.mse_loss(property_pred, data_y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 000 | Train Loss: 497.3152 | Val Loss: 461866915.7463\n",
      "Epoch 001 | Train Loss: 7322.1087 | Val Loss: 7158179934171715.0000\n",
      "Epoch 002 | Train Loss: 1854.0303 | Val Loss: 37242950741371672.0000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[33]\u001b[39m\u001b[32m, line 75\u001b[39m\n\u001b[32m     72\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mBatch size: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbatch.batch.max().item()\u001b[38;5;250m \u001b[39m+\u001b[38;5;250m \u001b[39m\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     73\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_epochs):\n\u001b[32m     74\u001b[39m     \u001b[38;5;66;03m# Train\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m75\u001b[39m     train_loss = \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     77\u001b[39m     \u001b[38;5;66;03m# Validate\u001b[39;00m\n\u001b[32m     78\u001b[39m     val_loss = validate(model, val_loader, device)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[33]\u001b[39m\u001b[32m, line 15\u001b[39m, in \u001b[36mtrain_epoch\u001b[39m\u001b[34m(model, optimizer, train_loader, device)\u001b[39m\n\u001b[32m     12\u001b[39m optimizer.zero_grad()\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m node_features, positions, mu, log_var, property_pred, num_nodes = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# Calculate loss\u001b[39;00m\n\u001b[32m     18\u001b[39m loss = model.loss_function(\n\u001b[32m     19\u001b[39m     node_features, positions, num_nodes,\n\u001b[32m     20\u001b[39m     batch, mu, log_var, property_pred\n\u001b[32m     21\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/generative-molecular-design/.conda/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1734\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1735\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/generative-molecular-design/.conda/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1743\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1745\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1746\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1747\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1749\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1750\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[31]\u001b[39m\u001b[32m, line 191\u001b[39m, in \u001b[36mPropertyConditionedVAE.forward\u001b[39m\u001b[34m(self, data, target_property)\u001b[39m\n\u001b[32m    188\u001b[39m logger.debug(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTarget property shape after squeeze: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget_property.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    190\u001b[39m \u001b[38;5;66;03m# Decode\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m191\u001b[39m node_features, positions, num_nodes = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    192\u001b[39m \u001b[43m    \u001b[49m\u001b[43mz\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_property\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\n\u001b[32m    193\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    194\u001b[39m logger.debug(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mDecoder outputs - features: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnode_features.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, positions: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpositions.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    196\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m node_features, positions, mu, log_var, property_pred, num_nodes\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/generative-molecular-design/.conda/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1734\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1735\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/generative-molecular-design/.conda/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1743\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1745\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1746\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1747\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1749\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1750\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[31]\u001b[39m\u001b[32m, line 141\u001b[39m, in \u001b[36mConditionalDecoder.forward\u001b[39m\u001b[34m(self, z, target_property, batch_size)\u001b[39m\n\u001b[32m    139\u001b[39m \u001b[38;5;66;03m# Generate node features and positions\u001b[39;00m\n\u001b[32m    140\u001b[39m node_feat = \u001b[38;5;28mself\u001b[39m.node_decoder(h_expanded)\n\u001b[32m--> \u001b[39m\u001b[32m141\u001b[39m pos = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpos_decoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mh_expanded\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    143\u001b[39m node_features_list.append(node_feat)\n\u001b[32m    144\u001b[39m positions_list.append(pos)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/generative-molecular-design/.conda/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1734\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1735\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/generative-molecular-design/.conda/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1743\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1745\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1746\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1747\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1749\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1750\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/generative-molecular-design/.conda/lib/python3.12/site-packages/torch/nn/modules/container.py:250\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    248\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[32m    249\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    251\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/generative-molecular-design/.conda/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1734\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1735\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/generative-molecular-design/.conda/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1743\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1745\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1746\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1747\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1749\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1750\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/generative-molecular-design/.conda/lib/python3.12/site-packages/torch/nn/modules/linear.py:125\u001b[39m, in \u001b[36mLinear.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    124\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "\n",
    "# logging.basicConfig(level=logging.DEBUG)\n",
    "\n",
    "def train_epoch(model, optimizer, train_loader, device):\n",
    "    logger = logging.getLogger('train_epoch')\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch_idx, batch in enumerate(train_loader):\n",
    "        batch = batch.to(device)\n",
    "        logger.debug(f\"\\nBatch {batch_idx}:\")\n",
    "        logger.debug(f\"Batch properties: x={batch.x.shape}, pos={batch.pos.shape}, batch={batch.batch.shape}\")\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        node_features, positions, mu, log_var, property_pred, num_nodes = model(batch)\n",
    "\n",
    "        # Calculate loss\n",
    "        loss = model.loss_function(\n",
    "            node_features, positions, num_nodes,\n",
    "            batch, mu, log_var, property_pred\n",
    "        )\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(train_loader)\n",
    "\n",
    "def validate(model, val_loader, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            batch = batch.to(device)\n",
    "\n",
    "            # Forward pass with all outputs\n",
    "            node_features, positions, mu, log_var, property_pred, num_nodes = model(batch)\n",
    "\n",
    "            # Calculate loss with all parameters\n",
    "            loss = model.loss_function(\n",
    "                node_features, positions, num_nodes,\n",
    "                batch, mu, log_var, property_pred\n",
    "            )\n",
    "            total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(val_loader)\n",
    "\n",
    "\n",
    "# Training setup\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = PropertyConditionedVAE().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode='min', factor=0.5, patience=5, min_lr=1e-6\n",
    ")\n",
    "\n",
    "# Training loop\n",
    "n_epochs = 100\n",
    "best_val_loss = float('inf')\n",
    "patience = 10\n",
    "patience_counter = 0\n",
    "\n",
    "batch = next(iter(train_loader))\n",
    "print(f\"Target property shape: {batch.y.shape}\")\n",
    "print(f\"Target property sample: {batch.y[0]}\")\n",
    "print(f\"Input node features shape: {batch.x.shape}\")  # Should be (N, 11)\n",
    "print(f\"Input positions shape: {batch.pos.shape}\")    # Should be (N, 3)\n",
    "print(f\"Number of nodes: {batch.num_nodes}\")\n",
    "print(f\"Batch size: {batch.batch.max().item() + 1}\")\n",
    "for epoch in range(n_epochs):\n",
    "    # Train\n",
    "    train_loss = train_epoch(model, optimizer, train_loader, device)\n",
    "\n",
    "    # Validate\n",
    "    val_loss = validate(model, val_loader, device)\n",
    "\n",
    "    # Learning rate scheduling\n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "    # Early stopping\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        patience_counter = 0\n",
    "        # Save best model\n",
    "        # Save model with timestamp in a more readable format\n",
    "        timestamp = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "        save_path = f'best_vae_model_{timestamp}.pt'\n",
    "        torch.save(model.state_dict(), save_path)\n",
    "        print(f'Saved best model to: {save_path}')\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= patience:\n",
    "            print(f'Early stopping at epoch {epoch}')\n",
    "            break\n",
    "\n",
    "    # Print progress\n",
    "    print(f'Epoch {epoch:03d} | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}')\n",
    "\n",
    "# Load best model for testing\n",
    "model.load_state_dict(torch.load('best_vae_model.pt'))\n",
    "\n",
    "# Test final model\n",
    "test_loss = validate(model, test_loader, device)\n",
    "print(f'Final Test Loss: {test_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
