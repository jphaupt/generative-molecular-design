{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Message-Passing Graph Variational Autoencoder\n",
    "\n",
    "Here I will use principles from message-passing graph neural networks to try to generate\n",
    "molecules in a graph variational autoencoder. This is based on my solutions to \n",
    "`geometric-gnn-dojo/geometric_gnn_101.ipynb`\n",
    "Some of the code has also been taken from there\n",
    "\n",
    "might also want to consider autoregressive model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version 2.5.0+cu124\n",
      "PyG version 2.6.1\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import logging\n",
    "import time\n",
    "from mygenai.models.graphvae import PropertyConditionedVAE\n",
    "# importlib.reload(PropertyConditionedVAE)\n",
    "\n",
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "import torch_geometric\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "print(\"PyTorch version {}\".format(torch.__version__))\n",
    "print(\"PyG version {}\".format(torch_geometric.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Debug mode is OFF\n"
     ]
    }
   ],
   "source": [
    "\n",
    "debug_print = False\n",
    "if debug_print:\n",
    "    print(\"Debug mode is ON\")\n",
    "    logging.basicConfig(\n",
    "        level=logging.DEBUG,\n",
    "        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "        force=True  # Ensure configuration is applied\n",
    "    )\n",
    "    for logger_name in ['train_epoch', 'PropertyConditionedVAE', 'ConditionalDecoder', 'Encoder']:\n",
    "        logging.getLogger(logger_name).setLevel(logging.DEBUG)\n",
    "else:\n",
    "    print(\"Debug mode is OFF\")\n",
    "    logging.basicConfig(\n",
    "        level=logging.INFO,\n",
    "        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "        force=True  # Ensure configuration is applied\n",
    "    )\n",
    "    for logger_name in ['train_epoch', 'PropertyConditionedVAE', 'ConditionalDecoder', 'Encoder']:\n",
    "        logging.getLogger(logger_name).setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jph/dev/generative-molecular-design/.conda/lib/python3.12/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 28\u001b[39m\n\u001b[32m     25\u001b[39m         data.normalized_distances = distances / max_distance  \u001b[38;5;66;03m# Normalize distances\u001b[39;00m\n\u001b[32m     26\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m dataset\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m dataset = \u001b[43mnormalize_distances\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfixed_max_distance\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[38;5;66;03m# min_atomic_number = 1\u001b[39;00m\n\u001b[32m     30\u001b[39m \u001b[38;5;66;03m# max_atomic_number = 9\u001b[39;00m\n\u001b[32m     31\u001b[39m \u001b[38;5;66;03m# dataset.data.z = (dataset.data.z - min_atomic_number) / (max_atomic_number - min_atomic_number) # doesn't actually matter because it's not used (this information is determined by data.x)\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 20\u001b[39m, in \u001b[36mnormalize_distances\u001b[39m\u001b[34m(dataset, max_distance)\u001b[39m\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mnormalize_distances\u001b[39m(dataset, max_distance):\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpos\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpos\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# (n, 3) - absolute coordinates\u001b[39;49;00m\n\u001b[32m     22\u001b[39m \u001b[43m        \u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdst\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# (2, num_edges) - edge indices\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/generative-molecular-design/.conda/lib/python3.12/site-packages/torch_geometric/data/dataset.py:300\u001b[39m, in \u001b[36mDataset.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    298\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> Iterator[BaseData]:\n\u001b[32m    299\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m)):\n\u001b[32m--> \u001b[39m\u001b[32m300\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/generative-molecular-design/.conda/lib/python3.12/site-packages/torch_geometric/data/dataset.py:292\u001b[39m, in \u001b[36mDataset.__getitem__\u001b[39m\u001b[34m(self, idx)\u001b[39m\n\u001b[32m    287\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(idx, (\u001b[38;5;28mint\u001b[39m, np.integer))\n\u001b[32m    288\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(idx, Tensor) \u001b[38;5;129;01mand\u001b[39;00m idx.dim() == \u001b[32m0\u001b[39m)\n\u001b[32m    289\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(idx, np.ndarray) \u001b[38;5;129;01mand\u001b[39;00m np.isscalar(idx))):\n\u001b[32m    291\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.get(\u001b[38;5;28mself\u001b[39m.indices()[idx])\n\u001b[32m--> \u001b[39m\u001b[32m292\u001b[39m     data = data \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.transform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    293\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m data\n\u001b[32m    295\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/generative-molecular-design/mygenai/utils/transforms.py:22\u001b[39m, in \u001b[36mCompleteGraph.__call__\u001b[39m\u001b[34m(self, data)\u001b[39m\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m data.edge_attr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     21\u001b[39m     idx = data.edge_index[\u001b[32m0\u001b[39m] * data.num_nodes + data.edge_index[\u001b[32m1\u001b[39m]\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m     size = \u001b[38;5;28mlist\u001b[39m(\u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43medge_attr\u001b[49m\u001b[43m.\u001b[49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m     23\u001b[39m     size[\u001b[32m0\u001b[39m] = data.num_nodes * data.num_nodes\n\u001b[32m     24\u001b[39m     edge_attr = data.edge_attr.new_zeros(size)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.datasets import QM9\n",
    "from torch_geometric.loader import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from mygenai.utils.transforms import CompleteGraph\n",
    "\n",
    "dataset = QM9(root=\"../data/QM9\", transform=CompleteGraph())\n",
    "# Normalize targets per data sample to mean = 0 and std = 1.\n",
    "mean = dataset.data.y.mean(dim=0, keepdim=True)\n",
    "std = dataset.data.y.std(dim=0, keepdim=True)\n",
    "dataset.data.y = (dataset.data.y - mean) / std\n",
    "# focus on just using the one-hot encoding of the atomic number, for simplicity for now\n",
    "dataset.data.x = dataset.data.x[:, :5]\n",
    "\n",
    "# Normalize distances in the dataset\n",
    "fixed_max_distance = 2.0\n",
    "\n",
    "# TODO in the future maybe use a Z matrix representation for positions\n",
    "# def normalize_distances(dataset, max_distance):\n",
    "#     for data in dataset:\n",
    "#         pos = data.pos  # (n, 3) - absolute coordinates\n",
    "#         src, dst = data.edge_index  # (2, num_edges) - edge indices\n",
    "#         relative_positions = pos[dst] - pos[src]  # (num_edges, 3)\n",
    "#         distances = torch.norm(relative_positions, dim=1)  # (num_edges,)\n",
    "#         data.normalized_distances = distances / max_distance  # Normalize distances\n",
    "#     return dataset\n",
    "\n",
    "# dataset = normalize_distances(dataset, fixed_max_distance)\n",
    "# min_atomic_number = 1\n",
    "# max_atomic_number = 9\n",
    "# dataset.data.z = (dataset.data.z - min_atomic_number) / (max_atomic_number - min_atomic_number) # doesn't actually matter because it's not used (this information is determined by data.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data splitting (60/20/20)\n",
    "train_val_idx, test_idx = train_test_split(\n",
    "    np.arange(len(dataset)),\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "train_idx, val_idx = train_test_split(\n",
    "    train_val_idx,\n",
    "    test_size=0.25,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(dataset[train_idx], batch_size=128, shuffle=True)\n",
    "val_loader = DataLoader(dataset[val_idx], batch_size=128, shuffle=False)\n",
    "test_loader = DataLoader(dataset[test_idx], batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training setup\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = PropertyConditionedVAE().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode='min', factor=0.5, patience=5, min_lr=1e-6\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward pass successful!\n"
     ]
    }
   ],
   "source": [
    "# test forward passs\n",
    "batch = next(iter(train_loader))\n",
    "batch = batch.to(device)\n",
    "with torch.no_grad():\n",
    "    outputs = model(batch)\n",
    "print(\"Forward pass successful!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # check if training sets are reasonably balanced\n",
    "\n",
    "# def basic_homo_lumo_stats(loader, name):\n",
    "#     total_nodes = 0\n",
    "#     total_graphs = 0\n",
    "#     prop_values = []\n",
    "\n",
    "#     for batch in loader:\n",
    "#         total_graphs += batch.batch.max().item() + 1\n",
    "#         total_nodes += batch.x.shape[0]\n",
    "#         prop_values.append(batch.y[:, 4].cpu().numpy())\n",
    "\n",
    "#     prop_values = np.concatenate(prop_values)\n",
    "#     print(f\"{name} stats - graphs: {total_graphs}, avg. nodes: {total_nodes/total_graphs}\")\n",
    "#     print(f\"{name} property stats - mean: {prop_values.mean():.4f}, std: {prop_values.std():.4f}\")\n",
    "\n",
    "# basic_homo_lumo_stats(train_loader, \"Train\")\n",
    "# basic_homo_lumo_stats(test_loader, \"Test\")\n",
    "# basic_homo_lumo_stats(val_loader, \"Validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-20 18:51:03,065 - root - INFO - Target property shape: torch.Size([128, 19])\n",
      "2025-04-20 18:51:03,066 - root - INFO - Target property sample: tensor([-0.5368,  0.6629, -0.0587, -0.1267, -0.0984,  0.4885,  1.0045, -0.3360,\n",
      "        -0.3360, -0.3360, -0.3360,  0.8287, -0.9686, -0.9696, -0.9700, -0.9614,\n",
      "        -0.0038, -0.1471, -0.2082])\n",
      "2025-04-20 18:51:03,066 - root - INFO - Input node features shape: torch.Size([2360, 5])\n",
      "2025-04-20 18:51:03,066 - root - INFO - Input positions shape: torch.Size([2360, 3])\n",
      "2025-04-20 18:51:03,067 - root - INFO - Number of nodes: 2360\n",
      "2025-04-20 18:51:03,067 - root - INFO - Batch size: 128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated node features: min=0.0807, max=0.9049\n",
      "Original node features: min=0.0000, max=1.0000\n",
      "Generated distances: min=0.0000, max=1.9338\n",
      "Generated directions: min=-0.9967, max=0.9990\n",
      "Epoch 000 | Train Loss: 74.0588 | Val Loss: 9.8723\n",
      "Generated node features: min=0.0030, max=0.6648\n",
      "Original node features: min=0.0000, max=1.0000\n",
      "Generated distances: min=0.0000, max=3.7843\n",
      "Generated directions: min=-0.9946, max=0.9916\n",
      "Epoch 001 | Train Loss: 9.8253 | Val Loss: 5.7595\n",
      "Generated node features: min=0.0000, max=0.6689\n",
      "Original node features: min=0.0000, max=1.0000\n",
      "Generated distances: min=0.0000, max=4.0604\n",
      "Generated directions: min=-0.9901, max=0.9926\n",
      "Epoch 002 | Train Loss: 2.9047 | Val Loss: 2.7684\n",
      "Generated node features: min=0.0014, max=0.6640\n",
      "Original node features: min=0.0000, max=1.0000\n",
      "Generated distances: min=2.8320, max=4.4453\n",
      "Generated directions: min=-0.9961, max=0.9937\n",
      "Epoch 003 | Train Loss: 2.7186 | Val Loss: 2.6102\n",
      "Generated node features: min=0.0005, max=0.6837\n",
      "Original node features: min=0.0000, max=1.0000\n",
      "Generated distances: min=2.7414, max=4.0118\n",
      "Generated directions: min=-0.9983, max=0.9235\n",
      "Epoch 004 | Train Loss: 2.7113 | Val Loss: 2.7328\n",
      "Generated node features: min=0.0005, max=0.6787\n",
      "Original node features: min=0.0000, max=1.0000\n",
      "Generated distances: min=2.6038, max=3.9961\n",
      "Generated directions: min=-0.9861, max=0.9507\n",
      "Epoch 005 | Train Loss: 2.7055 | Val Loss: 3.0777\n",
      "Generated node features: min=0.0003, max=0.7014\n",
      "Original node features: min=0.0000, max=1.0000\n",
      "Generated distances: min=2.8099, max=4.1901\n",
      "Generated directions: min=-0.9715, max=0.9907\n",
      "Epoch 006 | Train Loss: 2.6984 | Val Loss: 2.7320\n",
      "Generated node features: min=0.0002, max=0.6687\n",
      "Original node features: min=0.0000, max=1.0000\n",
      "Generated distances: min=2.1936, max=4.2197\n",
      "Generated directions: min=-0.9925, max=0.9751\n",
      "Epoch 007 | Train Loss: 2.6993 | Val Loss: 3.3586\n",
      "Generated node features: min=0.0002, max=0.7677\n",
      "Original node features: min=0.0000, max=1.0000\n",
      "Generated distances: min=2.4603, max=4.0775\n",
      "Generated directions: min=-0.9869, max=0.9452\n",
      "Epoch 008 | Train Loss: 2.6953 | Val Loss: 4.2345\n",
      "Generated node features: min=0.0001, max=0.6544\n",
      "Original node features: min=0.0000, max=1.0000\n",
      "Generated distances: min=2.7738, max=4.1803\n",
      "Generated directions: min=-0.9877, max=0.9909\n",
      "Epoch 009 | Train Loss: 2.6974 | Val Loss: 2.7484\n",
      "Generated node features: min=0.0001, max=0.6322\n",
      "Original node features: min=0.0000, max=1.0000\n",
      "Generated distances: min=2.7275, max=4.5443\n",
      "Generated directions: min=-0.9768, max=0.9784\n",
      "Epoch 010 | Train Loss: 2.6748 | Val Loss: 2.6217\n",
      "Generated node features: min=0.0001, max=0.6530\n",
      "Original node features: min=0.0000, max=1.0000\n",
      "Generated distances: min=2.5844, max=3.9483\n",
      "Generated directions: min=-0.9806, max=0.9905\n",
      "Epoch 011 | Train Loss: 2.6719 | Val Loss: 2.6799\n",
      "Generated node features: min=0.0001, max=0.6560\n",
      "Original node features: min=0.0000, max=1.0000\n",
      "Generated distances: min=2.6174, max=4.0748\n",
      "Generated directions: min=-0.9670, max=0.9984\n",
      "Epoch 012 | Train Loss: 2.6661 | Val Loss: 2.7111\n",
      "Generated node features: min=0.0002, max=0.6751\n",
      "Original node features: min=0.0000, max=1.0000\n",
      "Generated distances: min=2.6834, max=4.1677\n",
      "Generated directions: min=-0.8926, max=0.9910\n",
      "Early stopping at epoch 13\n",
      "Saved best model to: best_vae_model_20250420_185729.pt\n",
      "Final Test Loss: 2.6187\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# TODO : move training etc. to mygenai\n",
    "# logging.basicConfig(level=logging.DEBUG)\n",
    "\n",
    "# for now, check to see if can at least reconstruct molecules\n",
    "recon_weight = 1.0\n",
    "kl_weight = 0. #0.01\n",
    "property_weight = 0.\n",
    "\n",
    "def train_epoch(model, optimizer, train_loader, device):\n",
    "    logger = logging.getLogger('train_epoch')\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch_idx, batch in enumerate(train_loader):\n",
    "        batch = batch.to(device)\n",
    "        logger.debug(f\"\\nBatch {batch_idx}:\")\n",
    "        logger.debug(f\"Batch properties: x={batch.x.shape}, pos={batch.pos.shape}, batch={batch.batch.shape}\")\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        node_features, distances, directions, edge_features, num_nodes, mu, log_var, property_pred = model(batch)\n",
    "\n",
    "        if batch_idx == 0:  # Check first batch only\n",
    "            # Print statistics about generated values\n",
    "            print(f\"Generated node features: min={node_features.min().item():.4f}, max={node_features.max().item():.4f}\")\n",
    "            print(f\"Original node features: min={batch.x.min().item():.4f}, max={batch.x.max().item():.4f}\")\n",
    "            print(f\"Generated distances: min={distances.min().item():.4f}, max={distances.max().item():.4f}\")\n",
    "            # print(f\"Generated directions: min={directions.min().item():.4f}, max={directions.max().item():.4f}\")\n",
    "\n",
    "        # Calculate loss\n",
    "        loss = model.loss_function(\n",
    "            node_features, distances, directions, edge_features, num_nodes,\n",
    "            batch, mu, log_var, property_pred,\n",
    "            recon_weight=recon_weight, kl_weight=kl_weight, property_weight=property_weight\n",
    "        )\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.)\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(train_loader)\n",
    "\n",
    "\n",
    "def validate(model, val_loader, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    batch_losses = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch in enumerate(val_loader):\n",
    "            batch = batch.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            node_features, distances, directions, edge_features, num_nodes, mu, log_var, property_pred = model(batch)\n",
    "\n",
    "            # Calculate loss\n",
    "            loss = model.loss_function(\n",
    "                node_features, distances, directions, edge_features, num_nodes,\n",
    "                batch, mu, log_var, property_pred,\n",
    "                recon_weight=recon_weight, kl_weight=kl_weight, property_weight=property_weight\n",
    "            )\n",
    "\n",
    "            batch_losses.append(loss.item())\n",
    "            total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(val_loader)\n",
    "\n",
    "\n",
    "# Training loop\n",
    "n_epochs = 100\n",
    "best_val_loss = float('inf')\n",
    "patience = 10\n",
    "patience_counter = 0\n",
    "\n",
    "batch = next(iter(train_loader))\n",
    "logging.info(f\"Target property shape: {batch.y.shape}\")\n",
    "logging.info(f\"Target property sample: {batch.y[0]}\")\n",
    "logging.info(f\"Input node features shape: {batch.x.shape}\")  # Should be (N, 11)\n",
    "logging.info(f\"Input positions shape: {batch.pos.shape}\")    # Should be (N, 3)\n",
    "logging.info(f\"Number of nodes: {batch.num_nodes}\")\n",
    "logging.info(f\"Batch size: {batch.batch.max().item() + 1}\")\n",
    "for epoch in range(n_epochs):\n",
    "    # Train\n",
    "    train_loss = train_epoch(model, optimizer, train_loader, device)\n",
    "\n",
    "    # Validate\n",
    "    val_loss = validate(model, val_loader, device)\n",
    "\n",
    "    # Learning rate scheduling\n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "    # Early stopping\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        patience_counter = 0\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= patience:\n",
    "            print(f'Early stopping at epoch {epoch}')\n",
    "            # Save best model\n",
    "            # Save model with timestamp in a more readable format\n",
    "            timestamp = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "            save_path = f'best_vae_model_{timestamp}.pt'\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            print(f'Saved best model to: {save_path}')\n",
    "            break\n",
    "\n",
    "    # Print progress\n",
    "    print(f'Epoch {epoch:03d} | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}')\n",
    "\n",
    "# Load best model for testing\n",
    "# model.load_state_dict(torch.load('best_vae_model.pt'))\n",
    "\n",
    "# Test final model\n",
    "test_loss = validate(model, test_loader, device)\n",
    "print(f'Final Test Loss: {test_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PropertyConditionedVAE(\n",
       "  (encoder): Encoder(\n",
       "    (lin_in): Linear(in_features=5, out_features=64, bias=True)\n",
       "    (convs): ModuleList(\n",
       "      (0-1): 2 x EquivariantMPNNLayer(emb_dim=64, aggr=add)\n",
       "    )\n",
       "    (mu): Linear(in_features=64, out_features=32, bias=True)\n",
       "    (log_var): Linear(in_features=64, out_features=32, bias=True)\n",
       "    (property_predictor): Sequential(\n",
       "      (0): Linear(in_features=32, out_features=64, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): Linear(in_features=64, out_features=1, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (decoder): ConditionalDecoder(\n",
       "    (lin_latent): Linear(in_features=33, out_features=64, bias=True)\n",
       "    (node_decoder): Sequential(\n",
       "      (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): Linear(in_features=64, out_features=5, bias=True)\n",
       "      (4): Sigmoid()\n",
       "    )\n",
       "    (distance_decoder): Sequential(\n",
       "      (0): Linear(in_features=128, out_features=64, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): Linear(in_features=64, out_features=1, bias=True)\n",
       "      (4): ReLU()\n",
       "    )\n",
       "    (direction_decoder): Sequential(\n",
       "      (0): Linear(in_features=128, out_features=64, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): Linear(in_features=64, out_features=3, bias=True)\n",
       "    )\n",
       "    (edge_features): Sequential(\n",
       "      (0): Linear(in_features=128, out_features=64, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): Linear(in_features=64, out_features=4, bias=True)\n",
       "      (4): Sigmoid()\n",
       "    )\n",
       "    (num_nodes_predictor): Sequential(\n",
       "      (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): Linear(in_features=64, out_features=1, bias=True)\n",
       "      (4): ReLU()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
