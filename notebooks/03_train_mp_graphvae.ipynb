{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Message-Passing Graph Variational Autoencoder\n",
    "\n",
    "Here I will use principles from message-passing graph neural networks to try to generate\n",
    "molecules in a graph variational autoencoder. This is based on my solutions to \n",
    "`geometric-gnn-dojo/geometric_gnn_101.ipynb`\n",
    "Some of the code has also been taken from there\n",
    "\n",
    "might also want to consider autoregressive model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version 2.5.0+cu124\n",
      "PyG version 2.6.1\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import logging\n",
    "import time\n",
    "from mygenai.models.graphvae import PropertyConditionedVAE\n",
    "# importlib.reload(PropertyConditionedVAE)\n",
    "\n",
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "import torch_geometric\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "print(\"PyTorch version {}\".format(torch.__version__))\n",
    "print(\"PyG version {}\".format(torch_geometric.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Debug mode is OFF\n"
     ]
    }
   ],
   "source": [
    "\n",
    "debug_print = False\n",
    "if debug_print:\n",
    "    print(\"Debug mode is ON\")\n",
    "    logging.basicConfig(\n",
    "        level=logging.DEBUG,\n",
    "        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "        force=True  # Ensure configuration is applied\n",
    "    )\n",
    "    for logger_name in ['train_epoch', 'PropertyConditionedVAE', 'ConditionalDecoder', 'Encoder']:\n",
    "        logging.getLogger(logger_name).setLevel(logging.DEBUG)\n",
    "else:\n",
    "    print(\"Debug mode is OFF\")\n",
    "    logging.basicConfig(\n",
    "        level=logging.INFO,\n",
    "        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "        force=True  # Ensure configuration is applied\n",
    "    )\n",
    "    for logger_name in ['train_epoch', 'PropertyConditionedVAE', 'ConditionalDecoder', 'Encoder']:\n",
    "        logging.getLogger(logger_name).setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jph/dev/generative-molecular-design/.conda/lib/python3.12/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.datasets import QM9\n",
    "from torch_geometric.loader import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from mygenai.utils.transforms import CompleteGraph\n",
    "\n",
    "dataset = QM9(root=\"../data/QM9\") #, transform=CompleteGraph())\n",
    "# Normalize targets per data sample to mean = 0 and std = 1.\n",
    "mean = dataset.data.y.mean(dim=0, keepdim=True)\n",
    "std = dataset.data.y.std(dim=0, keepdim=True)\n",
    "dataset.data.y = (dataset.data.y - mean) / std\n",
    "# focus on just using the one-hot encoding of the atomic number, for simplicity for now\n",
    "dataset.data.x = dataset.data.x[:, :5]\n",
    "\n",
    "# Normalize distances in the dataset\n",
    "fixed_max_distance = 2.0\n",
    "\n",
    "# TODO in the future maybe use a Z matrix representation for positions\n",
    "# def normalize_distances(dataset, max_distance):\n",
    "#     for data in dataset:\n",
    "#         pos = data.pos  # (n, 3) - absolute coordinates\n",
    "#         src, dst = data.edge_index  # (2, num_edges) - edge indices\n",
    "#         relative_positions = pos[dst] - pos[src]  # (num_edges, 3)\n",
    "#         distances = torch.norm(relative_positions, dim=1)  # (num_edges,)\n",
    "#         data.normalized_distances = distances / max_distance  # Normalize distances\n",
    "#     return dataset\n",
    "\n",
    "# dataset = normalize_distances(dataset, fixed_max_distance)\n",
    "# min_atomic_number = 1\n",
    "# max_atomic_number = 9\n",
    "# dataset.data.z = (dataset.data.z - min_atomic_number) / (max_atomic_number - min_atomic_number) # doesn't actually matter because it's not used (this information is determined by data.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data splitting (60/20/20)\n",
    "train_val_idx, test_idx = train_test_split(\n",
    "    np.arange(len(dataset)),\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "train_idx, val_idx = train_test_split(\n",
    "    train_val_idx,\n",
    "    test_size=0.25,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(dataset[train_idx], batch_size=128, shuffle=True)\n",
    "val_loader = DataLoader(dataset[val_idx], batch_size=128, shuffle=False)\n",
    "test_loader = DataLoader(dataset[test_idx], batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training setup\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = PropertyConditionedVAE().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode='min', factor=0.5, patience=5, min_lr=1e-6\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward pass successful!\n"
     ]
    }
   ],
   "source": [
    "# test forward passs\n",
    "batch = next(iter(train_loader))\n",
    "batch = batch.to(device)\n",
    "with torch.no_grad():\n",
    "    outputs = model(batch)\n",
    "print(\"Forward pass successful!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # check if training sets are reasonably balanced\n",
    "\n",
    "# def basic_homo_lumo_stats(loader, name):\n",
    "#     total_nodes = 0\n",
    "#     total_graphs = 0\n",
    "#     prop_values = []\n",
    "\n",
    "#     for batch in loader:\n",
    "#         total_graphs += batch.batch.max().item() + 1\n",
    "#         total_nodes += batch.x.shape[0]\n",
    "#         prop_values.append(batch.y[:, 4].cpu().numpy())\n",
    "\n",
    "#     prop_values = np.concatenate(prop_values)\n",
    "#     print(f\"{name} stats - graphs: {total_graphs}, avg. nodes: {total_nodes/total_graphs}\")\n",
    "#     print(f\"{name} property stats - mean: {prop_values.mean():.4f}, std: {prop_values.std():.4f}\")\n",
    "\n",
    "# basic_homo_lumo_stats(train_loader, \"Train\")\n",
    "# basic_homo_lumo_stats(test_loader, \"Test\")\n",
    "# basic_homo_lumo_stats(val_loader, \"Validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-21 11:48:39,966 - root - INFO - Target property shape: torch.Size([128, 19])\n",
      "2025-04-21 11:48:39,967 - root - INFO - Target property sample: tensor([ 0.1335,  0.8905, -0.0906, -0.6005, -0.5540,  0.0372,  0.9923,  0.5951,\n",
      "         0.5951,  0.5951,  0.5951,  0.4771, -1.1552, -1.1552, -1.1543, -1.1658,\n",
      "        -0.0036, -0.1398, -0.0276])\n",
      "2025-04-21 11:48:39,967 - root - INFO - Input node features shape: torch.Size([2310, 5])\n",
      "2025-04-21 11:48:39,968 - root - INFO - Input positions shape: torch.Size([2310, 3])\n",
      "2025-04-21 11:48:39,968 - root - INFO - Number of nodes: 2310\n",
      "2025-04-21 11:48:39,968 - root - INFO - Batch size: 128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated node features: min=0.0168, max=0.7573\n",
      "Generated distances: min=1.0587, max=1.7654\n",
      "Epoch 000 | Train Loss: 76.7905 | Val Loss: 9.3001\n",
      "Generated node features: min=0.0000, max=0.9995\n",
      "Generated distances: min=1.9954, max=2.0000\n",
      "Epoch 001 | Train Loss: 13.5905 | Val Loss: 36.0596\n",
      "Generated node features: min=0.0000, max=0.9885\n",
      "Generated distances: min=1.9996, max=1.9999\n",
      "Epoch 002 | Train Loss: 4.9449 | Val Loss: 4.9022\n",
      "Generated node features: min=0.0000, max=0.9941\n",
      "Generated distances: min=2.0000, max=2.0000\n",
      "Epoch 003 | Train Loss: 4.9230 | Val Loss: 6.7094\n",
      "Generated node features: min=0.0000, max=0.9994\n",
      "Generated distances: min=2.0000, max=2.0000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 88\u001b[39m\n\u001b[32m     85\u001b[39m logging.info(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mBatch size: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbatch.batch.max().item()\u001b[38;5;250m \u001b[39m+\u001b[38;5;250m \u001b[39m\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     86\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_epochs):\n\u001b[32m     87\u001b[39m     \u001b[38;5;66;03m# Train\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m88\u001b[39m     train_loss = \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     90\u001b[39m     \u001b[38;5;66;03m# Validate\u001b[39;00m\n\u001b[32m     91\u001b[39m     val_loss = validate(model, val_loader, device)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 14\u001b[39m, in \u001b[36mtrain_epoch\u001b[39m\u001b[34m(model, optimizer, train_loader, device)\u001b[39m\n\u001b[32m     11\u001b[39m model.train()\n\u001b[32m     12\u001b[39m total_loss = \u001b[32m0\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlogger\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdebug\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43mBatch \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mbatch_idx\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m:\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/generative-molecular-design/.conda/lib/python3.12/site-packages/torch/utils/data/dataloader.py:701\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    698\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    699\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    700\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m701\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    702\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    703\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    704\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    705\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    706\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    707\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/generative-molecular-design/.conda/lib/python3.12/site-packages/torch/utils/data/dataloader.py:757\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    755\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    756\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m757\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    758\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    759\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/generative-molecular-design/.conda/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py:55\u001b[39m, in \u001b[36m_MapDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     54\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/generative-molecular-design/.conda/lib/python3.12/site-packages/torch_geometric/loader/dataloader.py:27\u001b[39m, in \u001b[36mCollater.__call__\u001b[39m\u001b[34m(self, batch)\u001b[39m\n\u001b[32m     25\u001b[39m elem = batch[\u001b[32m0\u001b[39m]\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, BaseData):\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mBatch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_data_list\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfollow_batch\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfollow_batch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     30\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexclude_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mexclude_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     32\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, torch.Tensor):\n\u001b[32m     33\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m default_collate(batch)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/generative-molecular-design/.conda/lib/python3.12/site-packages/torch_geometric/data/batch.py:97\u001b[39m, in \u001b[36mBatch.from_data_list\u001b[39m\u001b[34m(cls, data_list, follow_batch, exclude_keys)\u001b[39m\n\u001b[32m     82\u001b[39m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[32m     83\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfrom_data_list\u001b[39m(\n\u001b[32m     84\u001b[39m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     87\u001b[39m     exclude_keys: Optional[List[\u001b[38;5;28mstr\u001b[39m]] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m     88\u001b[39m ) -> Self:\n\u001b[32m     89\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Constructs a :class:`~torch_geometric.data.Batch` object from a\u001b[39;00m\n\u001b[32m     90\u001b[39m \u001b[33;03m    list of :class:`~torch_geometric.data.Data` or\u001b[39;00m\n\u001b[32m     91\u001b[39m \u001b[33;03m    :class:`~torch_geometric.data.HeteroData` objects.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     95\u001b[39m \u001b[33;03m    Will exclude any keys given in :obj:`exclude_keys`.\u001b[39;00m\n\u001b[32m     96\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m97\u001b[39m     batch, slice_dict, inc_dict = \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     98\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     99\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdata_list\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    100\u001b[39m \u001b[43m        \u001b[49m\u001b[43mincrement\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    101\u001b[39m \u001b[43m        \u001b[49m\u001b[43madd_batch\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata_list\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mBatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    102\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfollow_batch\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_batch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    103\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexclude_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexclude_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    104\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    106\u001b[39m     batch._num_graphs = \u001b[38;5;28mlen\u001b[39m(data_list)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[32m    107\u001b[39m     batch._slice_dict = slice_dict  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/generative-molecular-design/.conda/lib/python3.12/site-packages/torch_geometric/data/collate.py:109\u001b[39m, in \u001b[36mcollate\u001b[39m\u001b[34m(cls, data_list, increment, add_batch, follow_batch, exclude_keys)\u001b[39m\n\u001b[32m    106\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m    108\u001b[39m \u001b[38;5;66;03m# Collate attributes into a unified representation:\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m109\u001b[39m value, slices, incs = \u001b[43m_collate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstores\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    110\u001b[39m \u001b[43m                               \u001b[49m\u001b[43mincrement\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    112\u001b[39m \u001b[38;5;66;03m# If parts of the data are already on GPU, make sure that auxiliary\u001b[39;00m\n\u001b[32m    113\u001b[39m \u001b[38;5;66;03m# data like `batch` or `ptr` are also created on GPU:\u001b[39;00m\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, Tensor) \u001b[38;5;129;01mand\u001b[39;00m value.is_cuda:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/generative-molecular-design/.conda/lib/python3.12/site-packages/torch_geometric/data/collate.py:169\u001b[39m, in \u001b[36m_collate\u001b[39m\u001b[34m(key, values, data_list, stores, increment)\u001b[39m\n\u001b[32m    167\u001b[39m slices = cumsum(sizes)\n\u001b[32m    168\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m increment:\n\u001b[32m--> \u001b[39m\u001b[32m169\u001b[39m     incs = \u001b[43mget_incs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstores\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    170\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m incs.dim() > \u001b[32m1\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mint\u001b[39m(incs[-\u001b[32m1\u001b[39m]) != \u001b[32m0\u001b[39m:\n\u001b[32m    171\u001b[39m         values = [\n\u001b[32m    172\u001b[39m             value + inc.to(value.device)\n\u001b[32m    173\u001b[39m             \u001b[38;5;28;01mfor\u001b[39;00m value, inc \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(values, incs)\n\u001b[32m    174\u001b[39m         ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/generative-molecular-design/.conda/lib/python3.12/site-packages/torch_geometric/data/collate.py:328\u001b[39m, in \u001b[36mget_incs\u001b[39m\u001b[34m(key, values, data_list, stores)\u001b[39m\n\u001b[32m    325\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_incs\u001b[39m(key, values: List[Any], data_list: List[BaseData],\n\u001b[32m    326\u001b[39m              stores: List[BaseStorage]) -> Tensor:\n\u001b[32m    327\u001b[39m     repeats = [\n\u001b[32m--> \u001b[39m\u001b[32m328\u001b[39m         \u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43m__inc__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    329\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m value, data, store \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(values, data_list, stores)\n\u001b[32m    330\u001b[39m     ]\n\u001b[32m    331\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(repeats[\u001b[32m0\u001b[39m], Tensor):\n\u001b[32m    332\u001b[39m         repeats = torch.stack(repeats, dim=\u001b[32m0\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/generative-molecular-design/.conda/lib/python3.12/site-packages/torch_geometric/data/data.py:662\u001b[39m, in \u001b[36mData.__inc__\u001b[39m\u001b[34m(self, key, value, *args, **kwargs)\u001b[39m\n\u001b[32m    660\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mint\u001b[39m(value.max()) + \u001b[32m1\u001b[39m\n\u001b[32m    661\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mindex\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m key \u001b[38;5;129;01mor\u001b[39;00m key == \u001b[33m'\u001b[39m\u001b[33mface\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m662\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnum_nodes\u001b[49m\n\u001b[32m    663\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    664\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[32m0\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/generative-molecular-design/.conda/lib/python3.12/site-packages/torch_geometric/data/data.py:616\u001b[39m, in \u001b[36mData.num_nodes\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    614\u001b[39m \u001b[38;5;129m@property\u001b[39m\n\u001b[32m    615\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mnum_nodes\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> Optional[\u001b[38;5;28mint\u001b[39m]:\n\u001b[32m--> \u001b[39m\u001b[32m616\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnum_nodes\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/generative-molecular-design/.conda/lib/python3.12/site-packages/torch_geometric/data/data.py:168\u001b[39m, in \u001b[36mBaseData.num_nodes\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    165\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m mapping.items():\n\u001b[32m    166\u001b[39m         \u001b[38;5;28mself\u001b[39m.\u001b[34m__dict__\u001b[39m[key] = value\n\u001b[32m--> \u001b[39m\u001b[32m168\u001b[39m \u001b[38;5;129m@property\u001b[39m\n\u001b[32m    169\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mnum_nodes\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> Optional[\u001b[38;5;28mint\u001b[39m]:\n\u001b[32m    170\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Returns the number of nodes in the graph.\u001b[39;00m\n\u001b[32m    171\u001b[39m \n\u001b[32m    172\u001b[39m \u001b[33;03m    .. note::\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    183\u001b[39m \u001b[33;03m        You will be given a warning that requests you to do so.\u001b[39;00m\n\u001b[32m    184\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m    185\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# TODO : move training etc. to mygenai\n",
    "# logging.basicConfig(level=logging.DEBUG)\n",
    "\n",
    "# for now, check to see if can at least reconstruct molecules\n",
    "recon_weight = 1.0\n",
    "kl_weight = 0. #0.001\n",
    "property_weight = 0.\n",
    "\n",
    "def train_epoch(model, optimizer, train_loader, device):\n",
    "    logger = logging.getLogger('train_epoch')\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch_idx, batch in enumerate(train_loader):\n",
    "        batch = batch.to(device)\n",
    "        logger.debug(f\"\\nBatch {batch_idx}:\")\n",
    "        logger.debug(f\"Batch properties: x={batch.x.shape}, pos={batch.pos.shape}, batch={batch.batch.shape}\")\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        node_features, distances, directions, edge_features, num_nodes, mu, log_var, property_pred = model(batch)\n",
    "\n",
    "        if batch_idx == 0:  # Check first batch only\n",
    "            # Print statistics about generated values\n",
    "            print(f\"Generated node features: min={node_features.min().item():.4f}, max={node_features.max().item():.4f}\")\n",
    "            # print(f\"Original node features: min={batch.x.min().item():.4f}, max={batch.x.max().item():.4f}\") # always in [0,1] because one-hot encoding\n",
    "            print(f\"Generated distances: min={distances.min().item():.4f}, max={distances.max().item():.4f}\")\n",
    "            # print(f\"Generated directions: min={directions.min().item():.4f}, max={directions.max().item():.4f}\")\n",
    "\n",
    "        # Calculate loss\n",
    "        loss = model.loss_function(\n",
    "            node_features, distances, directions, edge_features, num_nodes,\n",
    "            batch, mu, log_var, property_pred,\n",
    "            recon_weight=recon_weight, kl_weight=kl_weight, property_weight=property_weight\n",
    "        )\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.)\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(train_loader)\n",
    "\n",
    "\n",
    "def validate(model, val_loader, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    batch_losses = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch in enumerate(val_loader):\n",
    "            batch = batch.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            node_features, distances, directions, edge_features, num_nodes, mu, log_var, property_pred = model(batch)\n",
    "\n",
    "            # Calculate loss\n",
    "            loss = model.loss_function(\n",
    "                node_features, distances, directions, edge_features, num_nodes,\n",
    "                batch, mu, log_var, property_pred,\n",
    "                recon_weight=recon_weight, kl_weight=kl_weight, property_weight=property_weight\n",
    "            )\n",
    "\n",
    "            batch_losses.append(loss.item())\n",
    "            total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(val_loader)\n",
    "\n",
    "\n",
    "# Training loop\n",
    "n_epochs = 100\n",
    "best_val_loss = float('inf')\n",
    "patience = 10\n",
    "patience_counter = 0\n",
    "\n",
    "# TODO normalise for a minimum distance!!\n",
    "# TODO !!!!! The minimal and maximal distances are from preprocessing WITHOUT CompleteGraph >____<<< !!!!!!\n",
    "#   No wonder you get fucked up distances...\n",
    "# TODO don't use a complete graph, check edge detection and use softmax (since it is one-hot) for bond type!\n",
    "batch = next(iter(train_loader))\n",
    "logging.info(f\"Target property shape: {batch.y.shape}\")\n",
    "logging.info(f\"Target property sample: {batch.y[0]}\")\n",
    "logging.info(f\"Input node features shape: {batch.x.shape}\")  # Should be (N, 11)\n",
    "logging.info(f\"Input positions shape: {batch.pos.shape}\")    # Should be (N, 3)\n",
    "logging.info(f\"Number of nodes: {batch.num_nodes}\")\n",
    "logging.info(f\"Batch size: {batch.batch.max().item() + 1}\")\n",
    "for epoch in range(n_epochs):\n",
    "    # Train\n",
    "    train_loss = train_epoch(model, optimizer, train_loader, device)\n",
    "\n",
    "    # Validate\n",
    "    val_loss = validate(model, val_loader, device)\n",
    "\n",
    "    # Learning rate scheduling\n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "    # Early stopping\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        patience_counter = 0\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= patience:\n",
    "            print(f'Early stopping at epoch {epoch}')\n",
    "            # Save best model\n",
    "            # Save model with timestamp in a more readable format\n",
    "            timestamp = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "            save_path = f'best_vae_model_{timestamp}.pt'\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            print(f'Saved best model to: {save_path}')\n",
    "            break\n",
    "\n",
    "    # Print progress\n",
    "    print(f'Epoch {epoch:03d} | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}')\n",
    "\n",
    "# Load best model for testing\n",
    "# model.load_state_dict(torch.load('best_vae_model.pt'))\n",
    "\n",
    "# Test final model\n",
    "test_loss = validate(model, test_loader, device)\n",
    "print(f'Final Test Loss: {test_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_molecule = dataset[0]\n",
    "test_molecule = test_molecule.to(device)\n",
    "\n",
    "from torch_geometric.data import Batch\n",
    "# Create a batch with a single molecule\n",
    "test_batch = Batch.from_data_list([test_molecule])\n",
    "outputs = model(test_batch)\n",
    "node_features, distances, directions, edge_features, num_nodes, mu, log_var, property_pred = outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated node features:\n",
      "tensor([[0.5131, 0.3238, 0.0774, 0.0667, 0.0009],\n",
      "        [0.5131, 0.3238, 0.0774, 0.0667, 0.0009],\n",
      "        [0.5131, 0.3238, 0.0774, 0.0667, 0.0009],\n",
      "        [0.5131, 0.3238, 0.0774, 0.0667, 0.0009],\n",
      "        [0.5131, 0.3238, 0.0774, 0.0667, 0.0009]], device='cuda:0',\n",
      "       grad_fn=<SigmoidBackward0>)\n",
      "Generated distances:\n",
      "tensor([[0.9756],\n",
      "        [0.9756],\n",
      "        [0.9756],\n",
      "        [0.9756],\n",
      "        [0.9756],\n",
      "        [0.9756],\n",
      "        [0.9756],\n",
      "        [0.9756],\n",
      "        [0.9756],\n",
      "        [0.9756],\n",
      "        [0.9756],\n",
      "        [0.9756],\n",
      "        [0.9756],\n",
      "        [0.9756],\n",
      "        [0.9756],\n",
      "        [0.9756],\n",
      "        [0.9756],\n",
      "        [0.9756],\n",
      "        [0.9756],\n",
      "        [0.9756]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Generated directions:\n",
      "tensor([[ 0.5079,  0.3173, -0.8008],\n",
      "        [ 0.5079,  0.3173, -0.8008],\n",
      "        [ 0.5079,  0.3173, -0.8008],\n",
      "        [ 0.5079,  0.3173, -0.8008],\n",
      "        [ 0.5079,  0.3173, -0.8008],\n",
      "        [ 0.5079,  0.3173, -0.8008],\n",
      "        [ 0.5079,  0.3173, -0.8008],\n",
      "        [ 0.5079,  0.3173, -0.8008],\n",
      "        [ 0.5079,  0.3173, -0.8008],\n",
      "        [ 0.5079,  0.3173, -0.8008],\n",
      "        [ 0.5079,  0.3173, -0.8008],\n",
      "        [ 0.5079,  0.3173, -0.8008],\n",
      "        [ 0.5079,  0.3173, -0.8008],\n",
      "        [ 0.5079,  0.3173, -0.8008],\n",
      "        [ 0.5079,  0.3173, -0.8008],\n",
      "        [ 0.5079,  0.3173, -0.8008],\n",
      "        [ 0.5079,  0.3173, -0.8008],\n",
      "        [ 0.5079,  0.3173, -0.8008],\n",
      "        [ 0.5079,  0.3173, -0.8008],\n",
      "        [ 0.5079,  0.3173, -0.8008]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Generated edge features:\n",
      "tensor([[2.5264e-01, 4.0718e-02, 2.3968e-02, 9.3076e-05],\n",
      "        [2.5264e-01, 4.0718e-02, 2.3968e-02, 9.3076e-05],\n",
      "        [2.5264e-01, 4.0718e-02, 2.3968e-02, 9.3076e-05],\n",
      "        [2.5264e-01, 4.0718e-02, 2.3968e-02, 9.3076e-05],\n",
      "        [2.5264e-01, 4.0718e-02, 2.3968e-02, 9.3076e-05],\n",
      "        [2.5264e-01, 4.0718e-02, 2.3968e-02, 9.3076e-05],\n",
      "        [2.5264e-01, 4.0718e-02, 2.3968e-02, 9.3076e-05],\n",
      "        [2.5264e-01, 4.0718e-02, 2.3968e-02, 9.3076e-05],\n",
      "        [2.5264e-01, 4.0718e-02, 2.3968e-02, 9.3076e-05],\n",
      "        [2.5264e-01, 4.0718e-02, 2.3968e-02, 9.3076e-05],\n",
      "        [2.5264e-01, 4.0718e-02, 2.3968e-02, 9.3076e-05],\n",
      "        [2.5264e-01, 4.0718e-02, 2.3968e-02, 9.3076e-05],\n",
      "        [2.5264e-01, 4.0718e-02, 2.3968e-02, 9.3076e-05],\n",
      "        [2.5264e-01, 4.0718e-02, 2.3968e-02, 9.3076e-05],\n",
      "        [2.5264e-01, 4.0718e-02, 2.3968e-02, 9.3076e-05],\n",
      "        [2.5264e-01, 4.0718e-02, 2.3968e-02, 9.3076e-05],\n",
      "        [2.5264e-01, 4.0718e-02, 2.3968e-02, 9.3076e-05],\n",
      "        [2.5264e-01, 4.0718e-02, 2.3968e-02, 9.3076e-05],\n",
      "        [2.5264e-01, 4.0718e-02, 2.3968e-02, 9.3076e-05],\n",
      "        [2.5264e-01, 4.0718e-02, 2.3968e-02, 9.3076e-05]], device='cuda:0',\n",
      "       grad_fn=<SigmoidBackward0>)\n",
      "Generated num_nodes:\n",
      "tensor([5.0497], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "Generated mu:\n",
      "tensor([[-1.4931, -1.1431, -0.6427,  3.0384,  5.1735, -2.8455,  5.3105,  4.4994,\n",
      "          5.1331, -0.5789,  5.2715,  2.6913,  4.9612,  0.0303, -3.9811,  4.3022,\n",
      "         -1.9181, -4.7709, -1.6884, -1.4698,  3.2799,  0.2863, -1.5041, -3.2124,\n",
      "          1.4911, -0.8922,  3.1198,  1.8566, -3.1737, -5.3321, -0.7464,  1.9608]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "Generated log_var:\n",
      "tensor([[ -9.7594, -12.1989, -11.7337,  -8.4646, -12.7572, -10.8528, -14.3956,\n",
      "         -13.9251, -13.2693, -12.6329, -13.7991, -12.1467, -13.0779, -11.5100,\n",
      "         -14.7007, -14.1452, -10.6760, -13.8893,  -9.8134, -12.9918, -13.1495,\n",
      "          -8.3689, -11.0950, -13.5496,  -7.2385, -10.6251, -14.5129, -13.5778,\n",
      "         -13.5402, -14.1881, -12.4261, -11.4211]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Generated property prediction:\n",
      "tensor([[0.3805]], device='cuda:0', grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Print the generated node features\n",
    "print(\"Generated node features:\")\n",
    "print(node_features)\n",
    "print(\"Generated distances:\")\n",
    "print(distances)\n",
    "print(\"Generated directions:\")\n",
    "print(directions)\n",
    "print(\"Generated edge features:\")\n",
    "print(edge_features)\n",
    "print(\"Generated num_nodes:\")\n",
    "print(num_nodes)\n",
    "print(\"Generated mu:\")\n",
    "print(mu)\n",
    "print(\"Generated log_var:\")\n",
    "print(log_var)\n",
    "print(\"Generated property prediction:\")\n",
    "print(property_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/3dmoljs_load.v0": "<div id=\"3dmolviewer_1745179532531168\"  style=\"position: relative; width: 300px; height: 300px;\">\n        <p id=\"3dmolwarning_1745179532531168\" style=\"background-color:#ffcccc;color:black\">3Dmol.js failed to load for some reason.  Please check your browser console for error messages.<br></p>\n        </div>\n<script>\n\nvar loadScriptAsync = function(uri){\n  return new Promise((resolve, reject) => {\n    //this is to ignore the existence of requirejs amd\n    var savedexports, savedmodule;\n    if (typeof exports !== 'undefined') savedexports = exports;\n    else exports = {}\n    if (typeof module !== 'undefined') savedmodule = module;\n    else module = {}\n\n    var tag = document.createElement('script');\n    tag.src = uri;\n    tag.async = true;\n    tag.onload = () => {\n        exports = savedexports;\n        module = savedmodule;\n        resolve();\n    };\n  var firstScriptTag = document.getElementsByTagName('script')[0];\n  firstScriptTag.parentNode.insertBefore(tag, firstScriptTag);\n});\n};\n\nif(typeof $3Dmolpromise === 'undefined') {\n$3Dmolpromise = null;\n  $3Dmolpromise = loadScriptAsync('https://cdnjs.cloudflare.com/ajax/libs/3Dmol/2.4.2/3Dmol-min.js');\n}\n\nvar viewer_1745179532531168 = null;\nvar warn = document.getElementById(\"3dmolwarning_1745179532531168\");\nif(warn) {\n    warn.parentNode.removeChild(warn);\n}\n$3Dmolpromise.then(function() {\nviewer_1745179532531168 = $3Dmol.createViewer(document.getElementById(\"3dmolviewer_1745179532531168\"),{backgroundColor:\"white\"});\nviewer_1745179532531168.zoomTo();\n\tviewer_1745179532531168.addModel(\"\\n     RDKit          3D\\n\\n  5  4  0  0  0  0  0  0  0  0999 V2000\\n    0.0000   -0.0000   -0.0000 C   0  0  0  0  0  0  0  0  0  0  0  0\\n   -0.5762   -0.1871    0.9088 H   0  0  0  0  0  0  0  0  0  0  0  0\\n    0.4536    0.9920    0.0543 H   0  0  0  0  0  0  0  0  0  0  0  0\\n   -0.6616   -0.0508   -0.8675 H   0  0  0  0  0  0  0  0  0  0  0  0\\n    0.7842   -0.7542   -0.0956 H   0  0  0  0  0  0  0  0  0  0  0  0\\n  1  2  1  0\\n  1  3  1  0\\n  1  4  1  0\\n  1  5  1  0\\nM  END\\n\",\"mol\");\n\tviewer_1745179532531168.setStyle({\"stick\": {}});\n\tviewer_1745179532531168.zoomTo();\nviewer_1745179532531168.render();\n});\n</script>",
      "text/html": [
       "<div id=\"3dmolviewer_1745179532531168\"  style=\"position: relative; width: 300px; height: 300px;\">\n",
       "        <p id=\"3dmolwarning_1745179532531168\" style=\"background-color:#ffcccc;color:black\">3Dmol.js failed to load for some reason.  Please check your browser console for error messages.<br></p>\n",
       "        </div>\n",
       "<script>\n",
       "\n",
       "var loadScriptAsync = function(uri){\n",
       "  return new Promise((resolve, reject) => {\n",
       "    //this is to ignore the existence of requirejs amd\n",
       "    var savedexports, savedmodule;\n",
       "    if (typeof exports !== 'undefined') savedexports = exports;\n",
       "    else exports = {}\n",
       "    if (typeof module !== 'undefined') savedmodule = module;\n",
       "    else module = {}\n",
       "\n",
       "    var tag = document.createElement('script');\n",
       "    tag.src = uri;\n",
       "    tag.async = true;\n",
       "    tag.onload = () => {\n",
       "        exports = savedexports;\n",
       "        module = savedmodule;\n",
       "        resolve();\n",
       "    };\n",
       "  var firstScriptTag = document.getElementsByTagName('script')[0];\n",
       "  firstScriptTag.parentNode.insertBefore(tag, firstScriptTag);\n",
       "});\n",
       "};\n",
       "\n",
       "if(typeof $3Dmolpromise === 'undefined') {\n",
       "$3Dmolpromise = null;\n",
       "  $3Dmolpromise = loadScriptAsync('https://cdnjs.cloudflare.com/ajax/libs/3Dmol/2.4.2/3Dmol-min.js');\n",
       "}\n",
       "\n",
       "var viewer_1745179532531168 = null;\n",
       "var warn = document.getElementById(\"3dmolwarning_1745179532531168\");\n",
       "if(warn) {\n",
       "    warn.parentNode.removeChild(warn);\n",
       "}\n",
       "$3Dmolpromise.then(function() {\n",
       "viewer_1745179532531168 = $3Dmol.createViewer(document.getElementById(\"3dmolviewer_1745179532531168\"),{backgroundColor:\"white\"});\n",
       "viewer_1745179532531168.zoomTo();\n",
       "\tviewer_1745179532531168.addModel(\"\\n     RDKit          3D\\n\\n  5  4  0  0  0  0  0  0  0  0999 V2000\\n    0.0000   -0.0000   -0.0000 C   0  0  0  0  0  0  0  0  0  0  0  0\\n   -0.5762   -0.1871    0.9088 H   0  0  0  0  0  0  0  0  0  0  0  0\\n    0.4536    0.9920    0.0543 H   0  0  0  0  0  0  0  0  0  0  0  0\\n   -0.6616   -0.0508   -0.8675 H   0  0  0  0  0  0  0  0  0  0  0  0\\n    0.7842   -0.7542   -0.0956 H   0  0  0  0  0  0  0  0  0  0  0  0\\n  1  2  1  0\\n  1  3  1  0\\n  1  4  1  0\\n  1  5  1  0\\nM  END\\n\",\"mol\");\n",
       "\tviewer_1745179532531168.setStyle({\"stick\": {}});\n",
       "\tviewer_1745179532531168.zoomTo();\n",
       "viewer_1745179532531168.render();\n",
       "});\n",
       "</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<py3Dmol.view at 0x7fd40204b620>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mygenai.utils.visualisation import visualise_molecule\n",
    "visualise_molecule(test_molecule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-20 22:15:35,154 - PropertyConditionedVAE - DEBUG - Input data - batch_size: 100, nodes: 1005\n",
      "2025-04-20 22:15:35,154 - PropertyConditionedVAE - DEBUG - Forward called without target_property (None)\n",
      "2025-04-20 22:15:35,157 - PropertyConditionedVAE - DEBUG - Encoder outputs - mu: torch.Size([100, 32]), log_var: torch.Size([100, 32]), property_pred: torch.Size([100, 1])\n",
      "2025-04-20 22:15:35,158 - PropertyConditionedVAE - DEBUG - Sampled z shape: torch.Size([100, 32])\n",
      "2025-04-20 22:15:35,158 - PropertyConditionedVAE - DEBUG - Using encoder prediction for property, shape: torch.Size([100, 1])\n",
      "2025-04-20 22:15:35,161 - PropertyConditionedVAE - DEBUG - Decoder outputs - node_features: torch.Size([1005, 5]), distances: torch.Size([10070, 1]), directions: torch.Size([10070, 3]), edge_features: torch.Size([10070, 4]), num_nodes: tensor([ 5.0497,  4.1476,  3.2143,  3.9463,  2.7335,  3.9900,  8.1959,  6.0648,\n",
      "         7.1128,  6.0964,  7.1026,  6.1230, 11.0618,  9.1959,  9.2088,  9.1748,\n",
      "         7.0867, 10.1681,  9.2303,  8.2218, 14.1310, 12.1423,  6.0138,  5.0495,\n",
      "         3.9108,  6.0440,  5.1101,  6.0573, 10.2043, 10.1809,  9.2224,  8.1946,\n",
      "         8.1760,  7.1230, 10.1608,  9.2309,  8.1667,  8.1545, 14.1338, 12.1415,\n",
      "        12.1465, 10.1613, 12.1187, 10.1624, 11.1417, 10.1526, 12.1156, 10.1552,\n",
      "        12.1653, 10.1503,  9.1841,  9.1720,  8.1120, 17.1554, 15.1755,  9.1902,\n",
      "         8.1200,  8.1405,  9.2026,  8.1552, 13.1370, 12.1617, 11.1665, 11.1458,\n",
      "        10.1755, 13.1500, 11.1680, 12.1636, 11.1707, 13.1431, 12.1702, 12.1610,\n",
      "        11.1906, 12.1634, 11.1786, 10.1961, 10.1898, 15.1739, 13.1523, 17.1544,\n",
      "        15.1722, 15.1728, 15.1740, 13.1476, 13.1484, 10.1714, 11.1346, 10.1659,\n",
      "         9.1858, 10.1652,  9.1915, 15.1721, 13.1461, 13.1484, 13.1493, 11.1659,\n",
      "        15.1720, 13.1467, 14.1443, 13.1445], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# import importlib\n",
    "# import mygenai.models.graphvae\n",
    "# from mygenai.models.graphvae import PropertyConditionedVAE\n",
    "# importlib.reload(mygenai.models.graphvae)\n",
    "logging.getLogger('PropertyConditionedVAE').setLevel(logging.DEBUG)\n",
    "batch_data = dataset[:100]\n",
    "batch = Batch.from_data_list(batch_data).to(device)\n",
    "with torch.no_grad():  # Disable gradient computation\n",
    "    outputs = model(batch)\n",
    "node_features, distances, directions, edge_features, num_nodes, mu, log_var, property_pred = outputs\n",
    "\n",
    "# Compute the loss\n",
    "loss = model.loss_function(\n",
    "    node_features=node_features,\n",
    "    distances=distances,\n",
    "    directions=directions,\n",
    "    edge_features=edge_features,\n",
    "    num_nodes=num_nodes,\n",
    "    data=batch,\n",
    "    mu=mu,\n",
    "    log_var=log_var,\n",
    "    property_pred=property_pred,\n",
    "    property_weight=property_weight,  # Use the same weights as during training\n",
    "    recon_weight=recon_weight,\n",
    "    kl_weight=kl_weight\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
