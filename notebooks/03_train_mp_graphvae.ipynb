{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Message-Passing Graph Variational Autoencoder\n",
    "\n",
    "Here I will use principles from message-passing graph neural networks to try to generate\n",
    "molecules in a graph variational autoencoder. This is based on my solutions to \n",
    "`geometric-gnn-dojo/geometric_gnn_101.ipynb`\n",
    "Some of the code has also been taken from there\n",
    "\n",
    "might also want to consider autoregressive model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version 2.5.0+cu124\n",
      "PyG version 2.6.1\n"
     ]
    }
   ],
   "source": [
    "#@title [RUN] Import python modules\n",
    "\n",
    "import logging\n",
    "\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "from scipy.stats import ortho_group\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Linear, ReLU, BatchNorm1d, Module, Sequential, Sigmoid\n",
    "\n",
    "import torch_geometric\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.data import Batch\n",
    "from torch_geometric.datasets import QM9\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.utils import remove_self_loops, to_dense_adj, dense_to_sparse\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import MessagePassing, global_mean_pool\n",
    "from torch_geometric.datasets import QM9\n",
    "from torch_scatter import scatter\n",
    "\n",
    "import rdkit.Chem as Chem\n",
    "from rdkit.Geometry.rdGeometry import Point3D\n",
    "from rdkit.Chem import QED, Crippen, rdMolDescriptors, rdmolops\n",
    "from rdkit.Chem.Draw import IPythonConsole\n",
    "\n",
    "import py3Dmol\n",
    "from rdkit.Chem import AllChem\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# from google.colab import files\n",
    "from IPython.display import HTML\n",
    "\n",
    "print(\"PyTorch version {}\".format(torch.__version__))\n",
    "print(\"PyG version {}\".format(torch_geometric.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Debug mode is OFF\n"
     ]
    }
   ],
   "source": [
    "debug_print = False\n",
    "if debug_print:\n",
    "    print(\"Debug mode is ON\")\n",
    "    logging.basicConfig(\n",
    "        level=logging.DEBUG,\n",
    "        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "        force=True  # Ensure configuration is applied\n",
    "    )\n",
    "    for logger_name in ['train_epoch', 'PropertyConditionedVAE', 'ConditionalDecoder', 'Encoder']:\n",
    "        logging.getLogger(logger_name).setLevel(logging.DEBUG)\n",
    "else:\n",
    "    print(\"Debug mode is OFF\")\n",
    "    logging.basicConfig(\n",
    "        level=logging.INFO,\n",
    "        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "        force=True  # Ensure configuration is applied\n",
    "    )\n",
    "    for logger_name in ['train_epoch', 'PropertyConditionedVAE', 'ConditionalDecoder', 'Encoder']:\n",
    "        logging.getLogger(logger_name).setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CompleteGraph(object):\n",
    "    \"\"\"\n",
    "    This transform adds all pairwise edges into the edge index per data sample,\n",
    "    then removes self loops, i.e. it builds a fully connected or complete graph\n",
    "    \"\"\"\n",
    "    def __call__(self, data):\n",
    "        device = data.edge_index.device\n",
    "\n",
    "        row = torch.arange(data.num_nodes, dtype=torch.long, device=device)\n",
    "        col = torch.arange(data.num_nodes, dtype=torch.long, device=device)\n",
    "\n",
    "        row = row.view(-1, 1).repeat(1, data.num_nodes).view(-1)\n",
    "        col = col.repeat(data.num_nodes)\n",
    "        edge_index = torch.stack([row, col], dim=0)\n",
    "\n",
    "        edge_attr = None\n",
    "        if data.edge_attr is not None:\n",
    "            idx = data.edge_index[0] * data.num_nodes + data.edge_index[1]\n",
    "            size = list(data.edge_attr.size())\n",
    "            size[0] = data.num_nodes * data.num_nodes\n",
    "            edge_attr = data.edge_attr.new_zeros(size)\n",
    "            edge_attr[idx] = data.edge_attr\n",
    "\n",
    "        edge_index, edge_attr = remove_self_loops(edge_index, edge_attr)\n",
    "        data.edge_attr = edge_attr\n",
    "        data.edge_index = edge_index\n",
    "\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jph/dev/generative-molecular-design/.conda/lib/python3.12/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch_geometric.utils import to_dense_batch\n",
    "import torch_geometric as pyg\n",
    "import torch_geometric.nn as pyg_nn\n",
    "from torch_geometric.datasets import QM9\n",
    "from torch_geometric.loader import DataLoader\n",
    "import mygenai\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "dataset = QM9(root=\"../data/QM9\", transform=CompleteGraph())\n",
    "# Normalize targets per data sample to mean = 0 and std = 1.\n",
    "mean = dataset.data.y.mean(dim=0, keepdim=True)\n",
    "std = dataset.data.y.std(dim=0, keepdim=True)\n",
    "dataset.data.y = (dataset.data.y - mean) / std\n",
    "# mean, std = mean[:, target].item(), std[:, target].item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First, some review\n",
    "This is the non-generative model that simply predicts properties based on input "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:3: SyntaxWarning: invalid escape sequence '\\o'\n",
      "<>:3: SyntaxWarning: invalid escape sequence '\\o'\n",
      "/tmp/ipykernel_37680/3876908471.py:3: SyntaxWarning: invalid escape sequence '\\o'\n",
      "  \"\"\"Message Passing Neural Network Layer\n"
     ]
    }
   ],
   "source": [
    "class EquivariantMPNNLayer(MessagePassing):\n",
    "    def __init__(self, emb_dim=64, edge_dim=4, aggr='add'):\n",
    "        \"\"\"Message Passing Neural Network Layer\n",
    "\n",
    "        This layer is equivariant to 3D rotations and translations.\n",
    "\n",
    "        Args:\n",
    "            emb_dim: (int) - hidden dimension `d`\n",
    "            edge_dim: (int) - edge feature dimension `d_e`\n",
    "            aggr: (str) - aggregation function `\\oplus` (sum/mean/max)\n",
    "        \"\"\"\n",
    "        # Set the aggregation function\n",
    "        super().__init__(aggr=aggr)\n",
    "\n",
    "        self.emb_dim = emb_dim\n",
    "        self.edge_dim = edge_dim\n",
    "\n",
    "        self.mlp_scalar = Sequential(\n",
    "            Linear(2*emb_dim + edge_dim + 1, emb_dim),  # +1 for distance\n",
    "            BatchNorm1d(emb_dim),\n",
    "            ReLU()\n",
    "        )\n",
    "        self.mlp_vector = Sequential(\n",
    "            Linear(2*emb_dim + edge_dim + 1, 1),  # Input: [h_i, h_j, edge_attr, dist]\n",
    "            BatchNorm1d(1),\n",
    "            ReLU()\n",
    "        )\n",
    "\n",
    "        # update MLPs\n",
    "        self.mlp_h = Sequential(\n",
    "            Linear(2*emb_dim, emb_dim), BatchNorm1d(emb_dim), ReLU(),\n",
    "            Linear(emb_dim, emb_dim), BatchNorm1d(emb_dim), ReLU()\n",
    "        )\n",
    "        self.mlp_pos = Sequential(\n",
    "            Linear(emb_dim, emb_dim), BatchNorm1d(emb_dim), ReLU(),\n",
    "            Linear(emb_dim, 1), BatchNorm1d(1), ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, h, pos, edge_index, edge_attr):\n",
    "        \"\"\"\n",
    "        The forward pass updates node features `h` via one round of message passing.\n",
    "\n",
    "        Args:\n",
    "            h: (n, d) - initial node features\n",
    "            pos: (n, 3) - initial node coordinates\n",
    "            edge_index: (e, 2) - pairs of edges (i, j)\n",
    "            edge_attr: (e, d_e) - edge features\n",
    "\n",
    "        Returns:\n",
    "            out: [(n, d),(n,3)] - updated node features\n",
    "        \"\"\"\n",
    "        return self.propagate(edge_index, h=h, pos=pos, edge_attr=edge_attr)\n",
    "\n",
    "    def message(self, h_i, h_j, pos_i, pos_j, edge_attr):\n",
    "        r_ij = pos_j - pos_i # equivariant\n",
    "        dist = torch.norm(r_ij, dim=-1, keepdim=True)  # invariant\n",
    "\n",
    "        # Scalar message (invariant features)\n",
    "        scalar_inputs = torch.cat([h_i, h_j, edge_attr, dist], dim=-1)\n",
    "        scalar_msg = self.mlp_scalar(scalar_inputs)\n",
    "\n",
    "        # Vector message (equivariant coordinates)\n",
    "        # vector message should only depend on rotation/translation invariant quantities\n",
    "        vector_inputs = torch.cat([h_i, h_j, edge_attr, dist], dim=-1)\n",
    "        scale = self.mlp_vector(vector_inputs) # (e, 1)\n",
    "        vector_msg = scale * r_ij # (e, 3)\n",
    "\n",
    "        return scalar_msg, vector_msg\n",
    "\n",
    "    def aggregate(self, inputs, index):\n",
    "        scalar_msgs, vector_msgs = inputs\n",
    "        scalar_aggr = scatter(scalar_msgs, index, dim=self.node_dim, reduce=self.aggr)\n",
    "        vector_aggr = scatter(vector_msgs, index, dim=self.node_dim, reduce=self.aggr)\n",
    "        return scalar_aggr, vector_aggr\n",
    "\n",
    "    def update(self, aggr_out, h, pos):\n",
    "        scalar_aggr, vector_aggr = aggr_out\n",
    "\n",
    "        # Update node features (h)\n",
    "        h_update = self.mlp_h(torch.cat([h, scalar_aggr], dim=-1))\n",
    "\n",
    "        # Update node positions (pos)\n",
    "        scale = self.mlp_pos(scalar_aggr) # (n, 1)\n",
    "        pos_update = pos + scale * vector_aggr  # (n, 3)\n",
    "\n",
    "        return h_update, pos_update\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return (f'{self.__class__.__name__}(emb_dim={self.emb_dim}, aggr={self.aggr})')\n",
    "\n",
    "\n",
    "class EquivariantGNNPredictor(Module):\n",
    "    def __init__(self, num_layers=4, emb_dim=64, in_dim=11, edge_dim=4, out_dim=1):\n",
    "        \"\"\"Message Passing Neural Network model for graph property prediction\n",
    "\n",
    "        This model uses both node features and coordinates as inputs, and\n",
    "        is invariant to 3D rotations and translations (the constituent MPNN layers\n",
    "        are equivariant to 3D rotations and translations).\n",
    "\n",
    "        Args:\n",
    "            num_layers: (int) - number of message passing layers `L`\n",
    "            emb_dim: (int) - hidden dimension `d`\n",
    "            in_dim: (int) - initial node feature dimension `d_n`\n",
    "            edge_dim: (int) - edge feature dimension `d_e`\n",
    "            out_dim: (int) - output dimension (fixed to 1)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        # Linear projection for initial node features\n",
    "        # dim: d_n -> d\n",
    "        self.lin_in = Linear(in_dim, emb_dim)\n",
    "\n",
    "        # Stack of MPNN layers\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        for layer in range(num_layers):\n",
    "            self.convs.append(EquivariantMPNNLayer(emb_dim, edge_dim, aggr='add'))\n",
    "\n",
    "        # Global pooling/readout function `R` (mean pooling)\n",
    "        # PyG handles the underlying logic via `global_mean_pool()`\n",
    "        self.pool = global_mean_pool\n",
    "\n",
    "        # Linear prediction head\n",
    "        # dim: d -> out_dim\n",
    "        self.lin_pred = Linear(emb_dim, out_dim)\n",
    "\n",
    "    def forward(self, data):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            data: (PyG.Data) - batch of PyG graphs\n",
    "\n",
    "        Returns:\n",
    "            out: (batch_size, out_dim) - prediction for each graph\n",
    "        \"\"\"\n",
    "        h = self.lin_in(data.x) # (n, d_n) -> (n, d)\n",
    "        pos = data.pos\n",
    "\n",
    "        for conv in self.convs:\n",
    "            # Message passing layer\n",
    "            h_update, pos_update = conv(h, pos, data.edge_index, data.edge_attr)\n",
    "\n",
    "            # Update node features\n",
    "            h = h + h_update # (n, d) -> (n, d)\n",
    "            # Note that we add a residual connection after each MPNN layer\n",
    "\n",
    "            # Update node coordinates\n",
    "            pos = pos_update # (n, 3) -> (n, 3)\n",
    "\n",
    "        h_graph = self.pool(h, data.batch) # (n, d) -> (batch_size, d)\n",
    "\n",
    "        out = self.lin_pred(h_graph) # (batch_size, d) -> (batch_size, 1)\n",
    "\n",
    "        return out.view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EquivariantGNNPredictor(num_layers=4, emb_dim=64, in_dim=11, edge_dim=4, out_dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unit test\n",
    "def random_orthogonal_matrix(dim=3):\n",
    "  \"\"\"Helper function to build a random orthogonal matrix of shape (dim, dim)\n",
    "  \"\"\"\n",
    "  Q = torch.tensor(ortho_group.rvs(dim=dim)).float()\n",
    "  return Q\n",
    "\n",
    "\n",
    "def rot_trans_invariance_unit_test(module, dataloader):\n",
    "    \"\"\"Unit test for checking whether a module (GNN model/layer) is\n",
    "    rotation and translation invariant.\n",
    "    \"\"\"\n",
    "    it = iter(dataloader)\n",
    "    data = next(it)\n",
    "\n",
    "    # Forward pass on original example\n",
    "    # Note: We have written a conditional forward pass so that the same unit\n",
    "    #       test can be used for both the GNN model as well as the layer.\n",
    "    #       The functionality for layers will be useful subsequently.\n",
    "    # if isinstance(module, MPNNModel):\n",
    "    out_1 = module(data)\n",
    "    # else: # if ininstance(module, MessagePassing):\n",
    "        # out_1 = module(data.x, data.pos, data.edge_index, data.edge_attr)\n",
    "\n",
    "    Q = random_orthogonal_matrix(dim=3)\n",
    "    t = torch.rand(3)\n",
    "    # ============ YOUR CODE HERE ==============\n",
    "    # Perform random rotation + translation on data.\n",
    "    #\n",
    "    data.pos = data.pos @ Q  + t\n",
    "    # ==========================================\n",
    "\n",
    "    # Forward pass on rotated + translated example\n",
    "    # if isinstance(module, MPNNModel):\n",
    "    out_2 = module(data)\n",
    "    # else: # if ininstance(module, MessagePassing):\n",
    "        # out_2 = module(data.x, data.pos, data.edge_index, data.edge_attr)\n",
    "\n",
    "    # ============ YOUR CODE HERE ==============\n",
    "    # Check whether output varies after applying transformations.\n",
    "    #\n",
    "    return torch.allclose(out_1, out_2, atol=1e-04)\n",
    "    # ==========================================\n",
    "\n",
    "def rot_trans_equivariance_unit_test(module, dataloader):\n",
    "    \"\"\"Unit test for checking whether a module (GNN layer) is\n",
    "    rotation and translation equivariant.\n",
    "    \"\"\"\n",
    "    it = iter(dataloader)\n",
    "    data = next(it)\n",
    "\n",
    "    out_1, pos_1 = module(data.x, data.pos, data.edge_index, data.edge_attr)\n",
    "\n",
    "    Q = random_orthogonal_matrix(dim=3)\n",
    "    t = torch.rand(3)\n",
    "    # ============ YOUR CODE HERE ==============\n",
    "    # Perform random rotation + translation on data.\n",
    "    #\n",
    "    data.pos = data.pos @ Q + t # row vectors => post-multiply Q\n",
    "    # ==========================================\n",
    "\n",
    "    # Forward pass on rotated + translated example\n",
    "    out_2, pos_2 = module(data.x, data.pos, data.edge_index, data.edge_attr)\n",
    "\n",
    "    # ============ YOUR CODE HERE ==============\n",
    "    # Check whether output varies after applying transformations.\n",
    "    return torch.allclose(out_1, out_2, atol=1e-04) and torch.allclose(pos_1 @ Q + t, pos_2, atol=1e-04)\n",
    "    # =========================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is EquivariantGNNPredictor rotation and translation invariant? --> True!\n",
      "Is EquivariantMPNNLayer rotation and translation equivariant? --> True!\n"
     ]
    }
   ],
   "source": [
    "# ============ YOUR CODE HERE ==============\n",
    "# Instantiate temporary model, layer, and dataloader for unit testing.\n",
    "# Remember that we are now unit testing the EquivariantGNNPredictor,\n",
    "# which is  composed of the EquivariantMPNNLayer.\n",
    "#\n",
    "layer = EquivariantMPNNLayer(emb_dim=11, edge_dim=4)\n",
    "model = EquivariantGNNPredictor(num_layers=4, emb_dim=64, in_dim=11, edge_dim=4, out_dim=1)\n",
    "# ==========================================\n",
    "dataloader = DataLoader(dataset[:1000], batch_size=1, shuffle=True)\n",
    "\n",
    "# Rotation and translation invariance unit test for MPNN model\n",
    "print(f\"Is {type(model).__name__} rotation and translation invariant? --> {rot_trans_invariance_unit_test(model, dataloader)}!\")\n",
    "\n",
    "# Rotation and translation invariance unit test for MPNN layer\n",
    "print(f\"Is {type(layer).__name__} rotation and translation equivariant? --> {rot_trans_equivariance_unit_test(layer, dataloader)}!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now trying an encoder-decoder architecture\n",
    "class Encoder(Module):\n",
    "    def __init__(self, emb_dim=64, in_dim=11, edge_dim=4, latent_dim=32):\n",
    "        \"\"\"Encoder module for graph property prediction\n",
    "\n",
    "        Args:\n",
    "            emb_dim: (int) - hidden dimension `d`\n",
    "            in_dim: (int) - initial node feature dimension `d_n`\n",
    "            edge_dim: (int) - edge feature dimension `d_e`\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        # Linear projection for initial node features\n",
    "        # dim: d_n -> d\n",
    "        self.lin_in = Linear(in_dim, emb_dim)\n",
    "\n",
    "        # Stack of MPNN layers\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        for layer in range(2):\n",
    "            self.convs.append(EquivariantMPNNLayer(emb_dim, edge_dim, aggr='add'))\n",
    "\n",
    "        # Global pooling/readout function `R` (mean pooling)\n",
    "        # PyG handles the underlying logic via `global_mean_pool()`\n",
    "        self.pool = global_mean_pool\n",
    "\n",
    "        # projections to latent space\n",
    "        self.mu = Linear(emb_dim, latent_dim)\n",
    "        self.log_var = Linear(emb_dim, latent_dim)\n",
    "\n",
    "        # Property prediction (only one: homo-lumo gap)\n",
    "        self.property_predictor = Sequential(\n",
    "            Linear(latent_dim, emb_dim),\n",
    "            ReLU(),\n",
    "            BatchNorm1d(emb_dim),\n",
    "            Linear(emb_dim, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, data):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            data: (PyG.Data) - batch of PyG graphs\n",
    "\n",
    "        Returns:\n",
    "            out: [(batch_size, d),(batch_size,3)] - updated node features\n",
    "        \"\"\"\n",
    "        h = self.lin_in(data.x) # (n, d_n) -> (n, d)\n",
    "        pos = data.pos\n",
    "\n",
    "        for conv in self.convs:\n",
    "            # Message passing layer\n",
    "            h_update, pos_update = conv(h, pos, data.edge_index, data.edge_attr)\n",
    "\n",
    "            # Update node features\n",
    "            h = h + h_update # (n, d) -> (n, d)\n",
    "\n",
    "            # Update node coordinates\n",
    "            pos = pos_update # (n, 3) -> (n, 3)\n",
    "\n",
    "        # Pool to graph level\n",
    "        h_graph = self.pool(h, data.batch) # (n, d) -> (batch_size, d)\n",
    "\n",
    "        # Get latent parameters and property prediction\n",
    "        mu = self.mu(h_graph)\n",
    "        log_var = self.log_var(h_graph)\n",
    "        property_pred = self.property_predictor(mu)\n",
    "\n",
    "        return mu, log_var, property_pred\n",
    "\n",
    "class ConditionalDecoder(Module):\n",
    "    def __init__(self, latent_dim=32, emb_dim=64, out_node_dim=11, out_edge_dim=4):\n",
    "        super().__init__()\n",
    "        self.logger = logging.getLogger(self.__class__.__name__)\n",
    "\n",
    "        # Initial projection from latent+property space\n",
    "        # expect one property\n",
    "        self.lin_latent = Linear(latent_dim + 1, emb_dim)\n",
    "\n",
    "        # Node feature generation\n",
    "        self.node_decoder = Sequential(\n",
    "            Linear(emb_dim, emb_dim),\n",
    "            ReLU(),\n",
    "            BatchNorm1d(emb_dim),\n",
    "            Linear(emb_dim, out_node_dim)\n",
    "        )\n",
    "\n",
    "        # Position generation\n",
    "        self.pos_decoder = Sequential(\n",
    "            Linear(emb_dim, emb_dim),\n",
    "            ReLU(),\n",
    "            BatchNorm1d(emb_dim),\n",
    "            Linear(emb_dim, 3)\n",
    "        )\n",
    "\n",
    "        # Number of nodes predictor\n",
    "        self.num_nodes_predictor = Sequential(\n",
    "            Linear(emb_dim, emb_dim),\n",
    "            ReLU(),\n",
    "            Linear(emb_dim, 1)\n",
    "        )\n",
    "\n",
    "        # Edge prediction\n",
    "        self.edge_existence = Sequential(\n",
    "            Linear(2 * emb_dim, emb_dim),\n",
    "            ReLU(),\n",
    "            BatchNorm1d(emb_dim),\n",
    "            Linear(emb_dim, 1),\n",
    "            Sigmoid()\n",
    "        )\n",
    "\n",
    "        self.edge_features = Sequential(\n",
    "            Linear(2 * emb_dim, emb_dim),\n",
    "            ReLU(),\n",
    "            BatchNorm1d(emb_dim),\n",
    "            Linear(emb_dim, out_edge_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, z, target_property, batch_size):\n",
    "        self.logger.debug(f\"Input shapes - z: {z.shape}, target_property: {target_property.shape}\")\n",
    "\n",
    "        # Make sure target_property has correct shape for concatenation\n",
    "        if target_property.dim() == 3:\n",
    "            target_property = target_property.squeeze(1)\n",
    "        if target_property.dim() == 1:\n",
    "            target_property = target_property.unsqueeze(1)\n",
    "\n",
    "        z_cond = torch.cat([z, target_property], dim=1)\n",
    "        h = self.lin_latent(z_cond)\n",
    "\n",
    "        # Predict number of nodes per graph\n",
    "        num_nodes = self.num_nodes_predictor(h).sigmoid() * 30 + 5  # 5-35 nodes\n",
    "        num_nodes = num_nodes.long()\n",
    "\n",
    "        node_features_list = []\n",
    "        positions_list = []\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            n = num_nodes[i].item()  # Convert tensor to integer\n",
    "            h_expanded = h[i:i+1].expand(n, -1)\n",
    "\n",
    "            # Generate node features and positions\n",
    "            node_feat = self.node_decoder(h_expanded)\n",
    "            pos = self.pos_decoder(h_expanded)\n",
    "\n",
    "            node_features_list.append(node_feat)\n",
    "            positions_list.append(pos)\n",
    "\n",
    "        node_features = torch.cat(node_features_list, dim=0)\n",
    "        positions = torch.cat(positions_list, dim=0)\n",
    "\n",
    "        self.logger.debug(f\"Output shapes - node_features: {node_features.shape}, positions: {positions.shape}\")\n",
    "\n",
    "        return node_features, positions, num_nodes\n",
    "\n",
    "class PropertyConditionedVAE(Module):\n",
    "    def __init__(self, num_layers=4, emb_dim=64, in_dim=11, edge_dim=4, latent_dim=32):\n",
    "        super().__init__()\n",
    "        self.logger = logging.getLogger(self.__class__.__name__)\n",
    "\n",
    "        self.encoder = Encoder(emb_dim, in_dim, edge_dim, latent_dim)\n",
    "        self.decoder = ConditionalDecoder(latent_dim, emb_dim, in_dim)\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "    def reparameterize(self, mu, log_var):\n",
    "        if self.training:\n",
    "            std = torch.exp(0.5 * log_var)\n",
    "            eps = torch.randn_like(std)\n",
    "            return mu + eps * std\n",
    "        return mu\n",
    "\n",
    "    def forward(self, data, target_property=None):\n",
    "        logger = logging.getLogger('PropertyConditionedVAE')\n",
    "\n",
    "        # Encode\n",
    "        mu, log_var, property_pred = self.encoder(data)\n",
    "        logger.debug(f\"Encoder outputs - mu: {mu.shape}, log_var: {log_var.shape}, property_pred: {property_pred.shape}\")\n",
    "\n",
    "        # Sample from latent space\n",
    "        z = self.reparameterize(mu, log_var)\n",
    "        logger.debug(f\"Sampled z shape: {z.shape}\")\n",
    "\n",
    "        # Use predicted property if target not provided\n",
    "        if target_property is None:\n",
    "            target_property = property_pred\n",
    "        else:\n",
    "            # if all properties provided, extract just the HOMO-LUMO gap\n",
    "            if target_property.size(1) != 1:\n",
    "                target_property = target_property[:, 4:5]\n",
    "        logger.debug(f\"Target property shape before squeeze: {target_property.shape}\")\n",
    "\n",
    "        # # Ensure target_property is 2D\n",
    "        # if len(target_property.shape) == 3:\n",
    "        #     target_property = target_property.squeeze(1)\n",
    "        # logger.debug(f\"Target property shape after squeeze: {target_property.shape}\")\n",
    "\n",
    "        # Decode\n",
    "        node_features, positions, num_nodes = self.decoder(\n",
    "            z, target_property, data.batch.max().item() + 1\n",
    "        )\n",
    "        logger.debug(f\"Decoder outputs - features: {node_features.shape}, positions: {positions.shape}\")\n",
    "\n",
    "        return node_features, positions, mu, log_var, property_pred, num_nodes\n",
    "\n",
    "    def loss_function(self, node_features, positions, num_nodes, data, mu, log_var,\n",
    "                    property_pred, property_weight=1.0):\n",
    "        logger = logging.getLogger(self.__class__.__name__)\n",
    "\n",
    "        # Log shapes for debugging\n",
    "        logger.debug(f\"Property prediction shape: {property_pred.shape}\")\n",
    "        logger.debug(f\"Target property shape: {data.y.shape}\")\n",
    "\n",
    "        # Get batch size\n",
    "        batch_size = data.batch.max().item() + 1\n",
    "\n",
    "        # Reconstruction loss (with proper masking for variable size graphs)\n",
    "        recon_loss = 0\n",
    "        start_idx = 0\n",
    "        total_nodes = 0\n",
    "\n",
    "        for i, n in enumerate(num_nodes):\n",
    "            n_orig = (data.batch == i).sum()\n",
    "            n_gen = n.item()\n",
    "            nodes_to_compare = min(n_gen, n_orig)\n",
    "            total_nodes += nodes_to_compare\n",
    "\n",
    "            if nodes_to_compare > 0:\n",
    "                # Node feature reconstruction - use sum reduction\n",
    "                recon_loss += F.mse_loss(\n",
    "                    node_features[start_idx:start_idx + nodes_to_compare],\n",
    "                    data.x[data.batch == i][:nodes_to_compare],\n",
    "                    reduction='sum'  # Sum within each graph\n",
    "                )\n",
    "\n",
    "                # Position reconstruction - use sum reduction\n",
    "                recon_loss += F.mse_loss(\n",
    "                    positions[start_idx:start_idx + nodes_to_compare],\n",
    "                    data.pos[data.batch == i][:nodes_to_compare],\n",
    "                    reduction='sum'  # Sum within each graph\n",
    "                )\n",
    "\n",
    "            start_idx += n_gen\n",
    "\n",
    "        # Normalize reconstruction loss by total nodes compared\n",
    "        if total_nodes > 0:\n",
    "            recon_loss = recon_loss / total_nodes\n",
    "\n",
    "        # KL divergence (already normalized by batch size)\n",
    "        kl_loss = -0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp()) / batch_size\n",
    "\n",
    "        # # Property prediction loss - ensure shapes match\n",
    "        # if property_pred.shape != data.y.shape:\n",
    "        #     logger.warning(f\"Property shape mismatch: pred={property_pred.shape}, target={data.y.shape}\")\n",
    "        #     # Fix the shape of either property_pred or data.y to match\n",
    "        #     if property_pred.size(1) == 1 and data.y.size(1) > 1:\n",
    "        #         # Need to modify your model to output the correct shape (19 columns)\n",
    "        #         # As a temporary fix, repeat the single value to match the target width\n",
    "        #         property_pred = property_pred.expand(-1, data.y.size(1))\n",
    "\n",
    "        target_property = data.y[:, 4:5]  # HOMO-LUMO gap, keep dimension as [batch_size, 1]\n",
    "        prop_loss = F.mse_loss(property_pred, target_property, reduction='mean')\n",
    "\n",
    "        # Combine losses with scaling factors\n",
    "        # Use smaller coefficients to prevent overflow\n",
    "        total_loss = recon_loss + 0.01 * kl_loss + 0.1 * property_weight * prop_loss\n",
    "\n",
    "        # Add guard against NaN or Inf\n",
    "        if not torch.isfinite(total_loss):\n",
    "            logger.error(f\"Non-finite loss detected! recon={recon_loss}, kl={kl_loss}, prop={prop_loss}\")\n",
    "            # Return a backup loss that won't break training\n",
    "            return torch.tensor(1000.0, device=total_loss.device, requires_grad=True)\n",
    "\n",
    "        # Log component values for debugging\n",
    "        if logger.isEnabledFor(logging.DEBUG):\n",
    "            logger.debug(f\"Losses - recon: {recon_loss.item():.4f}, KL: {kl_loss.item():.4f}, prop: {prop_loss.item():.4f}, total: {total_loss.item():.4f}\")\n",
    "\n",
    "        return total_loss\n",
    "\n",
    "    def generate_molecule(self, target_property, num_samples=1):\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            # Sample from prior\n",
    "            z = torch.randn(num_samples, self.latent_dim).to(next(self.parameters()).device)\n",
    "            target = torch.ones(num_samples, 1).to(z.device) * target_property # single value for homo-lumo gap\n",
    "\n",
    "            # Generate\n",
    "            node_features, positions, num_nodes = self.decoder(z, target, num_samples)\n",
    "\n",
    "            return node_features, positions, num_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data splitting (60/20/20)\n",
    "train_val_idx, test_idx = train_test_split(\n",
    "    np.arange(len(dataset)),\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "train_idx, val_idx = train_test_split(\n",
    "    train_val_idx,\n",
    "    test_size=0.25,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(dataset[train_idx], batch_size=128, shuffle=True)\n",
    "val_loader = DataLoader(dataset[val_idx], batch_size=128, shuffle=False)\n",
    "test_loader = DataLoader(dataset[test_idx], batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target property shape: torch.Size([128, 19])\n",
      "Target property sample: tensor([ 1.7801, -0.4565, -0.2499,  0.1850,  0.2999, -0.5561, -0.3152, -0.1797,\n",
      "        -0.1798, -0.1798, -0.1797, -0.8097,  0.3219,  0.3204,  0.3207,  0.3240,\n",
      "        -0.0039,  0.1084,  0.0737])\n",
      "Input node features shape: torch.Size([2241, 11])\n",
      "Input positions shape: torch.Size([2241, 3])\n",
      "Number of nodes: 2241\n",
      "Batch size: 128\n",
      "Epoch 000 | Train Loss: 23.5831 | Val Loss: 235483165571.1219\n",
      "Epoch 001 | Train Loss: 24.9270 | Val Loss: 286896091551754.0000\n",
      "Epoch 002 | Train Loss: 46.5103 | Val Loss: 535562400536346.2500\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 79\u001b[39m\n\u001b[32m     76\u001b[39m \u001b[38;5;66;03m# TODO : implement gradient clipping?\u001b[39;00m\n\u001b[32m     77\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_epochs):\n\u001b[32m     78\u001b[39m     \u001b[38;5;66;03m# Train\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m79\u001b[39m     train_loss = \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     81\u001b[39m     \u001b[38;5;66;03m# Validate\u001b[39;00m\n\u001b[32m     82\u001b[39m     val_loss = validate(model, val_loader, device)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 30\u001b[39m, in \u001b[36mtrain_epoch\u001b[39m\u001b[34m(model, optimizer, train_loader, device)\u001b[39m\n\u001b[32m     27\u001b[39m     loss.backward()\n\u001b[32m     28\u001b[39m     optimizer.step()\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m     total_loss += \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     32\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m total_loss / \u001b[38;5;28mlen\u001b[39m(train_loader)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "\n",
    "# logging.basicConfig(level=logging.DEBUG)\n",
    "\n",
    "def train_epoch(model, optimizer, train_loader, device):\n",
    "    logger = logging.getLogger('train_epoch')\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch_idx, batch in enumerate(train_loader):\n",
    "        batch = batch.to(device)\n",
    "        logger.debug(f\"\\nBatch {batch_idx}:\")\n",
    "        logger.debug(f\"Batch properties: x={batch.x.shape}, pos={batch.pos.shape}, batch={batch.batch.shape}\")\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        node_features, positions, mu, log_var, property_pred, num_nodes = model(batch)\n",
    "\n",
    "        # Calculate loss\n",
    "        loss = model.loss_function(\n",
    "            node_features, positions, num_nodes,\n",
    "            batch, mu, log_var, property_pred\n",
    "        )\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(train_loader)\n",
    "\n",
    "def validate(model, val_loader, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            batch = batch.to(device)\n",
    "\n",
    "            # Forward pass with all outputs\n",
    "            node_features, positions, mu, log_var, property_pred, num_nodes = model(batch)\n",
    "\n",
    "            # Calculate loss with all parameters\n",
    "            loss = model.loss_function(\n",
    "                node_features, positions, num_nodes,\n",
    "                batch, mu, log_var, property_pred\n",
    "            )\n",
    "            total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(val_loader)\n",
    "\n",
    "\n",
    "# Training setup\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = PropertyConditionedVAE().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode='min', factor=0.5, patience=5, min_lr=1e-6\n",
    ")\n",
    "\n",
    "# Training loop\n",
    "n_epochs = 100\n",
    "best_val_loss = float('inf')\n",
    "patience = 10\n",
    "patience_counter = 0\n",
    "\n",
    "batch = next(iter(train_loader))\n",
    "print(f\"Target property shape: {batch.y.shape}\")\n",
    "print(f\"Target property sample: {batch.y[0]}\")\n",
    "print(f\"Input node features shape: {batch.x.shape}\")  # Should be (N, 11)\n",
    "print(f\"Input positions shape: {batch.pos.shape}\")    # Should be (N, 3)\n",
    "print(f\"Number of nodes: {batch.num_nodes}\")\n",
    "print(f\"Batch size: {batch.batch.max().item() + 1}\")\n",
    "# TODO : implement gradient clipping?\n",
    "for epoch in range(n_epochs):\n",
    "    # Train\n",
    "    train_loss = train_epoch(model, optimizer, train_loader, device)\n",
    "\n",
    "    # Validate\n",
    "    val_loss = validate(model, val_loader, device)\n",
    "\n",
    "    # Learning rate scheduling\n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "    # Early stopping\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        patience_counter = 0\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= patience:\n",
    "            print(f'Early stopping at epoch {epoch}')\n",
    "            # Save best model\n",
    "            # Save model with timestamp in a more readable format\n",
    "            timestamp = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "            save_path = f'best_vae_model_{timestamp}.pt'\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            print(f'Saved best model to: {save_path}')\n",
    "            break\n",
    "\n",
    "    # Print progress\n",
    "    print(f'Epoch {epoch:03d} | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}')\n",
    "\n",
    "# Load best model for testing\n",
    "model.load_state_dict(torch.load('best_vae_model.pt'))\n",
    "\n",
    "# Test final model\n",
    "test_loss = validate(model, test_loader, device)\n",
    "print(f'Final Test Loss: {test_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
