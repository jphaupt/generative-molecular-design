{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Message-Passing Graph Variational Autoencoder\n",
    "\n",
    "Here I will use principles from message-passing graph neural networks to try to generate\n",
    "molecules in a graph variational autoencoder. This is based on my solutions to \n",
    "`geometric-gnn-dojo/geometric_gnn_101.ipynb`\n",
    "Some of the code has also been taken from there\n",
    "\n",
    "might also want to consider autoregressive model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version 2.5.0+cu124\n",
      "PyG version 2.6.1\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import logging\n",
    "import time\n",
    "from mygenai.models.graphvae import PropertyConditionedVAE\n",
    "# importlib.reload(PropertyConditionedVAE)\n",
    "\n",
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "import torch_geometric\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "print(\"PyTorch version {}\".format(torch.__version__))\n",
    "print(\"PyG version {}\".format(torch_geometric.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Debug mode is OFF\n"
     ]
    }
   ],
   "source": [
    "\n",
    "debug_print = False\n",
    "if debug_print:\n",
    "    print(\"Debug mode is ON\")\n",
    "    logging.basicConfig(\n",
    "        level=logging.DEBUG,\n",
    "        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "        force=True  # Ensure configuration is applied\n",
    "    )\n",
    "    for logger_name in ['train_epoch', 'PropertyConditionedVAE', 'ConditionalDecoder', 'Encoder']:\n",
    "        logging.getLogger(logger_name).setLevel(logging.DEBUG)\n",
    "else:\n",
    "    print(\"Debug mode is OFF\")\n",
    "    logging.basicConfig(\n",
    "        level=logging.INFO,\n",
    "        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "        force=True  # Ensure configuration is applied\n",
    "    )\n",
    "    for logger_name in ['train_epoch', 'PropertyConditionedVAE', 'ConditionalDecoder', 'Encoder']:\n",
    "        logging.getLogger(logger_name).setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jph/dev/generative-molecular-design/.conda/lib/python3.12/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.datasets import QM9\n",
    "from torch_geometric.loader import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from mygenai.utils.transforms import CompleteGraph\n",
    "\n",
    "dataset = QM9(root=\"../data/QM9\", transform=CompleteGraph())\n",
    "# Normalize targets per data sample to mean = 0 and std = 1.\n",
    "mean = dataset.data.y.mean(dim=0, keepdim=True)\n",
    "std = dataset.data.y.std(dim=0, keepdim=True)\n",
    "dataset.data.y = (dataset.data.y - mean) / std\n",
    "# focus on just using the one-hot encoding of the atomic number, for simplicity for now\n",
    "dataset.data.x = dataset.data.x[:, :5]\n",
    "# min_atomic_number = 1\n",
    "# max_atomic_number = 9\n",
    "# dataset.data.z = (dataset.data.z - min_atomic_number) / (max_atomic_number - min_atomic_number) # doesn't actually matter because it's not used (this information is determined by data.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data splitting (60/20/20)\n",
    "train_val_idx, test_idx = train_test_split(\n",
    "    np.arange(len(dataset)),\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "train_idx, val_idx = train_test_split(\n",
    "    train_val_idx,\n",
    "    test_size=0.25,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(dataset[train_idx], batch_size=128, shuffle=True)\n",
    "val_loader = DataLoader(dataset[val_idx], batch_size=128, shuffle=False)\n",
    "test_loader = DataLoader(dataset[test_idx], batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training setup\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = PropertyConditionedVAE().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode='min', factor=0.5, patience=5, min_lr=1e-6\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward pass successful!\n"
     ]
    }
   ],
   "source": [
    "# test forward passs\n",
    "batch = next(iter(train_loader))\n",
    "batch = batch.to(device)\n",
    "with torch.no_grad():\n",
    "    outputs = model(batch)\n",
    "print(\"Forward pass successful!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # check if training sets are reasonably balanced\n",
    "\n",
    "# def basic_homo_lumo_stats(loader, name):\n",
    "#     total_nodes = 0\n",
    "#     total_graphs = 0\n",
    "#     prop_values = []\n",
    "\n",
    "#     for batch in loader:\n",
    "#         total_graphs += batch.batch.max().item() + 1\n",
    "#         total_nodes += batch.x.shape[0]\n",
    "#         prop_values.append(batch.y[:, 4].cpu().numpy())\n",
    "\n",
    "#     prop_values = np.concatenate(prop_values)\n",
    "#     print(f\"{name} stats - graphs: {total_graphs}, avg. nodes: {total_nodes/total_graphs}\")\n",
    "#     print(f\"{name} property stats - mean: {prop_values.mean():.4f}, std: {prop_values.std():.4f}\")\n",
    "\n",
    "# basic_homo_lumo_stats(train_loader, \"Train\")\n",
    "# basic_homo_lumo_stats(test_loader, \"Test\")\n",
    "# basic_homo_lumo_stats(val_loader, \"Validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-20 18:51:03,065 - root - INFO - Target property shape: torch.Size([128, 19])\n",
      "2025-04-20 18:51:03,066 - root - INFO - Target property sample: tensor([-0.5368,  0.6629, -0.0587, -0.1267, -0.0984,  0.4885,  1.0045, -0.3360,\n",
      "        -0.3360, -0.3360, -0.3360,  0.8287, -0.9686, -0.9696, -0.9700, -0.9614,\n",
      "        -0.0038, -0.1471, -0.2082])\n",
      "2025-04-20 18:51:03,066 - root - INFO - Input node features shape: torch.Size([2360, 5])\n",
      "2025-04-20 18:51:03,066 - root - INFO - Input positions shape: torch.Size([2360, 3])\n",
      "2025-04-20 18:51:03,067 - root - INFO - Number of nodes: 2360\n",
      "2025-04-20 18:51:03,067 - root - INFO - Batch size: 128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated node features: min=0.0807, max=0.9049\n",
      "Original node features: min=0.0000, max=1.0000\n",
      "Generated distances: min=0.0000, max=1.9338\n",
      "Generated directions: min=-0.9967, max=0.9990\n",
      "Epoch 000 | Train Loss: 74.0588 | Val Loss: 9.8723\n",
      "Generated node features: min=0.0030, max=0.6648\n",
      "Original node features: min=0.0000, max=1.0000\n",
      "Generated distances: min=0.0000, max=3.7843\n",
      "Generated directions: min=-0.9946, max=0.9916\n",
      "Epoch 001 | Train Loss: 9.8253 | Val Loss: 5.7595\n",
      "Generated node features: min=0.0000, max=0.6689\n",
      "Original node features: min=0.0000, max=1.0000\n",
      "Generated distances: min=0.0000, max=4.0604\n",
      "Generated directions: min=-0.9901, max=0.9926\n",
      "Epoch 002 | Train Loss: 2.9047 | Val Loss: 2.7684\n",
      "Generated node features: min=0.0014, max=0.6640\n",
      "Original node features: min=0.0000, max=1.0000\n",
      "Generated distances: min=2.8320, max=4.4453\n",
      "Generated directions: min=-0.9961, max=0.9937\n",
      "Epoch 003 | Train Loss: 2.7186 | Val Loss: 2.6102\n",
      "Generated node features: min=0.0005, max=0.6837\n",
      "Original node features: min=0.0000, max=1.0000\n",
      "Generated distances: min=2.7414, max=4.0118\n",
      "Generated directions: min=-0.9983, max=0.9235\n",
      "Epoch 004 | Train Loss: 2.7113 | Val Loss: 2.7328\n",
      "Generated node features: min=0.0005, max=0.6787\n",
      "Original node features: min=0.0000, max=1.0000\n",
      "Generated distances: min=2.6038, max=3.9961\n",
      "Generated directions: min=-0.9861, max=0.9507\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# TODO : move training etc. to mygenai\n",
    "# logging.basicConfig(level=logging.DEBUG)\n",
    "\n",
    "# for now, check to see if can at least reconstruct molecules\n",
    "recon_weight = 1.0\n",
    "kl_weight = 0. #0.01\n",
    "property_weight = 0.\n",
    "\n",
    "def train_epoch(model, optimizer, train_loader, device):\n",
    "    logger = logging.getLogger('train_epoch')\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch_idx, batch in enumerate(train_loader):\n",
    "        batch = batch.to(device)\n",
    "        logger.debug(f\"\\nBatch {batch_idx}:\")\n",
    "        logger.debug(f\"Batch properties: x={batch.x.shape}, pos={batch.pos.shape}, batch={batch.batch.shape}\")\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        node_features, distances, directions, edge_features, num_nodes, mu, log_var, property_pred = model(batch)\n",
    "\n",
    "        if batch_idx == 0:  # Check first batch only\n",
    "            # Print statistics about generated values\n",
    "            print(f\"Generated node features: min={node_features.min().item():.4f}, max={node_features.max().item():.4f}\")\n",
    "            print(f\"Original node features: min={batch.x.min().item():.4f}, max={batch.x.max().item():.4f}\")\n",
    "            print(f\"Generated distances: min={distances.min().item():.4f}, max={distances.max().item():.4f}\")\n",
    "            # print(f\"Generated directions: min={directions.min().item():.4f}, max={directions.max().item():.4f}\")\n",
    "\n",
    "        # Calculate loss\n",
    "        loss = model.loss_function(\n",
    "            node_features, distances, directions, edge_features, num_nodes,\n",
    "            batch, mu, log_var, property_pred,\n",
    "            recon_weight=recon_weight, kl_weight=kl_weight, property_weight=property_weight\n",
    "        )\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.)\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(train_loader)\n",
    "\n",
    "\n",
    "def validate(model, val_loader, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    batch_losses = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch in enumerate(val_loader):\n",
    "            batch = batch.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            node_features, distances, directions, edge_features, num_nodes, mu, log_var, property_pred = model(batch)\n",
    "\n",
    "            # Calculate loss\n",
    "            loss = model.loss_function(\n",
    "                node_features, distances, directions, edge_features, num_nodes,\n",
    "                batch, mu, log_var, property_pred,\n",
    "                recon_weight=recon_weight, kl_weight=kl_weight, property_weight=property_weight\n",
    "            )\n",
    "\n",
    "            batch_losses.append(loss.item())\n",
    "            total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(val_loader)\n",
    "\n",
    "\n",
    "# Training loop\n",
    "n_epochs = 100\n",
    "best_val_loss = float('inf')\n",
    "patience = 10\n",
    "patience_counter = 0\n",
    "\n",
    "batch = next(iter(train_loader))\n",
    "logging.info(f\"Target property shape: {batch.y.shape}\")\n",
    "logging.info(f\"Target property sample: {batch.y[0]}\")\n",
    "logging.info(f\"Input node features shape: {batch.x.shape}\")  # Should be (N, 11)\n",
    "logging.info(f\"Input positions shape: {batch.pos.shape}\")    # Should be (N, 3)\n",
    "logging.info(f\"Number of nodes: {batch.num_nodes}\")\n",
    "logging.info(f\"Batch size: {batch.batch.max().item() + 1}\")\n",
    "for epoch in range(n_epochs):\n",
    "    # Train\n",
    "    train_loss = train_epoch(model, optimizer, train_loader, device)\n",
    "\n",
    "    # Validate\n",
    "    val_loss = validate(model, val_loader, device)\n",
    "\n",
    "    # Learning rate scheduling\n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "    # Early stopping\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        patience_counter = 0\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= patience:\n",
    "            print(f'Early stopping at epoch {epoch}')\n",
    "            # Save best model\n",
    "            # Save model with timestamp in a more readable format\n",
    "            timestamp = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "            save_path = f'best_vae_model_{timestamp}.pt'\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            print(f'Saved best model to: {save_path}')\n",
    "            break\n",
    "\n",
    "    # Print progress\n",
    "    print(f'Epoch {epoch:03d} | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}')\n",
    "\n",
    "# Load best model for testing\n",
    "# model.load_state_dict(torch.load('best_vae_model.pt'))\n",
    "\n",
    "# Test final model\n",
    "test_loss = validate(model, test_loader, device)\n",
    "print(f'Final Test Loss: {test_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_57558/1361509368.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('best_vae_model_recon_only.pt'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PropertyConditionedVAE(\n",
       "  (encoder): Encoder(\n",
       "    (lin_in): Linear(in_features=11, out_features=64, bias=True)\n",
       "    (convs): ModuleList(\n",
       "      (0-1): 2 x EquivariantMPNNLayer(emb_dim=64, aggr=add)\n",
       "    )\n",
       "    (mu): Linear(in_features=64, out_features=32, bias=True)\n",
       "    (log_var): Linear(in_features=64, out_features=32, bias=True)\n",
       "    (property_predictor): Sequential(\n",
       "      (0): Linear(in_features=32, out_features=64, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): Linear(in_features=64, out_features=1, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (decoder): ConditionalDecoder(\n",
       "    (lin_latent): Linear(in_features=33, out_features=64, bias=True)\n",
       "    (node_decoder): Sequential(\n",
       "      (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): Linear(in_features=64, out_features=11, bias=True)\n",
       "      (4): Tanh()\n",
       "    )\n",
       "    (pos_decoder): Sequential(\n",
       "      (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): Linear(in_features=64, out_features=3, bias=True)\n",
       "      (4): Tanh()\n",
       "    )\n",
       "    (num_nodes_predictor): Sequential(\n",
       "      (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=64, out_features=1, bias=True)\n",
       "    )\n",
       "    (edge_existence): Sequential(\n",
       "      (0): Linear(in_features=128, out_features=64, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): Linear(in_features=64, out_features=1, bias=True)\n",
       "      (4): Sigmoid()\n",
       "    )\n",
       "    (edge_features): Sequential(\n",
       "      (0): Linear(in_features=128, out_features=64, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): Linear(in_features=64, out_features=4, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
