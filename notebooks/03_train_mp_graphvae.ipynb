{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Message-Passing Graph Variational Autoencoder\n",
    "\n",
    "Here I will use principles from message-passing graph neural networks to try to generate\n",
    "molecules in a graph variational autoencoder. This is based on my solutions to \n",
    "`geometric-gnn-dojo/geometric_gnn_101.ipynb`\n",
    "Some of the code has also been taken from there\n",
    "\n",
    "might also want to consider autoregressive model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version 2.5.0+cu124\n",
      "PyG version 2.6.1\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import time\n",
    "from mygenai.models.graphvae import PropertyConditionedVAE\n",
    "\n",
    "import torch\n",
    "import torch_geometric\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "print(\"PyTorch version {}\".format(torch.__version__))\n",
    "print(\"PyG version {}\".format(torch_geometric.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Debug mode is OFF\n"
     ]
    }
   ],
   "source": [
    "\n",
    "debug_print = False\n",
    "if debug_print:\n",
    "    print(\"Debug mode is ON\")\n",
    "    logging.basicConfig(\n",
    "        level=logging.DEBUG,\n",
    "        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "        force=True  # Ensure configuration is applied\n",
    "    )\n",
    "    for logger_name in ['train_epoch', 'PropertyConditionedVAE', 'ConditionalDecoder', 'Encoder']:\n",
    "        logging.getLogger(logger_name).setLevel(logging.DEBUG)\n",
    "else:\n",
    "    print(\"Debug mode is OFF\")\n",
    "    logging.basicConfig(\n",
    "        level=logging.INFO,\n",
    "        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "        force=True  # Ensure configuration is applied\n",
    "    )\n",
    "    for logger_name in ['train_epoch', 'PropertyConditionedVAE', 'ConditionalDecoder', 'Encoder']:\n",
    "        logging.getLogger(logger_name).setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-18 15:10:40,013 - rdkit - INFO - Enabling RDKit 2024.09.6 jupyter extensions\n",
      "/home/jph/dev/generative-molecular-design/.conda/lib/python3.12/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.datasets import QM9\n",
    "from torch_geometric.loader import DataLoader\n",
    "import mygenai\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from mygenai.utils.transforms import CompleteGraph\n",
    "\n",
    "dataset = QM9(root=\"../data/QM9\", transform=CompleteGraph())\n",
    "# Normalize targets per data sample to mean = 0 and std = 1.\n",
    "mean = dataset.data.y.mean(dim=0, keepdim=True)\n",
    "std = dataset.data.y.std(dim=0, keepdim=True)\n",
    "dataset.data.y = (dataset.data.y - mean) / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data splitting (60/20/20)\n",
    "train_val_idx, test_idx = train_test_split(\n",
    "    np.arange(len(dataset)),\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "train_idx, val_idx = train_test_split(\n",
    "    train_val_idx,\n",
    "    test_size=0.25,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(dataset[train_idx], batch_size=128, shuffle=True)\n",
    "val_loader = DataLoader(dataset[val_idx], batch_size=128, shuffle=False)\n",
    "test_loader = DataLoader(dataset[test_idx], batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test forward passs\n",
    "batch = next(iter(train_loader))\n",
    "batch = batch.to(device)\n",
    "with torch.no_grad():\n",
    "    outputs = model(batch)\n",
    "print(\"Forward pass successful!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train stats - graphs: 78498, avg. nodes: 18.033746082702745\n",
      "Train property stats - mean: 0.0014, std: 0.9989\n",
      "Test stats - graphs: 26167, avg. nodes: 18.038445370122673\n",
      "Test property stats - mean: -0.0037, std: 1.0037\n",
      "Validation stats - graphs: 26166, avg. nodes: 18.0228158679202\n",
      "Validation property stats - mean: -0.0005, std: 0.9995\n"
     ]
    }
   ],
   "source": [
    "# check if training sets are reasonably balanced\n",
    "\n",
    "def basic_homo_lumo_stats(loader, name):\n",
    "    total_nodes = 0\n",
    "    total_graphs = 0\n",
    "    prop_values = []\n",
    "\n",
    "    for batch in loader:\n",
    "        total_graphs += batch.batch.max().item() + 1\n",
    "        total_nodes += batch.x.shape[0]\n",
    "        prop_values.append(batch.y[:, 4].cpu().numpy())\n",
    "\n",
    "    prop_values = np.concatenate(prop_values)\n",
    "    print(f\"{name} stats - graphs: {total_graphs}, avg. nodes: {total_nodes/total_graphs}\")\n",
    "    print(f\"{name} property stats - mean: {prop_values.mean():.4f}, std: {prop_values.std():.4f}\")\n",
    "\n",
    "basic_homo_lumo_stats(train_loader, \"Train\")\n",
    "basic_homo_lumo_stats(test_loader, \"Test\")\n",
    "basic_homo_lumo_stats(val_loader, \"Validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-18 15:11:38,218 - root - INFO - Target property shape: torch.Size([128, 19])\n",
      "2025-04-18 15:11:38,219 - root - INFO - Target property sample: tensor([-0.6957,  0.7926,  1.1932,  1.5083,  0.9399, -0.3079,  0.7014,  1.1254,\n",
      "         1.1254,  1.1254,  1.1254, -0.4195, -0.6963, -0.7002, -0.7000, -0.6920,\n",
      "        -0.0032, -0.0611,  0.0994])\n",
      "2025-04-18 15:11:38,220 - root - INFO - Input node features shape: torch.Size([2349, 11])\n",
      "2025-04-18 15:11:38,220 - root - INFO - Input positions shape: torch.Size([2349, 3])\n",
      "2025-04-18 15:11:38,220 - root - INFO - Number of nodes: 2349\n",
      "2025-04-18 15:11:38,220 - root - INFO - Batch size: 128\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 87\u001b[39m\n\u001b[32m     84\u001b[39m logging.info(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mBatch size: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbatch.batch.max().item()\u001b[38;5;250m \u001b[39m+\u001b[38;5;250m \u001b[39m\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     85\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_epochs):\n\u001b[32m     86\u001b[39m     \u001b[38;5;66;03m# Train\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m87\u001b[39m     train_loss = \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     89\u001b[39m     \u001b[38;5;66;03m# Validate\u001b[39;00m\n\u001b[32m     90\u001b[39m     val_loss = validate(model, val_loader, device)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 24\u001b[39m, in \u001b[36mtrain_epoch\u001b[39m\u001b[34m(model, optimizer, train_loader, device)\u001b[39m\n\u001b[32m     21\u001b[39m optimizer.zero_grad()\n\u001b[32m     23\u001b[39m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m node_features, positions, mu, log_var, property_pred, num_nodes = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[38;5;66;03m# Calculate loss\u001b[39;00m\n\u001b[32m     27\u001b[39m loss = model.loss_function(\n\u001b[32m     28\u001b[39m     node_features, positions, num_nodes,\n\u001b[32m     29\u001b[39m     batch, mu, log_var, property_pred,\n\u001b[32m     30\u001b[39m     recon_weight=recon_weight, kl_weight=kl_weight, property_weight=property_weight\n\u001b[32m     31\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/generative-molecular-design/.conda/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1734\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1735\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/generative-molecular-design/.conda/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1743\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1745\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1746\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1747\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1749\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1750\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/generative-molecular-design/mygenai/models/graphvae.py:52\u001b[39m, in \u001b[36mPropertyConditionedVAE.forward\u001b[39m\u001b[34m(self, data, target_property)\u001b[39m\n\u001b[32m     49\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     50\u001b[39m     \u001b[38;5;66;03m# During validation without teacher forcing, use encoder prediction\u001b[39;00m\n\u001b[32m     51\u001b[39m     decoder_property = property_pred\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m logger.debug(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTarget property shape before squeeze: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mtarget_property\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     54\u001b[39m \u001b[38;5;66;03m# # Ensure target_property is 2D\u001b[39;00m\n\u001b[32m     55\u001b[39m \u001b[38;5;66;03m# if len(target_property.shape) == 3:\u001b[39;00m\n\u001b[32m     56\u001b[39m \u001b[38;5;66;03m#     target_property = target_property.squeeze(1)\u001b[39;00m\n\u001b[32m     57\u001b[39m \u001b[38;5;66;03m# logger.debug(f\"Target property shape after squeeze: {target_property.shape}\")\u001b[39;00m\n\u001b[32m     58\u001b[39m \n\u001b[32m     59\u001b[39m \u001b[38;5;66;03m# Decode\u001b[39;00m\n\u001b[32m     60\u001b[39m node_features, positions, num_nodes = \u001b[38;5;28mself\u001b[39m.decoder(\n\u001b[32m     61\u001b[39m     z, decoder_property, data.batch.max().item() + \u001b[32m1\u001b[39m\n\u001b[32m     62\u001b[39m )\n",
      "\u001b[31mAttributeError\u001b[39m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# TODO : move training etc. to mygenai\n",
    "# logging.basicConfig(level=logging.DEBUG)\n",
    "\n",
    "# for now, check to see if can at least reconstruct molecules\n",
    "recon_weight = 1.0\n",
    "kl_weight = 0.\n",
    "property_weight = 0.\n",
    "\n",
    "def train_epoch(model, optimizer, train_loader, device):\n",
    "    logger = logging.getLogger('train_epoch')\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch_idx, batch in enumerate(train_loader):\n",
    "        batch = batch.to(device)\n",
    "        logger.debug(f\"\\nBatch {batch_idx}:\")\n",
    "        logger.debug(f\"Batch properties: x={batch.x.shape}, pos={batch.pos.shape}, batch={batch.batch.shape}\")\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        node_features, positions, mu, log_var, property_pred, num_nodes = model(batch)\n",
    "\n",
    "        # Calculate loss\n",
    "        loss = model.loss_function(\n",
    "            node_features, positions, num_nodes,\n",
    "            batch, mu, log_var, property_pred,\n",
    "            recon_weight=recon_weight, kl_weight=kl_weight, property_weight=property_weight\n",
    "        )\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(train_loader)\n",
    "\n",
    "def validate(model, val_loader, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            batch = batch.to(device)\n",
    "\n",
    "            # Forward pass with all outputs\n",
    "            node_features, positions, mu, log_var, property_pred, num_nodes = model(batch)\n",
    "\n",
    "            # Calculate loss with all parameters\n",
    "            loss = model.loss_function(\n",
    "                node_features, positions, num_nodes,\n",
    "                batch, mu, log_var, property_pred,\n",
    "            recon_weight=recon_weight, kl_weight=kl_weight, property_weight=property_weight\n",
    "            )\n",
    "            total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(val_loader)\n",
    "\n",
    "\n",
    "# Training setup\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = PropertyConditionedVAE().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode='min', factor=0.5, patience=5, min_lr=1e-6\n",
    ")\n",
    "\n",
    "# Training loop\n",
    "n_epochs = 100\n",
    "best_val_loss = float('inf')\n",
    "patience = 10\n",
    "patience_counter = 0\n",
    "\n",
    "batch = next(iter(train_loader))\n",
    "logging.info(f\"Target property shape: {batch.y.shape}\")\n",
    "logging.info(f\"Target property sample: {batch.y[0]}\")\n",
    "logging.info(f\"Input node features shape: {batch.x.shape}\")  # Should be (N, 11)\n",
    "logging.info(f\"Input positions shape: {batch.pos.shape}\")    # Should be (N, 3)\n",
    "logging.info(f\"Number of nodes: {batch.num_nodes}\")\n",
    "logging.info(f\"Batch size: {batch.batch.max().item() + 1}\")\n",
    "for epoch in range(n_epochs):\n",
    "    # Train\n",
    "    train_loss = train_epoch(model, optimizer, train_loader, device)\n",
    "\n",
    "    # Validate\n",
    "    val_loss = validate(model, val_loader, device)\n",
    "\n",
    "    # Learning rate scheduling\n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "    # Early stopping\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        patience_counter = 0\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= patience:\n",
    "            print(f'Early stopping at epoch {epoch}')\n",
    "            # Save best model\n",
    "            # Save model with timestamp in a more readable format\n",
    "            timestamp = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "            save_path = f'best_vae_model_{timestamp}.pt'\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            print(f'Saved best model to: {save_path}')\n",
    "            break\n",
    "\n",
    "    # Print progress\n",
    "    print(f'Epoch {epoch:03d} | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}')\n",
    "\n",
    "# Load best model for testing\n",
    "model.load_state_dict(torch.load('best_vae_model.pt'))\n",
    "\n",
    "# Test final model\n",
    "test_loss = validate(model, test_loader, device)\n",
    "print(f'Final Test Loss: {test_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
