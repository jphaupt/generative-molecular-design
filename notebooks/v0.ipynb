{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version 2.5.0+cu124\n",
      "PyG version 2.6.1\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import mygenai\n",
    "from mygenai.models.graphvae import GraphVAE\n",
    "from mygenai.utils.transforms import CompleteGraph, SetTarget, PadToFixedSize, ExtractFeatures\n",
    "from torch_geometric.datasets import QM9\n",
    "from torch_geometric.loader import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch_geometric\n",
    "import torch_geometric.transforms\n",
    "import numpy as np\n",
    "\n",
    "print(\"PyTorch version {}\".format(torch.__version__))\n",
    "print(\"PyG version {}\".format(torch_geometric.__version__))\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Using device: {}\".format(device))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.858491897583008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jph/dev/generative-molecular-design/.conda/lib/python3.12/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# Transforms which are applied during data loading:\n",
    "# (1) Fully connect the graphs, (2) Select the target/label\n",
    "\n",
    "transform = torch_geometric.transforms.Compose([\n",
    "        ExtractFeatures(),\n",
    "        PadToFixedSize(),\n",
    "        CompleteGraph(),\n",
    "        SetTarget()\n",
    "    ])\n",
    "target = 4\n",
    "\n",
    "# Load the QM9 dataset with the transforms defined\n",
    "dataset = QM9(\"../data/QM9\", transform=transform)\n",
    "\n",
    "# Normalize targets per data sample to mean = 0 and std = 1.\n",
    "mean = dataset.data.y.mean(dim=0, keepdim=True)\n",
    "std = dataset.data.y.std(dim=0, keepdim=True)\n",
    "dataset.data.y = (dataset.data.y - mean) / std\n",
    "mean, std = mean[:, target].item(), std[:, target].item()\n",
    "# dataset = dataset[1000]\n",
    "print(mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of samples: 130831.\n",
      "Created dataset splits with 1000 training, 1000 validation, 1000 test samples.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total number of samples: {len(dataset)}.\")\n",
    "\n",
    "# Split datasets (in case of using the full dataset)\n",
    "# test_dataset = dataset[:10000]\n",
    "# val_dataset = dataset[10000:20000]\n",
    "# train_dataset = dataset[20000:]\n",
    "\n",
    "# Split datasets (our 3K subset)\n",
    "train_dataset = dataset[:1000]\n",
    "val_dataset = dataset[1000:2000]\n",
    "test_dataset = dataset[2000:3000]\n",
    "print(f\"Created dataset splits with {len(train_dataset)} training, {len(val_dataset)} validation, {len(test_dataset)} test samples.\")\n",
    "\n",
    "# Create dataloaders with batch size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GraphVAE().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward pass successful!\n"
     ]
    }
   ],
   "source": [
    "# test forward passs\n",
    "batch = next(iter(train_loader))\n",
    "batch = batch.to(device)\n",
    "with torch.no_grad():\n",
    "    outputs = model(batch)\n",
    "print(\"Forward pass successful!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 000 | Train Loss: 0.4629 | Val Loss: 0.1651\n",
      "Epoch 001 | Train Loss: 0.1668 | Val Loss: 0.1538\n",
      "Epoch 002 | Train Loss: 0.1517 | Val Loss: 0.1488\n",
      "Epoch 003 | Train Loss: 0.1444 | Val Loss: 0.1384\n",
      "Epoch 004 | Train Loss: 0.1260 | Val Loss: 0.1068\n",
      "Epoch 005 | Train Loss: 0.0719 | Val Loss: 0.0306\n",
      "Epoch 006 | Train Loss: 0.0114 | Val Loss: 0.0025\n",
      "Epoch 007 | Train Loss: 0.0011 | Val Loss: 0.0005\n",
      "Epoch 008 | Train Loss: 0.0004 | Val Loss: 0.0003\n",
      "Epoch 009 | Train Loss: 0.0002 | Val Loss: 0.0002\n",
      "Epoch 010 | Train Loss: 0.0001 | Val Loss: 0.0001\n",
      "Epoch 011 | Train Loss: 0.0001 | Val Loss: 0.0001\n",
      "Epoch 012 | Train Loss: 0.0001 | Val Loss: 0.0001\n",
      "Epoch 013 | Train Loss: 0.0001 | Val Loss: 0.0001\n",
      "Epoch 014 | Train Loss: 0.0001 | Val Loss: 0.0001\n",
      "Epoch 015 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Epoch 016 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Epoch 017 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Epoch 018 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Epoch 019 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Epoch 020 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Epoch 021 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Epoch 022 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Epoch 023 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Epoch 024 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Epoch 025 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Epoch 026 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Epoch 027 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Epoch 028 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Epoch 029 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Epoch 030 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Epoch 031 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Epoch 032 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Epoch 033 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Epoch 034 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Epoch 035 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Epoch 036 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Epoch 037 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Epoch 038 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Epoch 039 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Epoch 040 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Epoch 041 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Epoch 042 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Epoch 043 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Epoch 044 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Epoch 045 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Epoch 046 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Epoch 047 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Epoch 048 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Epoch 049 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Epoch 050 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Epoch 051 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Epoch 052 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Epoch 053 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Epoch 054 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Epoch 055 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Epoch 056 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Epoch 057 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Epoch 058 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Epoch 059 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Epoch 060 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Epoch 061 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Epoch 062 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Epoch 063 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Epoch 064 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Epoch 065 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Epoch 066 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Epoch 067 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Epoch 068 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Epoch 069 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Epoch 070 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Epoch 071 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Epoch 072 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Epoch 073 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Epoch 074 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Epoch 075 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Epoch 076 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Epoch 077 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Epoch 078 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Epoch 079 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Epoch 080 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Epoch 081 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Epoch 082 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Epoch 083 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Epoch 084 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Epoch 085 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Epoch 086 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Epoch 087 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Epoch 088 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Epoch 089 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Epoch 090 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Epoch 091 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Epoch 092 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Epoch 093 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Epoch 094 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Epoch 095 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Epoch 096 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Epoch 097 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Epoch 098 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Epoch 099 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Training finished\n"
     ]
    }
   ],
   "source": [
    "import mygenai.training.training as training\n",
    "training.train_model(model, train_loader, val_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "water = dataset[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        ...,\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "water.edge_attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 1., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "water.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Water molecule edge attributes:  tensor([[1., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 1.]], device='cuda:0')\n",
      "Water molecule node attributes:  tensor([[0., 0., 0., 1., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 1.]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# feed water to the model\n",
    "water = water.to(device)\n",
    "with torch.no_grad():\n",
    "    outputs = model(water)\n",
    "print(\"Water molecule edge attributes: \", water.edge_attr)\n",
    "print(\"Water molecule node attributes: \", water.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_logits, mu, logvar, property_pred = outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 4, got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m edge_probs, edge_preds = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecoder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict_edges\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmu\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/generative-molecular-design/mygenai/models/decoders.py:56\u001b[39m, in \u001b[36mGraphDecoder.predict_edges\u001b[39m\u001b[34m(self, z, threshold)\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpredict_edges\u001b[39m(\u001b[38;5;28mself\u001b[39m, z, threshold=\u001b[32m0.5\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m56\u001b[39m     edge_logits, _, _, _ = \u001b[38;5;28mself\u001b[39m(z)\n\u001b[32m     57\u001b[39m     edge_probs = torch.sigmoid(edge_logits)\n\u001b[32m     58\u001b[39m     edge_pred = (edge_probs > threshold).float()\n",
      "\u001b[31mValueError\u001b[39m: not enough values to unpack (expected 4, got 1)"
     ]
    }
   ],
   "source": [
    "edge_probs, edge_preds = model.decoder.predict_edges(mu)\n",
    "print(\"Edge logits: \", edge_logits)\n",
    "print(\"Edge probabilities: \", edge_probs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
