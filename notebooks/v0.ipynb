{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version 2.5.0+cu124\n",
      "PyG version 2.6.1\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import mygenai\n",
    "from mygenai.models.graphvae import GraphVAE\n",
    "from mygenai.utils.transforms import CompleteGraph, SetTarget, PadToFixedSize, ExtractFeatures\n",
    "from torch_geometric.datasets import QM9\n",
    "from torch_geometric.loader import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch_geometric\n",
    "import torch_geometric.transforms\n",
    "import numpy as np\n",
    "\n",
    "print(\"PyTorch version {}\".format(torch.__version__))\n",
    "print(\"PyG version {}\".format(torch_geometric.__version__))\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Using device: {}\".format(device))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.858491897583008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jph/dev/generative-molecular-design/.conda/lib/python3.12/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# Transforms which are applied during data loading:\n",
    "# (1) Fully connect the graphs, (2) Select the target/label\n",
    "\n",
    "transform = torch_geometric.transforms.Compose([\n",
    "        ExtractFeatures(),\n",
    "        PadToFixedSize(),\n",
    "        CompleteGraph(),\n",
    "        SetTarget()\n",
    "    ])\n",
    "target = 4\n",
    "\n",
    "# Load the QM9 dataset with the transforms defined\n",
    "dataset = QM9(\"../data/QM9\", transform=transform)\n",
    "\n",
    "# Normalize targets per data sample to mean = 0 and std = 1.\n",
    "mean = dataset.data.y.mean(dim=0, keepdim=True)\n",
    "std = dataset.data.y.std(dim=0, keepdim=True)\n",
    "dataset.data.y = (dataset.data.y - mean) / std\n",
    "mean, std = mean[:, target].item(), std[:, target].item()\n",
    "# dataset = dataset[1000]\n",
    "print(mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of samples: 130831.\n",
      "Created dataset splits with 1000 training, 1000 validation, 1000 test samples.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total number of samples: {len(dataset)}.\")\n",
    "\n",
    "# Split datasets (in case of using the full dataset)\n",
    "# test_dataset = dataset[:10000]\n",
    "# val_dataset = dataset[10000:20000]\n",
    "# train_dataset = dataset[20000:]\n",
    "\n",
    "# Split datasets (our 3K subset)\n",
    "train_dataset = dataset[:1000]\n",
    "val_dataset = dataset[1000:2000]\n",
    "test_dataset = dataset[2000:3000]\n",
    "print(f\"Created dataset splits with {len(train_dataset)} training, {len(val_dataset)} validation, {len(test_dataset)} test samples.\")\n",
    "\n",
    "# Create dataloaders with batch size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GraphVAE().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward pass successful!\n"
     ]
    }
   ],
   "source": [
    "# test forward passs\n",
    "batch = next(iter(train_loader))\n",
    "batch = batch.to(device)\n",
    "with torch.no_grad():\n",
    "    outputs = model(batch)\n",
    "print(\"Forward pass successful!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 000 | Train Loss: 0.3969 | Val Loss: 0.1849\n",
      "Epoch 001 | Train Loss: 0.1626 | Val Loss: 0.1478\n",
      "Epoch 002 | Train Loss: 0.1356 | Val Loss: 0.1166\n",
      "Epoch 003 | Train Loss: 0.0843 | Val Loss: 0.0441\n",
      "Epoch 004 | Train Loss: 0.0177 | Val Loss: 0.0036\n",
      "Epoch 005 | Train Loss: 0.0014 | Val Loss: 0.0005\n",
      "Epoch 006 | Train Loss: 0.0003 | Val Loss: 0.0002\n",
      "Epoch 007 | Train Loss: 0.0002 | Val Loss: 0.0001\n",
      "Epoch 008 | Train Loss: 0.0001 | Val Loss: 0.0001\n",
      "Epoch 009 | Train Loss: 0.0001 | Val Loss: 0.0001\n",
      "Epoch 010 | Train Loss: 0.0001 | Val Loss: 0.0001\n",
      "Epoch 011 | Train Loss: 0.0001 | Val Loss: 0.0000\n",
      "Epoch 012 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Epoch 013 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Epoch 014 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Epoch 015 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Epoch 016 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Epoch 017 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Epoch 018 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Epoch 019 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Epoch 020 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Epoch 021 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Epoch 022 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Epoch 023 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Epoch 024 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Epoch 025 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Epoch 026 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Epoch 027 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Epoch 028 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Epoch 029 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Epoch 030 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Epoch 031 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Epoch 032 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Epoch 033 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Epoch 034 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Epoch 035 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Epoch 036 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Epoch 037 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Epoch 038 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Epoch 039 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Epoch 040 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Epoch 041 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Epoch 042 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Epoch 043 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Epoch 044 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Epoch 045 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Epoch 046 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Epoch 047 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Epoch 048 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Epoch 049 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Epoch 050 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Epoch 051 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Epoch 052 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Epoch 053 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Epoch 054 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Epoch 055 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Epoch 056 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Epoch 057 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Epoch 058 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Epoch 059 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Epoch 060 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Epoch 061 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Epoch 062 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Epoch 063 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Epoch 064 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Epoch 065 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Epoch 066 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Epoch 067 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Epoch 068 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Epoch 069 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Epoch 070 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Epoch 071 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Epoch 072 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Epoch 073 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Epoch 074 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Epoch 075 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Epoch 076 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Epoch 077 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Epoch 078 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Epoch 079 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Epoch 080 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Epoch 081 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Epoch 082 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Epoch 083 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Epoch 084 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Epoch 085 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Epoch 086 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Epoch 087 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Epoch 088 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Epoch 089 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Epoch 090 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Epoch 091 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Epoch 092 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Epoch 093 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Epoch 094 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Epoch 095 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Epoch 096 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Epoch 097 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Epoch 098 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Epoch 099 | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Training finished\n"
     ]
    }
   ],
   "source": [
    "import mygenai.training.training as training\n",
    "training.train_model(model, train_loader, val_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "water = dataset[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        ...,\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "water.edge_attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 1., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "water.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Water molecule edge attributes:  tensor([[1., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 1.]], device='cuda:0')\n",
      "Water molecule edge indices:  tensor([[ 0,  0,  0,  ..., 28, 28, 28],\n",
      "        [ 1,  2,  3,  ..., 25, 26, 27]], device='cuda:0')\n",
      "Ground-truth adjacency matrix:  tensor([[[[0., 0., 0., 0., 0.],\n",
      "          [1., 0., 0., 0., 0.],\n",
      "          [1., 0., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0., 0., 1.],\n",
      "          [0., 0., 0., 0., 1.],\n",
      "          [0., 0., 0., 0., 1.]],\n",
      "\n",
      "         [[1., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0., 0., 1.],\n",
      "          [0., 0., 0., 0., 1.],\n",
      "          [0., 0., 0., 0., 1.]],\n",
      "\n",
      "         [[1., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0., 0., 1.],\n",
      "          [0., 0., 0., 0., 1.],\n",
      "          [0., 0., 0., 0., 1.]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0., 0., 0., 0., 1.],\n",
      "          [0., 0., 0., 0., 1.],\n",
      "          [0., 0., 0., 0., 1.],\n",
      "          ...,\n",
      "          [0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 1.],\n",
      "          [0., 0., 0., 0., 1.]],\n",
      "\n",
      "         [[0., 0., 0., 0., 1.],\n",
      "          [0., 0., 0., 0., 1.],\n",
      "          [0., 0., 0., 0., 1.],\n",
      "          ...,\n",
      "          [0., 0., 0., 0., 1.],\n",
      "          [0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 1.]],\n",
      "\n",
      "         [[0., 0., 0., 0., 1.],\n",
      "          [0., 0., 0., 0., 1.],\n",
      "          [0., 0., 0., 0., 1.],\n",
      "          ...,\n",
      "          [0., 0., 0., 0., 1.],\n",
      "          [0., 0., 0., 0., 1.],\n",
      "          [0., 0., 0., 0., 0.]]]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "water = water.to(device)\n",
    "print(\"Water molecule edge attributes: \", water.edge_attr)\n",
    "# print(\"Water molecule node attributes: \", water.x)\n",
    "print(\"Water molecule edge indices: \", water.edge_index)\n",
    "from torch_geometric.utils import to_dense_adj\n",
    "# create ground-truth adjacency matrix\n",
    "adj = to_dense_adj(water.edge_index, batch=water.batch, edge_attr=water.edge_attr)\n",
    "print(\"Ground-truth adjacency matrix: \", adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feed water to the model\n",
    "with torch.no_grad():\n",
    "    outputs = model(water)\n",
    "edge_logits, mu, logvar, property_pred = outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edge predictions:  tensor([[[0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,\n",
      "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,\n",
      "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,\n",
      "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,\n",
      "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,\n",
      "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,\n",
      "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,\n",
      "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,\n",
      "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "          0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "          1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "          1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "          1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "          1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "          1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "          1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "          1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "          1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "          1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.]]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "edge_probs, edge_preds = model.decoder.predict_edges(mu)\n",
    "# print(\"Edge logits: \", edge_logits)\n",
    "# print(\"Edge probabilities: \", edge_probs)\n",
    "print(\"Edge predictions: \", edge_preds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
