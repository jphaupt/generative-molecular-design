{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualise NN-generated molecules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, HTML\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.datasets import QM9\n",
    "\n",
    "from mygenai.models.graphvae import PropertyConditionedVAE\n",
    "from mygenai.utils.visualisation import to_rdkit, visualise_molecule, moltosvg\n",
    "from mygenai.utils.transforms import CompleteGraph\n",
    "import logging\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_34673/3893471760.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('best_vae_model_20250420_220525.pt'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = PropertyConditionedVAE(num_layers=4, emb_dim=64, edge_dim=4, latent_dim=32)\n",
    "model.load_state_dict(torch.load('best_vae_model_20250420_220525.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PropertyConditionedVAE(\n",
       "  (encoder): Encoder(\n",
       "    (lin_in): Linear(in_features=5, out_features=64, bias=True)\n",
       "    (convs): ModuleList(\n",
       "      (0-1): 2 x EquivariantMPNNLayer(emb_dim=64, aggr=add)\n",
       "    )\n",
       "    (mu): Linear(in_features=64, out_features=32, bias=True)\n",
       "    (log_var): Linear(in_features=64, out_features=32, bias=True)\n",
       "    (property_predictor): Sequential(\n",
       "      (0): Linear(in_features=32, out_features=64, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): Linear(in_features=64, out_features=1, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (decoder): ConditionalDecoder(\n",
       "    (lin_latent): Linear(in_features=33, out_features=64, bias=True)\n",
       "    (node_decoder): Sequential(\n",
       "      (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): Linear(in_features=64, out_features=5, bias=True)\n",
       "      (4): Sigmoid()\n",
       "    )\n",
       "    (distance_decoder): Sequential(\n",
       "      (0): Linear(in_features=128, out_features=64, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): Linear(in_features=64, out_features=1, bias=True)\n",
       "      (4): Sigmoid()\n",
       "    )\n",
       "    (direction_decoder): Sequential(\n",
       "      (0): Linear(in_features=128, out_features=64, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): Linear(in_features=64, out_features=3, bias=True)\n",
       "    )\n",
       "    (edge_features): Sequential(\n",
       "      (0): Linear(in_features=128, out_features=64, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): Linear(in_features=64, out_features=4, bias=True)\n",
       "      (4): Sigmoid()\n",
       "    )\n",
       "    (num_nodes_predictor): Sequential(\n",
       "      (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): Linear(in_features=64, out_features=1, bias=True)\n",
       "      (4): ReLU()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jph/dev/generative-molecular-design/.conda/lib/python3.12/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "dataset = QM9(root=\"../data/QM9\", transform=CompleteGraph())\n",
    "# Normalize targets per data sample to mean = 0 and std = 1.\n",
    "mean = dataset.data.y.mean(dim=0, keepdim=True)\n",
    "std = dataset.data.y.std(dim=0, keepdim=True)\n",
    "dataset.data.y = (dataset.data.y - mean) / std\n",
    "# focus on just using the one-hot encoding of the atomic number, for simplicity for now\n",
    "dataset.data.x = dataset.data.x[:, :5]\n",
    "\n",
    "# Normalize distances in the dataset\n",
    "fixed_max_distance = 2.0\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-20 22:52:08,820 - PropertyConditionedVAE - DEBUG - Input data - batch_size: 100, nodes: 1005\n",
      "2025-04-20 22:52:08,820 - PropertyConditionedVAE - DEBUG - Forward called without target_property (None)\n",
      "2025-04-20 22:52:08,823 - PropertyConditionedVAE - DEBUG - Encoder outputs - mu: torch.Size([100, 32]), log_var: torch.Size([100, 32]), property_pred: torch.Size([100, 1])\n",
      "2025-04-20 22:52:08,823 - PropertyConditionedVAE - DEBUG - Sampled z shape: torch.Size([100, 32])\n",
      "2025-04-20 22:52:08,824 - PropertyConditionedVAE - DEBUG - Using encoder prediction for property, shape: torch.Size([100, 1])\n",
      "2025-04-20 22:52:08,824 - ConditionalDecoder - DEBUG - Input shapes - z: torch.Size([100, 32]), target_property: torch.Size([100, 1])\n",
      "2025-04-20 22:52:08,825 - ConditionalDecoder - DEBUG - Direction decoder output norm: 1.000000\n",
      "2025-04-20 22:52:08,826 - ConditionalDecoder - DEBUG - Output shapes - node_features: torch.Size([1005, 5]), distances: torch.Size([10070, 1]), directions: torch.Size([10070, 3]), edge_features: torch.Size([10070, 4]), num_nodes: torch.Size([100])\n",
      "2025-04-20 22:52:08,827 - PropertyConditionedVAE - DEBUG - Decoder outputs - node_features: torch.Size([1005, 5]), distances: torch.Size([10070, 1]), directions: torch.Size([10070, 3]), edge_features: torch.Size([10070, 4]), num_nodes: tensor([ 5.0497,  4.1476,  3.2143,  3.9463,  2.7335,  3.9900,  8.1959,  6.0648,\n",
      "         7.1128,  6.0964,  7.1026,  6.1230, 11.0618,  9.1959,  9.2088,  9.1748,\n",
      "         7.0867, 10.1681,  9.2303,  8.2218, 14.1310, 12.1423,  6.0138,  5.0495,\n",
      "         3.9108,  6.0440,  5.1101,  6.0573, 10.2043, 10.1809,  9.2224,  8.1946,\n",
      "         8.1760,  7.1230, 10.1608,  9.2309,  8.1667,  8.1545, 14.1338, 12.1415,\n",
      "        12.1465, 10.1613, 12.1187, 10.1624, 11.1417, 10.1526, 12.1156, 10.1552,\n",
      "        12.1653, 10.1503,  9.1841,  9.1720,  8.1120, 17.1554, 15.1755,  9.1902,\n",
      "         8.1200,  8.1405,  9.2026,  8.1552, 13.1370, 12.1617, 11.1665, 11.1458,\n",
      "        10.1755, 13.1500, 11.1680, 12.1636, 11.1707, 13.1431, 12.1702, 12.1610,\n",
      "        11.1906, 12.1634, 11.1786, 10.1961, 10.1898, 15.1739, 13.1523, 17.1544,\n",
      "        15.1722, 15.1728, 15.1740, 13.1476, 13.1484, 10.1714, 11.1346, 10.1659,\n",
      "         9.1858, 10.1652,  9.1915, 15.1721, 13.1461, 13.1484, 13.1493, 11.1659,\n",
      "        15.1720, 13.1467, 14.1443, 13.1445], device='cuda:0')\n",
      "2025-04-20 22:52:08,828 - PropertyConditionedVAE - DEBUG - Node feature loss: 0.109989\n",
      "2025-04-20 22:52:08,828 - PropertyConditionedVAE - DEBUG - Distance loss: 0.112727\n",
      "2025-04-20 22:52:08,828 - PropertyConditionedVAE - DEBUG - Predicted directions norm: 1.000000\n",
      "2025-04-20 22:52:08,828 - PropertyConditionedVAE - DEBUG - Ground truth directions norm: 1.000000\n",
      "2025-04-20 22:52:08,828 - PropertyConditionedVAE - DEBUG - Cosine similarity: -0.000000\n",
      "2025-04-20 22:52:08,829 - PropertyConditionedVAE - DEBUG - Direction loss: 1.000000\n",
      "2025-04-20 22:52:08,829 - PropertyConditionedVAE - DEBUG - Edge feature loss: 0.039113\n",
      "2025-04-20 22:52:08,829 - PropertyConditionedVAE - DEBUG - Number of nodes loss: 0.024919\n",
      "2025-04-20 22:52:08,829 - PropertyConditionedVAE - DEBUG - KL divergence loss: 434.825562\n",
      "2025-04-20 22:52:08,829 - PropertyConditionedVAE - DEBUG - KL divergence weight: 0.000000\n",
      "2025-04-20 22:52:08,830 - PropertyConditionedVAE - DEBUG - Property prediction loss: 5.478538\n",
      "2025-04-20 22:52:08,830 - PropertyConditionedVAE - DEBUG - Property prediction weight: 0.000000\n",
      "2025-04-20 22:52:08,830 - PropertyConditionedVAE - DEBUG - Reconstruction loss: 1.286748\n",
      "2025-04-20 22:52:08,830 - PropertyConditionedVAE - DEBUG - Reconstruction weight: 1.000000\n",
      "2025-04-20 22:52:08,830 - PropertyConditionedVAE - DEBUG - Total loss: 1.286748\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.data import Batch\n",
    "# pass debug logger to the model\n",
    "logging.basicConfig(level=logging.DEBUG, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "logging.getLogger('PropertyConditionedVAE').setLevel(logging.DEBUG)\n",
    "logging.getLogger('ConditionalDecoder').setLevel(logging.DEBUG)\n",
    "recon_weight = 1.0\n",
    "kl_weight = 0.01\n",
    "property_weight = 0.\n",
    "\n",
    "batch_data = dataset[:100]\n",
    "batch = Batch.from_data_list(batch_data).to(device)\n",
    "with torch.no_grad():  # Disable gradient computation\n",
    "    outputs = model(batch)\n",
    "node_features, distances, directions, edge_features, num_nodes, mu, log_var, property_pred = outputs\n",
    "\n",
    "# Compute the loss\n",
    "loss = model.loss_function(\n",
    "    node_features=node_features,\n",
    "    distances=distances,\n",
    "    directions=directions,\n",
    "    edge_features=edge_features,\n",
    "    num_nodes=num_nodes,\n",
    "    data=batch,\n",
    "    mu=mu,\n",
    "    log_var=log_var,\n",
    "    property_pred=property_pred,\n",
    "    property_weight=property_weight,  # Use the same weights as during training\n",
    "    recon_weight=recon_weight,\n",
    "    kl_weight=kl_weight\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(100.3494, device='cuda:0')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "directions.norm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct_molecule(model, data):\n",
    "    data = data.to(device)\n",
    "    with torch.no_grad():\n",
    "        # Forward pass\n",
    "        node_features, positions, mu, log_var, property_pred, num_nodes = model(data)\n",
    "\n",
    "        # Create a copy of the data object for the reconstruction\n",
    "        recon_data = data.clone()\n",
    "\n",
    "        # Replace features and positions with reconstructed ones\n",
    "        # Use the actual number of nodes in the original data\n",
    "        n_orig = data.x.size(0)\n",
    "        n_gen = min(num_nodes[0].item(), n_orig)\n",
    "\n",
    "        recon_data.x = node_features[:n_gen]\n",
    "        recon_data.pos = positions[:n_gen]\n",
    "\n",
    "        # If the generated number of nodes is less than original, trim the data\n",
    "        if n_gen < n_orig:\n",
    "            recon_data.edge_index = data.edge_index[:, data.edge_index[0] < n_gen]\n",
    "            recon_data.edge_index = recon_data.edge_index[:, recon_data.edge_index[1] < n_gen]\n",
    "            if hasattr(recon_data, 'edge_attr') and recon_data.edge_attr is not None:\n",
    "                mask = (recon_data.edge_index[0] < n_gen) & (recon_data.edge_index[1] < n_gen)\n",
    "                recon_data.edge_attr = recon_data.edge_attr[mask]\n",
    "\n",
    "        return recon_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/3dmoljs_load.v0": "<div id=\"3dmolviewer_174498970532636\"  style=\"position: relative; width: 300px; height: 300px;\">\n        <p id=\"3dmolwarning_174498970532636\" style=\"background-color:#ffcccc;color:black\">3Dmol.js failed to load for some reason.  Please check your browser console for error messages.<br></p>\n        </div>\n<script>\n\nvar loadScriptAsync = function(uri){\n  return new Promise((resolve, reject) => {\n    //this is to ignore the existence of requirejs amd\n    var savedexports, savedmodule;\n    if (typeof exports !== 'undefined') savedexports = exports;\n    else exports = {}\n    if (typeof module !== 'undefined') savedmodule = module;\n    else module = {}\n\n    var tag = document.createElement('script');\n    tag.src = uri;\n    tag.async = true;\n    tag.onload = () => {\n        exports = savedexports;\n        module = savedmodule;\n        resolve();\n    };\n  var firstScriptTag = document.getElementsByTagName('script')[0];\n  firstScriptTag.parentNode.insertBefore(tag, firstScriptTag);\n});\n};\n\nif(typeof $3Dmolpromise === 'undefined') {\n$3Dmolpromise = null;\n  $3Dmolpromise = loadScriptAsync('https://cdnjs.cloudflare.com/ajax/libs/3Dmol/2.4.2/3Dmol-min.js');\n}\n\nvar viewer_174498970532636 = null;\nvar warn = document.getElementById(\"3dmolwarning_174498970532636\");\nif(warn) {\n    warn.parentNode.removeChild(warn);\n}\n$3Dmolpromise.then(function() {\nviewer_174498970532636 = $3Dmol.createViewer(document.getElementById(\"3dmolviewer_174498970532636\"),{backgroundColor:\"white\"});\nviewer_174498970532636.zoomTo();\n\tviewer_174498970532636.addModel(\"\\n     RDKit          3D\\n\\n  5  4  0  0  0  0  0  0  0  0999 V2000\\n    0.0000   -0.0000    0.0000 C   0  0  0  0  0  0  0  0  0  0  0  0\\n   -0.6061    0.1534    0.8956 H   0  0  0  0  0  0  0  0  0  0  0  0\\n   -0.4021   -0.8388   -0.5724 H   0  0  0  0  0  0  0  0  0  0  0  0\\n   -0.0219    0.9033   -0.6136 H   0  0  0  0  0  0  0  0  0  0  0  0\\n    1.0301   -0.2180    0.2904 H   0  0  0  0  0  0  0  0  0  0  0  0\\n  1  2  1  0\\n  1  3  1  0\\n  1  4  1  0\\n  1  5  1  0\\nM  END\\n\",\"mol\");\n\tviewer_174498970532636.setStyle({\"stick\": {}});\n\tviewer_174498970532636.zoomTo();\nviewer_174498970532636.render();\n});\n</script>",
      "text/html": [
       "<div id=\"3dmolviewer_174498970532636\"  style=\"position: relative; width: 300px; height: 300px;\">\n",
       "        <p id=\"3dmolwarning_174498970532636\" style=\"background-color:#ffcccc;color:black\">3Dmol.js failed to load for some reason.  Please check your browser console for error messages.<br></p>\n",
       "        </div>\n",
       "<script>\n",
       "\n",
       "var loadScriptAsync = function(uri){\n",
       "  return new Promise((resolve, reject) => {\n",
       "    //this is to ignore the existence of requirejs amd\n",
       "    var savedexports, savedmodule;\n",
       "    if (typeof exports !== 'undefined') savedexports = exports;\n",
       "    else exports = {}\n",
       "    if (typeof module !== 'undefined') savedmodule = module;\n",
       "    else module = {}\n",
       "\n",
       "    var tag = document.createElement('script');\n",
       "    tag.src = uri;\n",
       "    tag.async = true;\n",
       "    tag.onload = () => {\n",
       "        exports = savedexports;\n",
       "        module = savedmodule;\n",
       "        resolve();\n",
       "    };\n",
       "  var firstScriptTag = document.getElementsByTagName('script')[0];\n",
       "  firstScriptTag.parentNode.insertBefore(tag, firstScriptTag);\n",
       "});\n",
       "};\n",
       "\n",
       "if(typeof $3Dmolpromise === 'undefined') {\n",
       "$3Dmolpromise = null;\n",
       "  $3Dmolpromise = loadScriptAsync('https://cdnjs.cloudflare.com/ajax/libs/3Dmol/2.4.2/3Dmol-min.js');\n",
       "}\n",
       "\n",
       "var viewer_174498970532636 = null;\n",
       "var warn = document.getElementById(\"3dmolwarning_174498970532636\");\n",
       "if(warn) {\n",
       "    warn.parentNode.removeChild(warn);\n",
       "}\n",
       "$3Dmolpromise.then(function() {\n",
       "viewer_174498970532636 = $3Dmol.createViewer(document.getElementById(\"3dmolviewer_174498970532636\"),{backgroundColor:\"white\"});\n",
       "viewer_174498970532636.zoomTo();\n",
       "\tviewer_174498970532636.addModel(\"\\n     RDKit          3D\\n\\n  5  4  0  0  0  0  0  0  0  0999 V2000\\n    0.0000   -0.0000    0.0000 C   0  0  0  0  0  0  0  0  0  0  0  0\\n   -0.6061    0.1534    0.8956 H   0  0  0  0  0  0  0  0  0  0  0  0\\n   -0.4021   -0.8388   -0.5724 H   0  0  0  0  0  0  0  0  0  0  0  0\\n   -0.0219    0.9033   -0.6136 H   0  0  0  0  0  0  0  0  0  0  0  0\\n    1.0301   -0.2180    0.2904 H   0  0  0  0  0  0  0  0  0  0  0  0\\n  1  2  1  0\\n  1  3  1  0\\n  1  4  1  0\\n  1  5  1  0\\nM  END\\n\",\"mol\");\n",
       "\tviewer_174498970532636.setStyle({\"stick\": {}});\n",
       "\tviewer_174498970532636.zoomTo();\n",
       "viewer_174498970532636.render();\n",
       "});\n",
       "</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<py3Dmol.view at 0x7fb1ae185160>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_mol = dataset[0]\n",
    "test_mol.batch = torch.zeros(test_mol.x.size(0), dtype=torch.long, device=test_mol.x.device)\n",
    "visualise_molecule(test_mol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "recon_mol = reconstruct_molecule(model, test_mol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original molecule:\n",
      "SMILES: [H]C([H])([H])[H]\n",
      "Z tensor([6, 1, 1, 1, 1], device='cuda:0')\n",
      "pos tensor([[-1.2700e-02,  1.0858e+00,  8.0000e-03],\n",
      "        [ 2.2000e-03, -6.0000e-03,  2.0000e-03],\n",
      "        [ 1.0117e+00,  1.4638e+00,  3.0000e-04],\n",
      "        [-5.4080e-01,  1.4475e+00, -8.7660e-01],\n",
      "        [-5.2380e-01,  1.4379e+00,  9.0640e-01]], device='cuda:0')\n",
      "Reconstructed molecule:\n",
      "SMILES: [H]C([H])([H])[H]\n",
      "Z tensor([6, 1, 1, 1, 1], device='cuda:0')\n",
      "pos tensor([[6.9755, 6.9755, 6.9755],\n",
      "        [6.9755, 6.9755, 6.9755],\n",
      "        [6.9755, 6.9755, 6.9755],\n",
      "        [6.9755, 6.9755, 6.9755],\n",
      "        [6.9755, 6.9755, 6.9755]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(\"Original molecule:\")\n",
    "print(\"SMILES:\", test_mol.smiles)\n",
    "print(\"Z\", test_mol.z)\n",
    "print(\"pos\", test_mol.pos)\n",
    "print(\"Reconstructed molecule:\")\n",
    "print(\"SMILES:\", recon_mol.smiles)\n",
    "print(\"Z\", recon_mol.z)\n",
    "print(\"pos\", recon_mol.pos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[5, 11], edge_index=[2, 20], edge_attr=[20, 4], y=[1, 19], pos=[5, 3], z=[5], smiles='[H]C([H])([H])[H]', name='gdb_1', idx=[1], batch=[5])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0, 0, 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3, 4, 4, 4, 4],\n",
       "        [1, 2, 3, 4, 0, 2, 3, 4, 0, 1, 3, 4, 0, 1, 2, 4, 0, 1, 2, 3]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(recon_mol)\n",
    "recon_mol.edge_index"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
